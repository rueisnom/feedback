<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="https://stackoverflow.com/questions/375913">
    <body>
      <group id="375913">
        <trans-unit id="474f686377fbd8012f361b7bd0929092b87eaedd" translate="yes" xml:space="preserve">
          <source>(The key is that we see &lt;code&gt;I&lt;/code&gt; more than once. If we only see it once, that doesn't tell us much except that &lt;code&gt;f&lt;/code&gt; &amp;gt; 0.)</source>
          <target state="translated">(Ключ в том, что мы видим &lt;code&gt;I&lt;/code&gt; более одного раза. Если мы видим его только один раз, это мало что нам говорит, за исключением того, что &lt;code&gt;f&lt;/code&gt; &amp;gt; 0.)</target>
        </trans-unit>
        <trans-unit id="6bddfcbf9effc6af0dc2a4017b8af4d6d8c3b612" translate="yes" xml:space="preserve">
          <source>(not so good for multi-threads, function pointers)</source>
          <target state="translated">(не очень хорошо для многопоточных,функциональных указателей)</target>
        </trans-unit>
        <trans-unit id="ba000b98349f454ff4d963d272eea56d9076b1f0" translate="yes" xml:space="preserve">
          <source>(wikipedia) Valgrind is in essence a virtual
  machine using just-in-time (JIT)
  compilation techniques, including
  dynamic recompilation. Nothing from
  the original program ever gets run
  directly on the host processor.
  Instead, Valgrind first translates the
  program into a temporary, simpler form
  called Intermediate Representation
  (IR), which is a processor-neutral,
  SSA-based form. After the conversion,
  a tool (see below) is free to do
  whatever transformations it would like
  on the IR, before Valgrind translates
  the IR back into machine code and lets
  the host processor run it.</source>
          <target state="translated">(wikipedia)Valgrind,по сути,является виртуальной машиной,использующей методы компиляции &quot;точно в срок&quot; (JIT),включая динамическую перекомпиляцию.Ничего из исходной программы никогда не запускается непосредственно на хост-процессоре.Вместо этого,Valgrind сначала переводит программу во временную,более простую форму под названием Intermediate Representation (IR),которая является нейтральной с точки зрения процессора,SSA-формой.После преобразования инструмент (см.ниже)может делать любые преобразования на IR,прежде чем Valgrind преобразует IR обратно в машинный код и позволяет хост-процессору запустить его.</target>
        </trans-unit>
        <trans-unit id="2f52699e83e4b55e1f403f7c6079898edd6b4dff" translate="yes" xml:space="preserve">
          <source>- Above function , there is a list of functions that call the function .</source>
          <target state="translated">-Над функцией находится список функций,вызывающих эту функцию.</target>
        </trans-unit>
        <trans-unit id="97381d92a175352738f31c6b84ed1b50492ba724" translate="yes" xml:space="preserve">
          <source>- Below function , there is a list of functions that are called by the function .</source>
          <target state="translated">-Ниже функции находится список функций,которые вызываются функцией.</target>
        </trans-unit>
        <trans-unit id="2a06d6944b31ca287d1197fb91866bf150b9273f" translate="yes" xml:space="preserve">
          <source>- In each section, one function is marked with an index number.</source>
          <target state="translated">-В каждой секции одна функция обозначается индексным номером.</target>
        </trans-unit>
        <trans-unit id="579a41d12eaf05b9059712857073fbbb03bff3f1" translate="yes" xml:space="preserve">
          <source>- how many seconds were spent in a function&amp;mdash;including and excluding calls to sub-functions,</source>
          <target state="translated">- сколько секунд было потрачено на функцию, включая и исключая вызовы подфункций,</target>
        </trans-unit>
        <trans-unit id="2e6d2ff4ea07291f0fe68b6a1592baa107889c9d" translate="yes" xml:space="preserve">
          <source>- the average time per call.</source>
          <target state="translated">-среднее время звонка.</target>
        </trans-unit>
        <trans-unit id="09049524fc0fe3657417bd54beda8ddfcc7d00b5" translate="yes" xml:space="preserve">
          <source>- the number of calls,</source>
          <target state="translated">-количество звонков,</target>
        </trans-unit>
        <trans-unit id="726e946052f1dbb2b5959a244967231f79036c38" translate="yes" xml:space="preserve">
          <source>- what percentage of the overall time was spent for the function,</source>
          <target state="translated">-какой процент общего времени был потрачен на эту функцию,</target>
        </trans-unit>
        <trans-unit id="e299449c036492af510a743e9982f023ddc5e7c0" translate="yes" xml:space="preserve">
          <source>1- Flat profiling:</source>
          <target state="translated">1.Плоское профилирование:</target>
        </trans-unit>
        <trans-unit id="961cb4afe9142078530eb983e36df03834cb40bb" translate="yes" xml:space="preserve">
          <source>2- graph profiling</source>
          <target state="translated">2-графическое профилирование</target>
        </trans-unit>
        <trans-unit id="45d30831218fba6255f04ee5d6cb69901aae44b4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;main&lt;/code&gt; calls &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;maybe_slow&lt;/code&gt; 3 times, one of the &lt;code&gt;maybe_slow&lt;/code&gt; calls being slow</source>
          <target state="translated">&lt;code&gt;main&lt;/code&gt; вызовы &lt;code&gt;fast&lt;/code&gt; и 3 раза &lt;code&gt;maybe_slow&lt;/code&gt; быть медленная, один из возможных вызовов медленная</target>
        </trans-unit>
        <trans-unit id="2b26d60b77140f5edaf92172d3607731805526d8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;perf&lt;/code&gt; seems to use exclusively Linux kernel sampling mechanisms. This makes it very simple to setup, but also not fully accurate.</source>
          <target state="translated">Кажется, что &lt;code&gt;perf&lt;/code&gt; использует исключительно механизмы выборки ядра Linux. Это делает его очень простым в настройке, но также не полностью точным.</target>
        </trans-unit>
        <trans-unit id="beaa2542bdd5cb48d735e110bbd66e279a970967" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;valgrind&lt;/code&gt; with the combination of &lt;code&gt;callrind&lt;/code&gt; and &lt;code&gt;kcachegrind&lt;/code&gt; should provide a decent estimation on the points above and once it's established that there are issues with some section of code, I'd suggest do a micro bench mark &lt;code&gt;google benchmark&lt;/code&gt; is a good place to start.</source>
          <target state="translated">&lt;code&gt;valgrind&lt;/code&gt; с комбинацией &lt;code&gt;callrind&lt;/code&gt; и &lt;code&gt;kcachegrind&lt;/code&gt; должен дать приличную оценку вышеупомянутым пунктам, и как только будет установлено, что есть проблемы с некоторым разделом кода, я бы предложил начать с микробенчмарка &lt;code&gt;google benchmark&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="558433641cab85097025b8b72bc823c8bf5e82ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;code&gt;perf&lt;/code&gt; from &lt;code&gt;linux-tools&lt;/code&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt; &lt;code&gt;perf&lt;/code&gt; из &lt;code&gt;linux-tools&lt;/code&gt; &lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1e49cc3868d9deb4e8335aa49828e8c34898c8a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;em&gt;For CPU bound applications:&lt;/em&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;&lt;em&gt;Для приложений, связанных с процессором:&lt;/em&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="7196658c799f4043d28d713837910b362f91ab93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;em&gt;For I/O bound applications:&lt;/em&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;&lt;em&gt;Для приложений ввода-вывода:&lt;/em&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="ad2cef4043d111e1ae8c4692b0d3548a6613fcbd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Intel VTune is the best (free for educational purposes).&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Intel VTune является лучшим (бесплатно для образовательных целей).&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a2b5b23586b55133642cbd2c4d931e703f33536e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Others:&lt;/strong&gt; AMD Codeanalyst (since replaced with AMD CodeXL), OProfile, 'perf' tools (apt-get install linux-tools)</source>
          <target state="translated">&lt;strong&gt;Другие:&lt;/strong&gt; AMD Codeanalyst (с заменой на AMD CodeXL), OProfile, инструменты 'perf' (apt-get install linux-tools)</target>
        </trans-unit>
        <trans-unit id="9f805de8a6187ff8c605dc1b87c1dbf750af8806" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Survey of C++ profiling techniques&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Обзор методов профилирования C ++&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="5935609263c49f484c816bb47bd583d8ac724622" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use Valgrind, callgrind and kcachegrind:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Используйте Valgrind, callgrind и kcachegrind:&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="f76b5fe3b1c9563ed7d1caedae895977e4729ca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use google-perftools:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Используйте google-perftools:&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="eaf91a71c594a624723a2785654641c0d49b648f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use gprof (add -pg):&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Используйте gprof (добавьте -pg):&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="e2938d732361a260a7c9ca67f5add9a7cbbbdb25" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gperftools&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;gperftools&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b34e9a3fe97464e4681d8532723054a812e2edcd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gprof&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;gprof&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a645022e82b11913d78a887f81582e01e0a2ca4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;valgrind callgrind&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Valgrind Callgrind&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b68ca6f37b8016941f5283f36f3759df87ef2002" translate="yes" xml:space="preserve">
          <source>A few other buzzwords if &lt;code&gt;gprof&lt;/code&gt; does not do the job for you: &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt;, Intel &lt;a href=&quot;http://en.wikipedia.org/wiki/VTune&quot;&gt;VTune&lt;/a&gt;, Sun &lt;a href=&quot;http://en.wikipedia.org/wiki/DTrace&quot;&gt;DTrace&lt;/a&gt;.</source>
          <target state="translated">Несколько других модных слов, если &lt;code&gt;gprof&lt;/code&gt; не выполняет эту работу за вас: &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt; , Intel &lt;a href=&quot;http://en.wikipedia.org/wiki/VTune&quot;&gt;VTune&lt;/a&gt; , Sun &lt;a href=&quot;http://en.wikipedia.org/wiki/DTrace&quot;&gt;DTrace&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7c42306a937ace4fd5a87d18a701b72889554283" translate="yes" xml:space="preserve">
          <source>ADDED, to give an intuitive feel for the difference between measuring and random stack sampling:</source>
          <target state="translated">Добавлено,чтобы дать интуитивное ощущение разницы между измерением и случайной выборкой стека:</target>
        </trans-unit>
        <trans-unit id="9276e16e7cc14ecf9ae00f247b4196166d5d1aeb" translate="yes" xml:space="preserve">
          <source>ADDED: Let me make a Bayesian explanation of how it works.  Suppose there is some instruction &lt;code&gt;I&lt;/code&gt; (call or otherwise) which is on the call stack some fraction &lt;code&gt;f&lt;/code&gt; of the time (and thus costs that much). For simplicity, suppose we don't know what &lt;code&gt;f&lt;/code&gt; is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori.</source>
          <target state="translated">ДОБАВЛЕНО: Позвольте мне сделать байесовское объяснение того, как это работает. Предположим, что есть какая-то инструкция &lt;code&gt;I&lt;/code&gt; (вызов или иное), которая находится в стеке вызовов некоторое время &lt;code&gt;f&lt;/code&gt; (и, следовательно, стоит так дорого). Для простоты предположим, что мы не знаем, что такое &lt;code&gt;f&lt;/code&gt; , но предположим, что оно равно либо 0,1, 0,2, 0,3, ... 0,9, 1,0, и априорная вероятность каждой из этих возможностей равна 0,1, поэтому все эти затраты равны скорее всего априори.</target>
        </trans-unit>
        <trans-unit id="830b0bd9a847a1c514fcf9b261f15a81a0e87159" translate="yes" xml:space="preserve">
          <source>Actually a bit surprised not many mentioned about &lt;a href=&quot;https://github.com/google/benchmark&quot;&gt;google/benchmark&lt;/a&gt; , while it is a bit cumbersome to pin the specific area of code, specially if the code base is a little big one, however I found this really helpful when used in combination with &lt;code&gt;callgrind&lt;/code&gt;</source>
          <target state="translated">На самом деле немного удивлен, что многие не упоминали о &lt;a href=&quot;https://github.com/google/benchmark&quot;&gt;google / benchmark&lt;/a&gt; , хотя немного сложно связать определенную область кода, особенно если база кода немного большая, однако я нашел это действительно полезным при использовании в сочетании с &lt;code&gt;callgrind&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d081153271ba73f6b08b5c733dfc600113ac8050" translate="yes" xml:space="preserve">
          <source>Added: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample.</source>
          <target state="translated">Добавлено:Может быть,это и не очевидно,но техника выборки стека работает одинаково хорошо при наличии рекурсии.Причина в том,что время,которое можно было бы сэкономить,удалив инструкцию,аппроксимируется долей содержащихся в ней выборок,независимо от того,сколько раз это может произойти внутри выборки.</target>
        </trans-unit>
        <trans-unit id="c111026e3becc4657525d1504f2a98b1227fa293" translate="yes" xml:space="preserve">
          <source>After running with either of those methods, we get a &lt;code&gt;prof.out&lt;/code&gt; profile data file as output. We can view that file graphically as an SVG with:</source>
          <target state="translated">После запуска любого из этих методов мы получаем &lt;code&gt;prof.out&lt;/code&gt; данных профиля prof.out в качестве вывода. Мы можем просмотреть этот файл графически как SVG с:</target>
        </trans-unit>
        <trans-unit id="938c0204782973ed2cee8235fd6ed9aad9bd19a0" translate="yes" xml:space="preserve">
          <source>Also worth mentioning are</source>
          <target state="translated">Также следует отметить</target>
        </trans-unit>
        <trans-unit id="30c36d00bdcf5c119d2a78569796b3b993fd0320" translate="yes" xml:space="preserve">
          <source>Also, if we go on the bottom right &quot;Call Graph&quot; tab, we see a call graph which we can export by right clicking it to obtain the following image with unreasonable amounts of white border :-)</source>
          <target state="translated">Также,если мы перейдем на вкладку &quot;График звонков&quot; внизу справа,мы увидим график звонков,который можно экспортировать,щелкнув по нему правой кнопкой мыши,чтобы получить следующее изображение с неоправданным количеством белой границы :-)</target>
        </trans-unit>
        <trans-unit id="1ac3bae0296e72365db70cdbd1d168992f9eb4f9" translate="yes" xml:space="preserve">
          <source>Alternatively, we can also get some textual data with:</source>
          <target state="translated">Кроме того,мы можем также получить некоторые текстовые данные:</target>
        </trans-unit>
        <trans-unit id="6fe0b9fdb5d375e1bdddd4970a95aeb96c822b66" translate="yes" xml:space="preserve">
          <source>Alternatively, we can also observe the text output of the &lt;code&gt;gprof&lt;/code&gt; built-in binutils tool which we previously saved at:</source>
          <target state="translated">В качестве альтернативы, мы также можем наблюдать вывод текста встроенного инструмента binutils &lt;code&gt;gprof&lt;/code&gt; , который мы ранее сохранили в:</target>
        </trans-unit>
        <trans-unit id="d9dc64edf60dc7f5a3736a9279e32f3c03a13aa5" translate="yes" xml:space="preserve">
          <source>Alternatively, we can build the library in at link time, dispensing passing &lt;code&gt;LD_PRELOAD&lt;/code&gt; at runtime:</source>
          <target state="translated">В качестве альтернативы мы можем встроить библиотеку во время соединения, распределяя передачу &lt;code&gt;LD_PRELOAD&lt;/code&gt; во время выполнения:</target>
        </trans-unit>
        <trans-unit id="2cf1c27c41cddb303f6c128115968d14017c5f27" translate="yes" xml:space="preserve">
          <source>Another objection I often hear is: &quot;&lt;em&gt;It will stop someplace random, and it will miss the real problem&lt;/em&gt;&quot;.
This comes from having a prior concept of what the real problem is.
A key property of performance problems is that they defy expectations.
Sampling tells you something is a problem, and your first reaction is disbelief.
That is natural, but you can be sure if it finds a problem it is real, and vice-versa.</source>
          <target state="translated">Другое возражение, которое я часто слышу, звучит так: &amp;laquo; &lt;em&gt;Это остановит что-то случайное и упустит реальную проблему&lt;/em&gt; &amp;raquo;. Это происходит из-за наличия предварительного представления о том, что является реальной проблемой. Ключевым свойством проблем с производительностью является то, что они не поддаются ожиданиям. Выборка говорит вам, что что-то является проблемой, и ваша первая реакция - неверие. Это естественно, но вы можете быть уверены, что если оно обнаружит проблему, то это реально, и наоборот.</target>
        </trans-unit>
        <trans-unit id="fd2b8eb720b92068f67a32658ccfc03d658f34d9" translate="yes" xml:space="preserve">
          <source>Another perf GUI interfaces which might be worth it include:</source>
          <target state="translated">Еще один совершенный GUI-интерфейс,который может стоить того,чтобы его включить:</target>
        </trans-unit>
        <trans-unit id="48122e4897dd407d27c90182539de52d682b669c" translate="yes" xml:space="preserve">
          <source>Another tool build upon Valgrind is Massif. I use it to profile heap memory usage. It works great. What it does is that it gives you snapshots of memory usage -- detailed information WHAT holds WHAT percentage of memory, and WHO had put it there. Such information is available at different points of time of application run.</source>
          <target state="translated">Другим инструментом,построенным на Valgrind,является Massif.Я использую его для профилирования использования памяти кучи.Он отлично работает.Он дает снимки использования памяти --подробную информацию о том,что содержит ЧТО,ЧТО и какой процент памяти,и кто его туда поместил.Такая информация доступна в различные моменты времени работы приложения.</target>
        </trans-unit>
        <trans-unit id="26cfea3667d4951989c3328a2749151be15581ab" translate="yes" xml:space="preserve">
          <source>Arm MAP is the profiler for parallel, multithreaded or single threaded C, C++, Fortran and F90 codes.  It provides in-depth analysis and bottleneck pinpointing to the source line.  Unlike most profilers, it's designed to be able to profile pthreads, OpenMP or MPI for parallel and threaded code.</source>
          <target state="translated">Arm MAP-это профилировщик для параллельных,многопоточных или однопоточных кодов C,C++,Fortran и F90.Он обеспечивает глубокий анализ и точное нахождение узких мест в исходной линии.В отличие от большинства профайлеров,она предназначена для профилирования многопоточных,OpenMP или MPI для параллельного и многопоточного кода.</target>
        </trans-unit>
        <trans-unit id="f607a78951293acbad31ccf19fd2a9c3fc0343e3" translate="yes" xml:space="preserve">
          <source>As a very quick summary for each section e.g.:</source>
          <target state="translated">В качестве очень быстрого резюме для каждого раздела,например:</target>
        </trans-unit>
        <trans-unit id="1361188e9146c170f0554ec525ed827cb7592cc2" translate="yes" xml:space="preserve">
          <source>As no one mentioned Arm MAP, I'd add it as personally I have successfully used Map to profile a C++ scientific program.</source>
          <target state="translated">Как никто не упоминал Arm MAP,я бы добавил его,так как лично я успешно использовал карту для профилирования научной программы на С++.</target>
        </trans-unit>
        <trans-unit id="33441507f930cc628d62c6420d02d66548f47be3" translate="yes" xml:space="preserve">
          <source>At runtime, we have to pass set the &lt;code&gt;LD_PRELOAD&lt;/code&gt; to point to &lt;code&gt;libprofiler.so&lt;/code&gt;, which you can find with &lt;code&gt;locate libprofiler.so&lt;/code&gt;, e.g. on my system:</source>
          <target state="translated">Во время выполнения мы должны передать set &lt;code&gt;LD_PRELOAD&lt;/code&gt; для указания на &lt;code&gt;libprofiler.so&lt;/code&gt; , который вы можете найти с помощью &lt;code&gt;locate libprofiler.so&lt;/code&gt; , например, в моей системе:</target>
        </trans-unit>
        <trans-unit id="275c32d1f4761fd0f70f1e315294ca1da95e4155" translate="yes" xml:space="preserve">
          <source>At work we have a really nice tool that helps us monitoring what we want in terms of scheduling. This has been useful numerous times.</source>
          <target state="translated">На работе у нас есть действительно хороший инструмент,который помогает нам следить за тем,что мы хотим с точки зрения планирования.Он был полезен много раз.</target>
        </trans-unit>
        <trans-unit id="c762222f2d1b7501653b936c0a39cd0b1aa6a933" translate="yes" xml:space="preserve">
          <source>Be sure to add &lt;code&gt;-pg&lt;/code&gt; to compilation before profiling:</source>
          <target state="translated">Обязательно добавьте &lt;code&gt;-pg&lt;/code&gt; к компиляции перед профилированием:</target>
        </trans-unit>
        <trans-unit id="d55e4a545eefcf858705baa9f8981e8dc001934b" translate="yes" xml:space="preserve">
          <source>Because we compiled with &lt;code&gt;-pg&lt;/code&gt;, running the program produces a file &lt;code&gt;gmon.out&lt;/code&gt; file containing the profiling data.</source>
          <target state="translated">Поскольку мы скомпилировали с &lt;code&gt;-pg&lt;/code&gt; , при запуске программы создается файл &lt;code&gt;gmon.out&lt;/code&gt; , содержащий данные профилирования.</target>
        </trans-unit>
        <trans-unit id="0e20564692b92dee75c5d2d38aa97448c7b86382" translate="yes" xml:space="preserve">
          <source>But this has the downside that you have to first convert the data to the Common Trace Format, which can be done with &lt;code&gt;perf data --to-ctf&lt;/code&gt;, but it needs to be enabled at build time/have &lt;code&gt;perf&lt;/code&gt; new enough, either of which is not the case for the perf in Ubuntu 18.04</source>
          <target state="translated">Но у этого есть недостаток: сначала нужно преобразовать данные в общий формат трассировки, что можно сделать с помощью &lt;code&gt;perf data --to-ctf&lt;/code&gt; , но его нужно включить во время сборки / иметь достаточно новый &lt;code&gt;perf&lt;/code&gt; , любой из которых дело не в перфе в Ubuntu 18.04</target>
        </trans-unit>
        <trans-unit id="7940ac6d6de4ba483d9863a1db60f99151f2c050" translate="yes" xml:space="preserve">
          <source>By default, this produces an extremely verbose output that explains what the output data means. Since I can't explain better than that, I'll let you read it yourself.</source>
          <target state="translated">По умолчанию это производит чрезвычайно подробный вывод,который объясняет,что означают выходные данные.Так как я не могу объяснить лучше,я позволю тебе прочитать это самому.</target>
        </trans-unit>
        <trans-unit id="0e030095a99fb3257e11106bd611c56f45c2b3ed" translate="yes" xml:space="preserve">
          <source>Callgrind is a profiler build upon that. Main benefit is that you don't have to run your aplication for hours to get reliable result. Even one second run is sufficient to get rock-solid, reliable results, because Callgrind is a &lt;strong&gt;non-probing&lt;/strong&gt; profiler.</source>
          <target state="translated">Callgrind - это профилировщик, основанный на этом. Основным преимуществом является то, что вам не нужно запускать приложение в течение нескольких часов, чтобы получить надежный результат. Даже одной секунды достаточно для получения надежных и надежных результатов, потому что Callgrind - &lt;strong&gt;не зондирующий&lt;/strong&gt; профилировщик.</target>
        </trans-unit>
        <trans-unit id="5fea0991e44d8690969eca7425688fa735bb73f4" translate="yes" xml:space="preserve">
          <source>Can you find the most critical call stack easily with all those tiny unsorted spaghetti lines going over one another? There might be better &lt;code&gt;dot&lt;/code&gt; options I'm sure, but I don't want to go there now. What we really need is a proper dedicated viewer for it, but I haven't found one yet:</source>
          <target state="translated">Можете ли вы легко найти наиболее критичный стек вызовов со всеми этими крошечными несортированными линиями спагетти, идущими друг на друга? Я уверен, что могут быть и более &lt;code&gt;dot&lt;/code&gt; варианты, но я не хочу идти туда сейчас. Что нам действительно нужно, так это соответствующий специальный просмотрщик, но я еще не нашел его:</target>
        </trans-unit>
        <trans-unit id="20f2f816399d50a15985c861ae31ff174b730293" translate="yes" xml:space="preserve">
          <source>Caveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because</source>
          <target state="translated">Caveat:Программисты склонны скептически относиться к этой технике,если они сами ее не использовали.Они скажут,что профайлеры дают вам эту информацию,но это верно только в том случае,если они сэмплируют весь стек вызовов,а затем позволят вам исследовать случайный набор образцов.(В аннотациях теряется понимание.)Графики вызовов не дают вам той же самой информации,потому что</target>
        </trans-unit>
        <trans-unit id="099dc36893aed4eafd86bced522e4eb9937e5b98" translate="yes" xml:space="preserve">
          <source>Eclipse Trace Compass plugin: &lt;a href=&quot;https://www.eclipse.org/tracecompass/&quot;&gt;https://www.eclipse.org/tracecompass/&lt;/a&gt;</source>
          <target state="translated">Плагин Eclipse Trace Compass: &lt;a href=&quot;https://www.eclipse.org/tracecompass/&quot;&gt;https://www.eclipse.org/tracecompass/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b0500648de7f8cd809c18dfe1a12b0af1850fcf1" translate="yes" xml:space="preserve">
          <source>First install gperftools with:</source>
          <target state="translated">Сначала установите перфораторы с:</target>
        </trans-unit>
        <trans-unit id="f718a4c61c9b86b8efe3e4a514c5978b1cf993ee" translate="yes" xml:space="preserve">
          <source>First we have to remove the &lt;code&gt;-pg&lt;/code&gt; flag to go back to normal compilation, otherwise the run actually fails with &lt;a href=&quot;https://stackoverflow.com/questions/2146082/valgrind-profiling-timer-expired&quot;&gt;&lt;code&gt;Profiling timer expired&lt;/code&gt;&lt;/a&gt;, and yes, this is so common that I did and there was a Stack Overflow question for it.</source>
          <target state="translated">Сначала мы должны удалить флаг &lt;code&gt;-pg&lt;/code&gt; , чтобы вернуться к нормальной компиляции, иначе запуск фактически завершится неудачно с &lt;a href=&quot;https://stackoverflow.com/questions/2146082/valgrind-profiling-timer-expired&quot;&gt; &lt;code&gt;Profiling timer expired&lt;/code&gt; &lt;/a&gt; , и да, это так часто, что я сделал, и для него возник вопрос переполнения стека.</target>
        </trans-unit>
        <trans-unit id="731b082498e3f526227d4ecd0e76236c0bf482bd" translate="yes" xml:space="preserve">
          <source>First, &lt;code&gt;time&lt;/code&gt; tells us that the execution time with and without &lt;code&gt;-pg&lt;/code&gt; were the same, which is great: no slowdown! I have however seen accounts of 2x - 3x slowdowns on complex software, e.g. as &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;shown in this ticket&lt;/a&gt;.</source>
          <target state="translated">Во-первых, &lt;code&gt;time&lt;/code&gt; говорит нам, что время выполнения с и без &lt;code&gt;-pg&lt;/code&gt; было одинаковым, и это здорово: никакого замедления! Однако я видел сообщения о 2x - 3x замедлениях на сложном программном обеспечении, например, как &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;показано в этом билете&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bcac6f94f0587cb573e61450977a4e3d79d79994" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;-O3&lt;/code&gt;, see here like in the graphical output that &lt;code&gt;maybe_slow&lt;/code&gt; and &lt;code&gt;fast&lt;/code&gt; don't have a known parent, which is what the documentation says that &lt;code&gt;&amp;lt;spontaneous&amp;gt;&lt;/code&gt; means.</source>
          <target state="translated">Для &lt;code&gt;-O3&lt;/code&gt; , смотрите здесь, как в графическом выводе, что &lt;code&gt;maybe_slow&lt;/code&gt; и &lt;code&gt;fast&lt;/code&gt; не имеют известного родителя, что в документации сказано, что означает &lt;code&gt;&amp;lt;spontaneous&amp;gt;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="06d456a661f5b9ba3d3687e35852bf5858fab879" translate="yes" xml:space="preserve">
          <source>For CPU, the reason for profiling in &lt;strong&gt;DEBUG&lt;/strong&gt; mode is because if your tried profiling in &lt;strong&gt;RELEASE&lt;/strong&gt; mode, the compiler is going to reduce math, vectorize loops, and inline functions which tends to glob your code into an un-mappable mess when it's assembled. &lt;strong&gt;An un-mappable mess means your profiler will not be able to clearly identify what is taking so long because the assembly may not correspond to the source code under optimization&lt;/strong&gt;. If you need the performance (e.g. timing sensitive) of &lt;strong&gt;RELEASE&lt;/strong&gt; mode, disable debugger features as needed to keep a usable performance.</source>
          <target state="translated">Для CPU, причина для профилирования в режиме &lt;strong&gt;DEBUG&lt;/strong&gt; заключается в том, что если вы попробовали профилирование в режиме &lt;strong&gt;RELEASE&lt;/strong&gt; , компилятор собирается уменьшить математические, векторизованные циклы и встроенные функции, которые имеют тенденцию превращать ваш код в не отображаемый беспорядок при сборке. &lt;strong&gt;Непоправимый беспорядок означает, что ваш профилировщик не сможет четко определить, что занимает так много времени, поскольку сборка может не соответствовать оптимизируемому исходному коду&lt;/strong&gt; . Если вам нужна производительность (например, чувствительная к времени) в режиме &lt;strong&gt;RELEASE&lt;/strong&gt; , отключите функции отладчика, чтобы сохранить работоспособность.</target>
        </trans-unit>
        <trans-unit id="1fd1a4e3732d0165baa94d16658f7291d1e77cb2" translate="yes" xml:space="preserve">
          <source>For I/O-bound, the profiler can still identify I/O operations in &lt;strong&gt;RELEASE&lt;/strong&gt; mode because I/O operations are either externally linked to a shared library (most of the time) or in the worst case, will result in a sys-call interrupt vector (which is also easily identifiable by the profiler).</source>
          <target state="translated">Для привязки к вводу / выводу профилировщик все еще может идентифицировать операции ввода / вывода в режиме &lt;strong&gt;RELEASE,&lt;/strong&gt; поскольку операции ввода / вывода либо внешне связаны с общей библиотекой (большую часть времени), либо в худшем случае приводят к системной вектор прерывания вызова (который также легко определяется профилировщиком).</target>
        </trans-unit>
        <trans-unit id="da7a5db11d6d72fa7a5c6be30597dedf122892f3" translate="yes" xml:space="preserve">
          <source>For educational reasons, we will also do a run without optimizations enabled. Note that this is useless in practice, as you normally only care about optimizing the performance of the optimized program:</source>
          <target state="translated">По образовательным причинам,мы также сделаем запуск без включенных оптимизаций.Обратите внимание,что на практике это бесполезно,так как обычно вы заботитесь только об оптимизации производительности оптимизированной программы:</target>
        </trans-unit>
        <trans-unit id="59ad9936a7b0f4788c6ad3b0ea79e48e4a42d309" translate="yes" xml:space="preserve">
          <source>For single-threaded programs you can use &lt;strong&gt;igprof&lt;/strong&gt;, The Ignominous Profiler: &lt;a href=&quot;https://igprof.org/&quot;&gt;https://igprof.org/&lt;/a&gt; .</source>
          <target state="translated">Для однопоточных программ вы можете использовать &lt;strong&gt;igprof&lt;/strong&gt; , Ignominous Profiler: &lt;a href=&quot;https://igprof.org/&quot;&gt;https://igprof.org/&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e32962da9446269770cb3283319d83603bd59de6" translate="yes" xml:space="preserve">
          <source>HPCToolkit (&lt;a href=&quot;http://hpctoolkit.org/&quot;&gt;http://hpctoolkit.org/&lt;/a&gt;) - Open-source, works for parallel programs and has a GUI with which to look at the results multiple ways</source>
          <target state="translated">HPCToolkit ( &lt;a href=&quot;http://hpctoolkit.org/&quot;&gt;http://hpctoolkit.org/&lt;/a&gt; ) - с открытым исходным кодом, работает для параллельных программ и имеет графический интерфейс для просмотра результатов несколькими способами</target>
        </trans-unit>
        <trans-unit id="9717437adb9e366c40c178b8b430e79730bf5d20" translate="yes" xml:space="preserve">
          <source>Here is an off-the-cuff illustration of the difference between examining measurements and examining stack samples.
The bottleneck could be one big blob like this, or numerous small ones, it makes no difference.</source>
          <target state="translated">Ниже приведена иллюстрация разницы между исследуемыми измерениями и исследуемыми образцами штабеля.Узким местом может быть один большой капля,как этот,или многочисленные маленькие,это не имеет значения.</target>
        </trans-unit>
        <trans-unit id="84e40b82ddf20b2158fe8ae0544325f38d246cfd" translate="yes" xml:space="preserve">
          <source>Here, the &lt;code&gt;gprof&lt;/code&gt; tool reads the &lt;code&gt;gmon.out&lt;/code&gt; trace information, and generates a human readable report in &lt;code&gt;main.gprof&lt;/code&gt;, which &lt;code&gt;gprof2dot&lt;/code&gt; then reads to generate a graph.</source>
          <target state="translated">Здесь инструмент &lt;code&gt;gprof&lt;/code&gt; считывает &lt;code&gt;gmon.out&lt;/code&gt; трассировки gmon.out и генерирует удобочитаемый отчет в &lt;code&gt;main.gprof&lt;/code&gt; , который &lt;code&gt;gprof2dot&lt;/code&gt; затем считывает для создания графика.</target>
        </trans-unit>
        <trans-unit id="966dcaa64447ac43f2c9e4440202155cac9e9802" translate="yes" xml:space="preserve">
          <source>Hope the idea is not obfuscated by the lack of sample code.</source>
          <target state="translated">Надеюсь,идею не затруднит отсутствие примерного кода.</target>
        </trans-unit>
        <trans-unit id="b3431131b2f01fa3ab4147cebf53065a9fed2f0e" translate="yes" xml:space="preserve">
          <source>How can I profile C++ code running on Linux</source>
          <target state="translated">Как профилировать C++код,работающий под Linux</target>
        </trans-unit>
        <trans-unit id="e8d9679c58e452301713e88a029c43b1b26959f7" translate="yes" xml:space="preserve">
          <source>However, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems.</source>
          <target state="translated">Однако,если вы торопитесь и можете вручную прервать свою программу под отладчиком,пока она субъективно медленная,есть простой способ найти проблемы с производительностью.</target>
        </trans-unit>
        <trans-unit id="469ae7f984de3b3fd05c657ff55c2e05a4bb68f3" translate="yes" xml:space="preserve">
          <source>I assume you're using GCC. The standard solution would be to profile with &lt;a href=&quot;http://www.math.utah.edu/docs/info/gprof_toc.html&quot;&gt;gprof&lt;/a&gt;.</source>
          <target state="translated">Я полагаю, вы используете GCC. Стандартным решением будет профилирование с помощью &lt;a href=&quot;http://www.math.utah.edu/docs/info/gprof_toc.html&quot;&gt;gprof&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2626ed11413be172901c236c0ce46711b1e4e409" translate="yes" xml:space="preserve">
          <source>I choose SVG output instead of PNG because the SVG is searchable with Ctrl + F and the file size can be about 10x smaller. Also, the width and height of the generated image can be humoungous with tens of thousands of pixels for complex software, and GNOME &lt;code&gt;eog&lt;/code&gt; 3.28.1 bugs out in that case for PNGs, while SVGs get opened by my browser automatically. gimp 2.8 worked well though, see also:</source>
          <target state="translated">Я выбираю вывод SVG вместо PNG, потому что SVG доступен для поиска с помощью Ctrl + F, а размер файла может быть примерно в 10 раз меньше. Кроме того, ширина и высота сгенерированного изображения могут быть огромными с десятками тысяч пикселей для сложного программного обеспечения, и GNOME &lt;code&gt;eog&lt;/code&gt; 3.28.1 в этом случае работает с ошибками для PNG, тогда как SVG автоматически открываются моим браузером. GIMP 2.8 работал хорошо, см. также:</target>
        </trans-unit>
        <trans-unit id="219d1034d60f6bcc0c754cc1eb67709e077e407e" translate="yes" xml:space="preserve">
          <source>I enable &lt;code&gt;--dump-instr=yes --collect-jumps=yes&lt;/code&gt; because this also dumps information that enables us to view a per assembly line breakdown of performance, at a relatively small added overhead cost.</source>
          <target state="translated">Я &lt;code&gt;--dump-instr=yes --collect-jumps=yes&lt;/code&gt; потому что это также выводит информацию, которая позволяет нам просматривать разбивку производительности по конвейеру при относительно небольших дополнительных накладных расходах.</target>
        </trans-unit>
        <trans-unit id="161bfcf11ea394e1742c7e0a58a6044adc301c18" translate="yes" xml:space="preserve">
          <source>I have a C++ application, running on Linux, which I'm in the process of optimizing. How can I pinpoint which areas of my code are running slowly?</source>
          <target state="translated">У меня есть C++приложение,работающее под Linux,которое я сейчас оптимизирую.Как я могу точно определить,какие области моего кода выполняются медленно?</target>
        </trans-unit>
        <trans-unit id="3fa235219dffe6626130e2fa7a49a904b35f5be5" translate="yes" xml:space="preserve">
          <source>I have used HPCToolkit and VTune and they are very effective at finding the long pole in the tent and do not need your code to be recompiled (except that you have to use -g -O or RelWithDebInfo type build in CMake to get meaningful output). I have heard TAU is similar in capabilities.</source>
          <target state="translated">Я использовал HPCToolkit и VTune,они очень эффективны при поиске длинного полюса в палатке и не нуждаются в перекомпиляции вашего кода (за исключением того,что вам нужно использовать тип -g -O или RelWithDebInfo тип сборки в CMake,чтобы получить осмысленный вывод).Я слышал,что TAU похожа по возможностям.</target>
        </trans-unit>
        <trans-unit id="d652bdc8e2d715973adba2c14a8aeac6ea5b5520" translate="yes" xml:space="preserve">
          <source>I haven't tried it yet but I've heard good things about &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;google-perftools&lt;/a&gt;. It is definitely worth a try.</source>
          <target state="translated">Я еще не пробовал, но слышал хорошие вещи о &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;google-perftools&lt;/a&gt; . Это определенно стоит попробовать.</target>
        </trans-unit>
        <trans-unit id="9adb36d7693cd006e9f81ed5125c898080cee016" translate="yes" xml:space="preserve">
          <source>I recommend in next window to click on &quot;Self&quot; column header, otherwise it shows that &quot;main()&quot; is most time consuming task. &quot;Self&quot; shows how much each function itself took time, not together with dependents.</source>
          <target state="translated">В следующем окне я рекомендую кликнуть на заголовок колонки &quot;Self&quot;,иначе это покажет,что &quot;main()&quot;-самая трудоемкая задача.&quot;Self&quot; показывает,сколько времени заняла сама функция,а не ее иждивенцы.</target>
        </trans-unit>
        <trans-unit id="0f482aa371b33a0d0d5638abd01afc2e298063e0" translate="yes" xml:space="preserve">
          <source>I think &lt;code&gt;fast&lt;/code&gt; is not showing on that graph because kcachegrind must have simplified the visualization because that call takes up too little time, this will likely be the behavior you want on a real program. The right click menu has some settings to control when to cull such nodes, but I couldn't get it to show such a short call after a quick attempt. If I click on &lt;code&gt;fast&lt;/code&gt; on the left window, it does show a call graph with &lt;code&gt;fast&lt;/code&gt;, so that stack was actually captured. No one had yet found a way to show the complete graph call graph: &lt;a href=&quot;https://stackoverflow.com/questions/33769323/make-callgrind-show-all-function-calls-in-the-kcachegrind-callgraph&quot;&gt;Make callgrind show all function calls in the kcachegrind callgraph&lt;/a&gt;</source>
          <target state="translated">Я думаю, что &lt;code&gt;fast&lt;/code&gt; не отображается на этом графике, потому что kcachegrind, должно быть, упростил визуализацию, потому что этот вызов занимает слишком мало времени, это, вероятно, будет поведение, которое вы хотите в реальной программе. Меню правого клика имеет некоторые настройки, чтобы контролировать, когда отбирать такие узлы, но я не смог заставить его показать такой короткий вызов после быстрой попытки. Если я нажимаю на &lt;code&gt;fast&lt;/code&gt; в левом окне, оно показывает график вызовов с &lt;code&gt;fast&lt;/code&gt; , так что стек фактически был захвачен. Никто еще не нашел способ показать полный график вызовов графа: &lt;a href=&quot;https://stackoverflow.com/questions/33769323/make-callgrind-show-all-function-calls-in-the-kcachegrind-callgraph&quot;&gt;заставить callgrind показывать все вызовы функций в графе вызовов kcachegrind&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9b793d633b0f9e951abdde18b8e2544cd6ea68b3" translate="yes" xml:space="preserve">
          <source>I would use Valgrind and Callgrind as a base for my profiling tool suite. What is important to know is that Valgrind is basically a Virtual Machine:</source>
          <target state="translated">Я бы использовал Valgrind и Callgrind в качестве основы для своего набора инструментов для профилирования.Важно знать,что Valgrind,по сути,является виртуальным станком:</target>
        </trans-unit>
        <trans-unit id="6263011d671a27f31d355d03e88575c38e353dc8" translate="yes" xml:space="preserve">
          <source>I'm not sure if there is a nice way to do line-by-line profiling with gprof: &lt;a href=&quot;https://stackoverflow.com/questions/9608949/gprof-time-spent-in-particular-lines-of-code&quot;&gt;`gprof` time spent in particular lines of code&lt;/a&gt;</source>
          <target state="translated">Я не уверен, есть ли хороший способ выполнить построчное профилирование с помощью gprof: &lt;a href=&quot;https://stackoverflow.com/questions/9608949/gprof-time-spent-in-particular-lines-of-code&quot;&gt;`gprof` время, потраченное на определенные строки кода&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bf065948e194a11f5b37f951703925e3fcde2b09" translate="yes" xml:space="preserve">
          <source>I've been using Gprof the last couple of days and have already found three significant limitations, one of which I've not seen documented anywhere else (yet):</source>
          <target state="translated">Последние пару дней я использую Gprof и уже нашел три существенных ограничения,одно из которых я нигде больше (пока)не видел задокументированным:</target>
        </trans-unit>
        <trans-unit id="9d8fb54a20b1fdf3a9f7cf18def00021f5a8cb9f" translate="yes" xml:space="preserve">
          <source>IMHO identifying the piece that is causing bottleneck is the key here. I'd however try and answer the following questions first and choose tool based on that</source>
          <target state="translated">IMHO идентифицировать кусок,который вызывает узкое место является ключом здесь.Тем не менее,я бы попробовал сначала ответить на следующие вопросы и выбрать инструмент на основании этого.</target>
        </trans-unit>
        <trans-unit id="dc4e7b05ff6973f04bea57e88cf21f888a6f86ea" translate="yes" xml:space="preserve">
          <source>If you don't have a profiler, use the poor man's profiler. Hit pause while debugging your application. Most developer suites will break into assembly with commented line numbers. You're statistically likely to land in a region that is eating most of your CPU cycles.</source>
          <target state="translated">Если у тебя нет профайлера,используй профайлер бедняги.Нажмите паузу во время отладки вашего приложения.Большинство пакетов разработчиков будут разбиваться на ассемблеры с прокомментированными номерами строк.По статистике,вы,скорее всего,приземлитесь в регионе,который съедает большую часть ваших циклов процессора.</target>
        </trans-unit>
        <trans-unit id="41540dddcb3ba901435fd0caa48e769fcf817d8a" translate="yes" xml:space="preserve">
          <source>If your goal is to use a profiler, use one of the suggested ones.</source>
          <target state="translated">Если ваша цель-использовать профилировщик,используйте один из предложенных.</target>
        </trans-unit>
        <trans-unit id="be4b7a0ea0d89ea3adbdc8138fbc2d0f2de5e625" translate="yes" xml:space="preserve">
          <source>In our example, outputs were for &lt;code&gt;-O0&lt;/code&gt;:</source>
          <target state="translated">В нашем примере выходные данные были для &lt;code&gt;-O0&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="431412748fb4a5baa6b65245373a7cfce7f17b4e" translate="yes" xml:space="preserve">
          <source>In this answer, I will use several different tools to a analyze a few very simple test programs, in order to concretely compare how those tools work.</source>
          <target state="translated">В этом ответе я буду использовать несколько различных инструментов для анализа нескольких очень простых тестовых программ с целью конкретного сравнения того,как эти инструменты работают.</target>
        </trans-unit>
        <trans-unit id="635f12c9ec4169045833041b2619bfd5f883a755" translate="yes" xml:space="preserve">
          <source>Intel VTune (&lt;a href=&quot;https://software.intel.com/en-us/vtune&quot;&gt;https://software.intel.com/en-us/vtune&lt;/a&gt;) - If you have intel compilers this is very good</source>
          <target state="translated">Intel VTune ( &lt;a href=&quot;https://software.intel.com/en-us/vtune&quot;&gt;https://software.intel.com/en-us/vtune&lt;/a&gt; ) - если у вас есть компиляторы Intel, это очень хорошо</target>
        </trans-unit>
        <trans-unit id="4642763219e0fa4ea52daaf7bd5c245926adf1ae" translate="yes" xml:space="preserve">
          <source>It doesn't work properly on multi-threaded code, unless you use a &lt;a href=&quot;http://sam.zoy.org/writings/programming/gprof.html&quot;&gt;workaround&lt;/a&gt;</source>
          <target state="translated">Он не работает должным образом для многопоточного кода, если вы не используете &lt;a href=&quot;http://sam.zoy.org/writings/programming/gprof.html&quot;&gt;обходной путь&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0a9760c557903dfa3fa680464b187e1b7fe3f2d6" translate="yes" xml:space="preserve">
          <source>It is a sampling profiler, along the lines of the... long... answer by Mike Dunlavey, which will gift wrap the results in a browsable call stack tree, annotated with the time or memory spent in each function, either cumulative or per-function.</source>
          <target state="translated">Это профилировщик выборки,по линии...длинного...ответа Майка Данлави,который обернет результаты в просматриваемое дерево стека вызовов,аннотированное с указанием времени или памяти,потраченной на каждую функцию,либо кумулятивную,либо на каждую функцию.</target>
        </trans-unit>
        <trans-unit id="2ba19127395eb53bf0dd24f844c9a45fd905b0fe" translate="yes" xml:space="preserve">
          <source>It says &lt;a href=&quot;http://www.cs.utah.edu/dept/old/texinfo/as/gprof.html&quot;&gt;here&lt;/a&gt; that &quot;... the number-of-calls figures are derived by counting, not sampling. They are completely accurate...&quot;. Yet I find my call graph giving me 5345859132+784984078 as call stats to my most-called function, where the first number is supposed to be direct calls, and the second recursive calls (which are all from itself). Since this implied I had a bug, I put in long (64-bit) counters into the code and did the same run again. My counts: 5345859132 direct, and 78094395406 self-recursive calls.  There are a lot of digits there, so I'll point out the recursive calls I measure are 78bn, versus 784m from Gprof: a factor of 100 different. Both runs were single threaded and unoptimised code, one compiled &lt;code&gt;-g&lt;/code&gt; and the other &lt;code&gt;-pg&lt;/code&gt;.</source>
          <target state="translated">Здесь говорится, что &amp;laquo;... цифры количества вызовов получены путем подсчета, а не выборки. Они абсолютно точны ...&amp;raquo;. Тем не менее, я нахожу свой график вызовов, показывающий мне 5345859132 + 784984078 как статистику вызовов для моей наиболее вызываемой функции, где первый номер должен быть прямым вызовом, а второй рекурсивный вызов (который все из себя). Поскольку это означало, что у меня была ошибка, я вставил в код длинные (64-битные) счетчики и повторил тот же прогон. Мои счета: 5345859132 прямых и 78094395406 саморекурсивных вызовов. Там много цифр, поэтому я укажу, что измеряемые мной рекурсивные вызовы составляют 78 млрд. Против 784 млн. Из Gprof: в 100 раз больше. Оба запуска были однопоточными и неоптимизированными, один скомпилированный &lt;code&gt;-g&lt;/code&gt; , а другой &lt;code&gt;-pg&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cb7e9d2c15a7ea8f0115ba5bd906e6333b013da" translate="yes" xml:space="preserve">
          <source>It will generate a file called &lt;code&gt;callgrind.out.x&lt;/code&gt;. You can then use &lt;code&gt;kcachegrind&lt;/code&gt; tool to read this file. It will give you a graphical analysis of things with results like which lines cost how much.</source>
          <target state="translated">Он сгенерирует файл с именем &lt;code&gt;callgrind.out.x&lt;/code&gt; . Затем вы можете использовать инструмент &lt;code&gt;kcachegrind&lt;/code&gt; для чтения этого файла. Это даст вам графический анализ вещей с результатами, например, какие строки стоят сколько.</target>
        </trans-unit>
        <trans-unit id="76e28acade3cc2a27154df90bec362b0a631dfad" translate="yes" xml:space="preserve">
          <source>It's cross-platform and allows you not to measure performance of your application also in real-time. You can even couple it with a live graph.
Full disclaimer: I am the author.</source>
          <target state="translated">Это кроссплатформенность и позволяет не измерять производительность вашего приложения также в режиме реального времени.Вы даже можете соединить его с живым графиком.Полный отказ от ответственности:Я-автор.</target>
        </trans-unit>
        <trans-unit id="4b1a94bb5d0f0a36818c07bf5e21ac7db7f6e83a" translate="yes" xml:space="preserve">
          <source>It's in C++ and must be customized to your needs. Unfortunately I can't share code, just concepts.
You use a &quot;large&quot; &lt;code&gt;volatile&lt;/code&gt; buffer containing timestamps and event ID that you can dump post mortem or after stopping the logging system (and dump this into a file for example).</source>
          <target state="translated">Он находится на C ++ и должен быть настроен в соответствии с вашими потребностями. К сожалению, я не могу поделиться кодом, только понятиями. Вы используете &amp;laquo;большой&amp;raquo; &lt;code&gt;volatile&lt;/code&gt; буфер, содержащий метки времени и идентификатор события, которые вы можете выгрузить после вскрытия или после остановки системы ведения журнала (и, например, выгрузить ее в файл).</target>
        </trans-unit>
        <trans-unit id="6866c589c53df9bdbafd58f6594aa3b9926e0556" translate="yes" xml:space="preserve">
          <source>Just halt it several times, and each time look at the call stack. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So that is roughly the percentage of samples on which you will see it. There is no educated guesswork required.
If you do have a guess as to what the problem is, this will prove or disprove it.</source>
          <target state="translated">Просто остановите его несколько раз,и каждый раз смотрите на стек вызовов.Если есть какой-то код,который тратит какой-то процент времени,20% или 50% или что-то в этом роде,то это вероятность того,что вы поймаете его в действии на каждом примере.Так что это примерно тот процент примеров,на которых вы его увидите.Нет никакой образованной догадки.Если у вас есть догадки,в чем проблема,это докажет или опровергнет ее.</target>
        </trans-unit>
        <trans-unit id="c54056bc2b49a6ba4b6c533b7638afae9a9d85da" translate="yes" xml:space="preserve">
          <source>MAP is commercial software.</source>
          <target state="translated">MAP-это коммерческое программное обеспечение.</target>
        </trans-unit>
        <trans-unit id="7f9d5d60edf957a9efb30c849d25e99af6c8e0ff" translate="yes" xml:space="preserve">
          <source>Measurement is horizontal; it tells you what fraction of time specific routines take.
Sampling is vertical.
If there is any way to avoid what the whole program is doing at that moment, &lt;em&gt;and if you see it on a second sample&lt;/em&gt;, you've found the bottleneck.
That's what makes the difference - seeing the whole reason for the time being spent, not just how much.</source>
          <target state="translated">Измерение горизонтальное; он говорит вам, какую часть времени занимают определенные подпрограммы. Выборка вертикальная. Если есть какой-либо способ избежать того, что в данный момент делает вся программа, &lt;em&gt;и если вы видите это во втором примере&lt;/em&gt; , вы нашли узкое место. Вот в чем разница - видя всю причину затраченного времени, а не только сколько.</target>
        </trans-unit>
        <trans-unit id="477fe7fb42d087f23d433845410b477d61ad6d95" translate="yes" xml:space="preserve">
          <source>N.B.</source>
          <target state="translated">N.B.</target>
        </trans-unit>
        <trans-unit id="5f635737b21ddea700a64d9ba1681ee8be0ba798" translate="yes" xml:space="preserve">
          <source>Newer kernels (e.g. the latest Ubuntu kernels) come with the new 'perf' tools (&lt;code&gt;apt-get install linux-tools&lt;/code&gt;) AKA &lt;a href=&quot;https://en.wikipedia.org/wiki/Perf_(Linux)&quot;&gt;perf_events&lt;/a&gt;.</source>
          <target state="translated">Более новые ядра (например, новейшие ядра Ubuntu) поставляются с новыми инструментами 'perf' ( &lt;code&gt;apt-get install linux-tools&lt;/code&gt; ) AKA &lt;a href=&quot;https://en.wikipedia.org/wiki/Perf_(Linux)&quot;&gt;perf_events&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="130b95199b8439c21a930c61f8c68941d88450a0" translate="yes" xml:space="preserve">
          <source>Now it says P(f &amp;gt;= 0.5) is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of &lt;code&gt;I&lt;/code&gt;. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing.</source>
          <target state="translated">Теперь он говорит, что P (f&amp;gt; = 0,5) составляет 26%, по сравнению с предыдущим предположением 0,6%. Таким образом, Байес позволяет нам обновить нашу оценку вероятной стоимости &lt;code&gt;I&lt;/code&gt; . Если объем данных невелик, он не говорит нам точно, какова стоимость, а лишь то, что он достаточно большой, чтобы его можно было исправить.</target>
        </trans-unit>
        <trans-unit id="1cc1ff9a05639f9a0179486bc64f7be0e48efc59" translate="yes" xml:space="preserve">
          <source>Now we have some files named callgrind.out.* in current directory. To see profiling results use:</source>
          <target state="translated">Теперь у нас есть несколько файлов с именем callgrind.out.*в текущем каталоге.Чтобы увидеть использование результатов профилирования:</target>
        </trans-unit>
        <trans-unit id="3440a6fe929867ee09b71eda8a51b92ff532c181" translate="yes" xml:space="preserve">
          <source>Now when it works and we want to start profiling we should run in another window:</source>
          <target state="translated">Теперь,когда это работает и мы хотим начать профилирование,мы должны запустить в другом окне:</target>
        </trans-unit>
        <trans-unit id="d3cb823c58e17cf865b583e5a20e385601ec48b1" translate="yes" xml:space="preserve">
          <source>Off the bat, &lt;code&gt;time&lt;/code&gt; tells us that the program took 29.5 seconds to execute, so we had a slowdown of about 15x on this example. Clearly, this slowdown is going to be a serious limitation for larger workloads. On the &quot;real world software example&quot; &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;mentioned here&lt;/a&gt;, I observed a slowdown of 80x.</source>
          <target state="translated">&lt;code&gt;time&lt;/code&gt; говорит нам, что выполнение программы заняло 29,5 секунды, поэтому в этом примере мы замедлились примерно в 15 раз. Понятно, что это замедление станет серьезным ограничением для больших рабочих нагрузок. На &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;упомянутом здесь&lt;/a&gt; &amp;laquo;примере программного обеспечения реального мира&amp;raquo; я заметил замедление в 80 раз.</target>
        </trans-unit>
        <trans-unit id="a2a01fb750150dbf6d32038f978233485a2955b5" translate="yes" xml:space="preserve">
          <source>On the a more complex example it becomes clear what the graph means:</source>
          <target state="translated">На более сложном примере становится понятно,что означает график:</target>
        </trans-unit>
        <trans-unit id="7ea07b1121db66a159bd732b96f60b6003126f27" translate="yes" xml:space="preserve">
          <source>Once you have understood the data output format, you can reduce verbosity to show just the data without the tutorial with the &lt;code&gt;-b&lt;/code&gt; option:</source>
          <target state="translated">Как только вы поняли формат вывода данных, вы можете уменьшить детализацию, чтобы показывать только данные без учебника, с опцией &lt;code&gt;-b&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="dbba8950c83f558b0a5b23878c05f60878612272" translate="yes" xml:space="preserve">
          <source>One cool thing about &lt;code&gt;perf&lt;/code&gt; is the FlameGraph tool from Brendan Gregg which displays the call stack timings in a very neat way that allows you to quickly see the big calls. The tool is available at: &lt;a href=&quot;https://github.com/brendangregg/FlameGraph&quot;&gt;https://github.com/brendangregg/FlameGraph&lt;/a&gt; and is also mentioned on his perf tutorial at: &lt;a href=&quot;http://www.brendangregg.com/perf.html#FlameGraphs&quot;&gt;http://www.brendangregg.com/perf.html#FlameGraphs&lt;/a&gt; When I ran &lt;code&gt;perf&lt;/code&gt; without &lt;code&gt;sudo&lt;/code&gt; I got &lt;a href=&quot;https://github.com/brendangregg/FlameGraph/issues/132&quot;&gt;&lt;code&gt;ERROR: No stack counts found&lt;/code&gt;&lt;/a&gt; so for now I'll be doing it with &lt;code&gt;sudo&lt;/code&gt;:</source>
          <target state="translated">Одна отличная вещь о &lt;code&gt;perf&lt;/code&gt; - инструмент FlameGraph от Brendan Gregg, который отображает время стека вызовов очень аккуратно, что позволяет вам быстро видеть большие вызовы. Инструмент доступен по адресу: &lt;a href=&quot;https://github.com/brendangregg/FlameGraph&quot;&gt;https://github.com/brendangregg/FlameGraph,&lt;/a&gt; а также упоминается в его руководстве по перфекту: &lt;a href=&quot;http://www.brendangregg.com/perf.html#FlameGraphs&quot;&gt;http://www.brendangregg.com/perf.html#FlameGraphs.&lt;/a&gt; Когда я запускал &lt;code&gt;perf&lt;/code&gt; без &lt;code&gt;sudo&lt;/code&gt; , я получил &lt;a href=&quot;https://github.com/brendangregg/FlameGraph/issues/132&quot;&gt; &lt;code&gt;ERROR: No stack counts found&lt;/code&gt; &lt;/a&gt; поэтому сейчас я буду делать это с помощью &lt;code&gt;sudo&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="e1e2d5fff1404430f80a9893a77239e1b369f4c6" translate="yes" xml:space="preserve">
          <source>P.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup).</source>
          <target state="translated">P.P.S Как грубое обобщение,чем больше слоев абстракции в вашем программном обеспечении,тем больше вероятность того,что вы обнаружите,что это является причиной проблем с производительностью (и возможностью получить ускорение).</target>
        </trans-unit>
        <trans-unit id="bbd10fe9dd107bcf29e061a1dbca691e2b9849ec" translate="yes" xml:space="preserve">
          <source>P.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java.</source>
          <target state="translated">P.S.Это также может быть сделано на многопоточных программах,если есть способ сбора образцов стека вызовов пула потоков в определенный момент времени,как это происходит в Java.</target>
        </trans-unit>
        <trans-unit id="4d12df151686c7a7b5c9580f37caebf54fd9c01a" translate="yes" xml:space="preserve">
          <source>Previously called &quot;Google Performance Tools&quot;, source: &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;https://github.com/gperftools/gperftools&lt;/a&gt; Sample based.</source>
          <target state="translated">Ранее назывался &amp;laquo;Инструменты повышения эффективности Google&amp;raquo;, источник: &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;https://github.com/gperftools/gperftools&lt;/a&gt; Пример на основе.</target>
        </trans-unit>
        <trans-unit id="4830d80b5bfe85f29931b456dde61e5a468406a7" translate="yes" xml:space="preserve">
          <source>Related question &lt;a href=&quot;https://stackoverflow.com/questions/56672/how-do-you-profile-your-code&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">Связанный вопрос &lt;a href=&quot;https://stackoverflow.com/questions/56672/how-do-you-profile-your-code&quot;&gt;здесь&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2577e776d1182d8b8493c8c47c6882960c233679" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;https://stackoverflow.com/questions/10874308/how-to-use-google-perf-tools&quot;&gt;How to use google perf tools&lt;/a&gt;</source>
          <target state="translated">Смотрите также: &lt;a href=&quot;https://stackoverflow.com/questions/10874308/how-to-use-google-perf-tools&quot;&gt;Как использовать Google Perf Tools&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d6bdcd52d3599e74ca39aae086a3b346358703f1" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;https://stackoverflow.com/questions/46949407/gperftools-profile-file-not-dumped&quot;&gt;gperftools - profile file not dumped&lt;/a&gt;</source>
          <target state="translated">Смотрите также: &lt;a href=&quot;https://stackoverflow.com/questions/46949407/gperftools-profile-file-not-dumped&quot;&gt;gperftools - файл профиля не выгружен&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6298bf00768899707674b3da8584b8c3f21f0334" translate="yes" xml:space="preserve">
          <source>So then I try to benchmark the &lt;code&gt;-O0&lt;/code&gt; program to see if that shows anything, and only now, at last, do I see a call graph:</source>
          <target state="translated">Затем я пытаюсь &lt;code&gt;-O0&lt;/code&gt; программу -O0, чтобы увидеть, показывает ли это что-нибудь, и только теперь, наконец, я вижу график вызовов:</target>
        </trans-unit>
        <trans-unit id="72cc02d3d1195fc59d61046450268e28e14c7f19" translate="yes" xml:space="preserve">
          <source>So this is what I recommend. Run program first:</source>
          <target state="translated">Так что вот что я рекомендую.Сначала запустите программу:</target>
        </trans-unit>
        <trans-unit id="f6772b5f69ff63328b7702c6bb60c75468582ac8" translate="yes" xml:space="preserve">
          <source>So we compile and run as:</source>
          <target state="translated">Так что мы собираем и запускаем как:</target>
        </trans-unit>
        <trans-unit id="cd0d4cbba9f07fc22442ddaca962fad827eac83d" translate="yes" xml:space="preserve">
          <source>So, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If &lt;code&gt;n&lt;/code&gt; samples are taken, and &lt;code&gt;f&lt;/code&gt; is the cost, then &lt;code&gt;I&lt;/code&gt; will appear on &lt;code&gt;nf+/-sqrt(nf(1-f))&lt;/code&gt; samples. Example, &lt;code&gt;n=10&lt;/code&gt;, &lt;code&gt;f=0.3&lt;/code&gt;, that is &lt;code&gt;3+/-1.4&lt;/code&gt; samples.)</source>
          <target state="translated">Таким образом, даже очень небольшое количество образцов может многое сказать нам о стоимости инструкций, которые он видит. (И он будет видеть их с частотой, в среднем, пропорциональной их стоимости. Если будет взято &lt;code&gt;n&lt;/code&gt; выборок, а &lt;code&gt;f&lt;/code&gt; - это стоимость, то &lt;code&gt;I&lt;/code&gt; появлюсь на &lt;code&gt;nf+/-sqrt(nf(1-f))&lt;/code&gt; выборках. Пример , &lt;code&gt;n=10&lt;/code&gt; , &lt;code&gt;f=0.3&lt;/code&gt; , то есть &lt;code&gt;3+/-1.4&lt;/code&gt; образца.)</target>
        </trans-unit>
        <trans-unit id="08239f177013e0b069b1f213aca8eed8d3e8fd03" translate="yes" xml:space="preserve">
          <source>Suppose the prior assumptions are different. Suppose we assume P(f=0.1) is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that &lt;code&gt;I&lt;/code&gt; is cheap. Then we get:</source>
          <target state="translated">Предположим, что предыдущие предположения разные. Предположим, мы предполагаем, что P (f = 0,1) равно 0,991 (почти наверняка), а все остальные возможности практически невозможны (0,001). Другими словами, наша предварительная уверенность в том, что &lt;code&gt;I&lt;/code&gt; дешев. Тогда мы получим:</target>
        </trans-unit>
        <trans-unit id="d3b210cd62d3d15648f1f008cbd6a6ff99536cd2" translate="yes" xml:space="preserve">
          <source>TAU (&lt;a href=&quot;http://www.cs.uoregon.edu/research/tau/home.php&quot;&gt;http://www.cs.uoregon.edu/research/tau/home.php&lt;/a&gt;)</source>
          <target state="translated">TAU ( &lt;a href=&quot;http://www.cs.uoregon.edu/research/tau/home.php&quot;&gt;http://www.cs.uoregon.edu/research/tau/home.php&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="ed5f5a3f654a364aa389b4161a87b5a87e7b8ec1" translate="yes" xml:space="preserve">
          <source>TODO on complex C++ software, I see some entries of type &lt;code&gt;&amp;lt;cycle N&amp;gt;&lt;/code&gt;, e.g. &lt;code&gt;&amp;lt;cycle 11&amp;gt;&lt;/code&gt; where I'd expect function names, what does that mean? I noticed there is a &quot;Cycle Detection&quot; button to toggle that on and off, but what does it mean?</source>
          <target state="translated">В TODO на сложном программном обеспечении C ++ я вижу некоторые записи типа &lt;code&gt;&amp;lt;cycle N&amp;gt;&lt;/code&gt; , например, &lt;code&gt;&amp;lt;cycle 11&amp;gt;&lt;/code&gt; где я ожидал бы имена функций, что это значит? Я заметил, что есть кнопка &amp;laquo;Обнаружение цикла&amp;raquo; для включения и выключения, но что это значит?</target>
        </trans-unit>
        <trans-unit id="b13a96071f0d7fdcbc2465e3e45593db4c6ebbfd" translate="yes" xml:space="preserve">
          <source>TODO there are a log of &lt;code&gt;[unknown]&lt;/code&gt; functions in that example, why is that?</source>
          <target state="translated">В этом примере есть журнал &lt;code&gt;[unknown]&lt;/code&gt; функций, почему?</target>
        </trans-unit>
        <trans-unit id="a19af3eb40fbc53ad472e0220f8b098385c16862" translate="yes" xml:space="preserve">
          <source>TODO: what happened on the &lt;code&gt;-O3&lt;/code&gt; execution? Is it simply that &lt;code&gt;maybe_slow&lt;/code&gt; and &lt;code&gt;fast&lt;/code&gt; were too fast and did not get any samples? Does it work well with &lt;code&gt;-O3&lt;/code&gt; on larger programs that take longer to execute? Did I miss some CLI option? I found out about &lt;code&gt;-F&lt;/code&gt; to control the sample frequency in Hertz, but I turned it up to the max allowed by default of &lt;code&gt;-F 39500&lt;/code&gt; (could be increased with &lt;code&gt;sudo&lt;/code&gt;) and I still don't see clear calls.</source>
          <target state="translated">ТОДО: что случилось с казнью &lt;code&gt;-O3&lt;/code&gt; ? Это просто, что &lt;code&gt;maybe_slow&lt;/code&gt; , медленный и &lt;code&gt;fast&lt;/code&gt; были слишком быстрыми и не получили никаких образцов? Хорошо ли работает с &lt;code&gt;-O3&lt;/code&gt; в больших программах, выполнение которых занимает больше времени? Я пропустил какой-то вариант CLI? Я узнал о &lt;code&gt;-F&lt;/code&gt; для управления частотой дискретизации в герцах, но я поднял ее до максимально допустимого значения по умолчанию &lt;code&gt;-F 39500&lt;/code&gt; (может быть увеличено с помощью &lt;code&gt;sudo&lt;/code&gt; ), и я до сих пор не вижу четких вызовов.</target>
        </trans-unit>
        <trans-unit id="6dc4e6a8f235d6662619c2b13f904dd1fd3359cb" translate="yes" xml:space="preserve">
          <source>TODO: why is &lt;code&gt;main&lt;/code&gt; missing from the &lt;code&gt;-O3&lt;/code&gt; output, even though I can see it on a &lt;code&gt;bt&lt;/code&gt; in GDB? &lt;a href=&quot;https://stackoverflow.com/questions/39041871/missing-function-from-gprof-output&quot;&gt;Missing function from GProf output&lt;/a&gt; I think it is because gprof is also sampling based in addition to its compiled instrumentation, and the &lt;code&gt;-O3&lt;/code&gt;&lt;code&gt;main&lt;/code&gt; is just too fast and got no samples.</source>
          <target state="translated">TODO: почему &lt;code&gt;main&lt;/code&gt; вывод отсутствует в выводе &lt;code&gt;-O3&lt;/code&gt; , хотя я вижу его на &lt;code&gt;bt&lt;/code&gt; в GDB? &lt;a href=&quot;https://stackoverflow.com/questions/39041871/missing-function-from-gprof-output&quot;&gt;Пропущенная функция из вывода GProf&lt;/a&gt; Я думаю, это потому, что gprof также использует сэмплирование в дополнение к скомпилированному инструментарию, а &lt;code&gt;main&lt;/code&gt; &lt;code&gt;-O3&lt;/code&gt; слишком быстр и не имеет сэмплов.</target>
        </trans-unit>
        <trans-unit id="6e53b60f1e0dfa855a4eef9b666d7279dabbee1a" translate="yes" xml:space="preserve">
          <source>Tested in Ubuntu 18.04, gprof2dot 2019.11.30, valgrind 3.13.0, perf 4.15.18, Linux kernel 4.15.0, FLameGraph 1a0dc6985aad06e76857cf2a354bd5ba0c9ce96b, gperftools 2.5-2.</source>
          <target state="translated">Протестировано в Ubuntu 18.04,gprof2dot 2019.11.30,valgrind 3.13.0,perf 4.15.18,ядро Linux 4.15.0,FLameGraph 1a0dc6985aad06e76857cf2a354bd5ba0c9ce96b,gperftools 2.5-2.</target>
        </trans-unit>
        <trans-unit id="3a80a1a4fbc3469221b7d5afd5713915cd326c8f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;-O0&lt;/code&gt; output is pretty much self-explanatory. For example, it shows that the 3 &lt;code&gt;maybe_slow&lt;/code&gt; calls and their child calls take up 97.56% of the total runtime, although execution of &lt;code&gt;maybe_slow&lt;/code&gt; itself without children accounts for 0.00% of the total execution time, i.e. almost all the time spent in that function was spent on child calls.</source>
          <target state="translated">Вывод &lt;code&gt;-O0&lt;/code&gt; в значительной степени говорит само за себя. Например, это показывает, что 3 &lt;code&gt;maybe_slow&lt;/code&gt; и их дочерние вызовы занимают 97,56% от общего времени выполнения, хотя выполнение самого &lt;code&gt;maybe_slow&lt;/code&gt; без дочерних элементов составляет 0,00% от общего времени выполнения, то есть почти все время, потраченное в этой функции, было потратил на детские звонки.</target>
        </trans-unit>
        <trans-unit id="e42365e1a6bff7fc2be05d355cadfefbdf5ea497" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;probe&lt;/code&gt; function uses a few assembly lines to retrieve the clock timestamp ASAP and then sets an entry in the buffer. We also have an atomic increment to safely find an index where to store the log event.
Of course buffer is circular.</source>
          <target state="translated">Функция &lt;code&gt;probe&lt;/code&gt; использует несколько сборочных линий для получения метки времени часов как можно скорее, а затем устанавливает запись в буфере. У нас также есть атомарный инкремент, чтобы безопасно найти индекс, где хранить событие журнала. Конечно, буфер является круглым.</target>
        </trans-unit>
        <trans-unit id="f1066d2d94872d1ccbce2036cf5aac073098024e" translate="yes" xml:space="preserve">
          <source>The answer to run &lt;code&gt;valgrind --tool=callgrind&lt;/code&gt; is not quite complete without some options. We usually do not want to profile 10 minutes of slow startup time under Valgrind and want to profile our program when it is doing some task.</source>
          <target state="translated">Ответ для запуска &lt;code&gt;valgrind --tool=callgrind&lt;/code&gt; не является полным без некоторых опций. Мы обычно не хотим профилировать 10 минут медленного запуска в Valgrind и хотим профилировать нашу программу, когда она выполняет какую-то задачу.</target>
        </trans-unit>
        <trans-unit id="36529a459a19fd1c86e51be05eccbd6859fb938f" translate="yes" xml:space="preserve">
          <source>The call graph gets confused by function pointers. Example: I have a function called &lt;code&gt;multithread()&lt;/code&gt; which enables me to multi-thread a specified function over a specified array (both passed as arguments). Gprof however, views all calls to &lt;code&gt;multithread()&lt;/code&gt; as equivalent for the purposes of computing time spent in children. Since some functions I pass to &lt;code&gt;multithread()&lt;/code&gt; take much longer than others my call graphs are mostly useless. (To those wondering if threading is the issue here: no, &lt;code&gt;multithread()&lt;/code&gt; can optionally, and did in this case, run everything sequentially on the calling thread only).</source>
          <target state="translated">Граф вызовов запутывается указателями на функции. Пример: у меня есть функция &lt;code&gt;multithread()&lt;/code&gt; которая позволяет мне выполнять многопоточность указанной функции по указанному массиву (оба передаются в качестве аргументов). Однако Gprof рассматривает все вызовы функции &lt;code&gt;multithread()&lt;/code&gt; как эквивалентные для вычисления времени, проводимого у детей. Поскольку некоторые функции, которые я &lt;code&gt;multithread()&lt;/code&gt; функции multithread (), занимают намного больше времени, чем другие, мои графы вызовов в основном бесполезны. (Для тех, кто интересуется, является ли здесь проблема с &lt;code&gt;multithread()&lt;/code&gt; : нет, функция multithread () может, и в этом случае выполняла все последовательно только в вызывающем потоке).</target>
        </trans-unit>
        <trans-unit id="a13b1906e442733e77eedc379dcc29d514b536bc" translate="yes" xml:space="preserve">
          <source>The concept is to define events in &lt;code&gt;tool_events_id.hpp&lt;/code&gt; like that :</source>
          <target state="translated">Идея состоит в том, чтобы определить события в &lt;code&gt;tool_events_id.hpp&lt;/code&gt; следующим образом:</target>
        </trans-unit>
        <trans-unit id="cdbc70168923d9d12dc32d25f0bf32b6568e5382" translate="yes" xml:space="preserve">
          <source>The downside of this is that there seems to be no Ubuntu package, and building it requires Qt 5.10 while Ubuntu 18.04 is at Qt 5.9.</source>
          <target state="translated">Недостатком является то,что,похоже,не существует пакета Ubuntu,и для его сборки требуется Qt 5.10,в то время как Ubuntu 18.04 находится на Qt 5.9.</target>
        </trans-unit>
        <trans-unit id="9b0a146d516aab93931f86859127170f3626293f" translate="yes" xml:space="preserve">
          <source>The following test program is very simple and does the following:</source>
          <target state="translated">Следующая тестовая программа очень проста и делает следующее:</target>
        </trans-unit>
        <trans-unit id="c15b8d0e65310a3d3e9195caeac933a4e6e84c5b" translate="yes" xml:space="preserve">
          <source>The important thing is that these tools can be &lt;strong&gt;system profiling&lt;/strong&gt; and not just process profiling - they can show the interaction between threads, processes and the kernel and let you understand the scheduling and I/O dependencies between processes.</source>
          <target state="translated">Важно то, что эти инструменты могут быть &lt;strong&gt;профилированием системы,&lt;/strong&gt; а не просто профилированием процесса - они могут показать взаимодействие между потоками, процессами и ядром и позволить вам понять зависимости планирования и ввода-вывода между процессами.</target>
        </trans-unit>
        <trans-unit id="b0d289675b93f88ef384de46c84952610710e353" translate="yes" xml:space="preserve">
          <source>The last column says that, for example, the probability that &lt;code&gt;f&lt;/code&gt; &amp;gt;= 0.5 is 92%, up from the prior assumption of 60%.</source>
          <target state="translated">В последнем столбце говорится, что, например, вероятность того, что &lt;code&gt;f&lt;/code&gt; &amp;gt; = 0,5, составляет 92%, по сравнению с предыдущим предположением 60%.</target>
        </trans-unit>
        <trans-unit id="627640c346afb672f5025becd9584112a15ea55e" translate="yes" xml:space="preserve">
          <source>The nicest way to view this data I've found so far is to make pprof output the same format that kcachegrind takes as input (yes, the Valgrind-project-viewer-tool) and use kcachegrind to view that:</source>
          <target state="translated">Самый приятный способ просмотра этих данных,который я нашел на данный момент,это заставить pprof выводить данные в том же формате,что и kcachegrind (да,Valgrind-project-viewer-tool),и использовать kcachegrind для просмотра этих данных:</target>
        </trans-unit>
        <trans-unit id="23eff0579ea840d749f7dacd94ef9acf84a98ca9" translate="yes" xml:space="preserve">
          <source>The program interface is:</source>
          <target state="translated">Интерфейс программы:</target>
        </trans-unit>
        <trans-unit id="19c4249e44db6d866c57af334d73685ec61d153c" translate="yes" xml:space="preserve">
          <source>The run generates a profile data file named &lt;code&gt;callgrind.out.&amp;lt;pid&amp;gt;&lt;/code&gt; e.g. &lt;code&gt;callgrind.out.8554&lt;/code&gt; in my case. We view that file with:</source>
          <target state="translated">При запуске создается файл данных профиля с именем &lt;code&gt;callgrind.out.&amp;lt;pid&amp;gt;&lt;/code&gt; например, &lt;code&gt;callgrind.out.8554&lt;/code&gt; в моем случае. Мы просматриваем этот файл с:</target>
        </trans-unit>
        <trans-unit id="ed9bf7107eccd71620c4c6d6bab4692580d8a7db" translate="yes" xml:space="preserve">
          <source>The slow call of &lt;code&gt;maybe_slow&lt;/code&gt; is 10x longer, and dominates runtime if we consider calls to the child function &lt;code&gt;common&lt;/code&gt;. Ideally, the profiling tool will be able to point us to the specific slow call.</source>
          <target state="translated">Медленный вызов &lt;code&gt;maybe_slow&lt;/code&gt; в 10 раз длиннее и доминирует во время выполнения, если мы считаем вызовы дочерней функции &lt;code&gt;common&lt;/code&gt; . В идеале, инструмент профилирования сможет указать нам на конкретный медленный вызов.</target>
        </trans-unit>
        <trans-unit id="b6c8bf98ecf41059e3237cb533da10773d9fb4c5" translate="yes" xml:space="preserve">
          <source>The source for gprof2dot is at: &lt;a href=&quot;https://github.com/jrfonseca/gprof2dot&quot;&gt;https://github.com/jrfonseca/gprof2dot&lt;/a&gt;</source>
          <target state="translated">Источник для gprof2dot находится по адресу: &lt;a href=&quot;https://github.com/jrfonseca/gprof2dot&quot;&gt;https://github.com/jrfonseca/gprof2dot&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="769adfccf68fa21aab6b3394b205656f5dab0061" translate="yes" xml:space="preserve">
          <source>Then suppose we take just 2 stack samples, and we see instruction &lt;code&gt;I&lt;/code&gt; on both samples, designated observation &lt;code&gt;o=2/2&lt;/code&gt;. This gives us new estimates of the frequency &lt;code&gt;f&lt;/code&gt; of &lt;code&gt;I&lt;/code&gt;, according to this:</source>
          <target state="translated">Затем предположим, что мы берем только 2 выборки стека и видим инструкцию &lt;code&gt;I&lt;/code&gt; для обеих выборок, обозначенную наблюдением &lt;code&gt;o=2/2&lt;/code&gt; . Это дает нам новые оценки частоты &lt;code&gt;f&lt;/code&gt; &lt;code&gt;I&lt;/code&gt; , согласно этому:</target>
        </trans-unit>
        <trans-unit id="7291eec49875f5d9df200c27efdf4f591116af3f" translate="yes" xml:space="preserve">
          <source>Then switch to RELEASE mode and comment out the questionable sections of your code (stub it with nothing) until you see changes in performance.</source>
          <target state="translated">Затем переключитесь в режим RELEASE и прокомментируйте сомнительные разделы вашего кода (завяжите его ни с чем),пока не увидите изменений в производительности.</target>
        </trans-unit>
        <trans-unit id="2e742db948961b9c3cb6ead916f107d3e8dda15c" translate="yes" xml:space="preserve">
          <source>Then, we can enable the gperftools CPU profiler in two ways: at runtime, or at build time.</source>
          <target state="translated">Затем мы можем включить профилировщик процессора gperftools двумя способами:во время выполнения или во время сборки.</target>
        </trans-unit>
        <trans-unit id="924edd37a29a71ab9fe4c8baa007eb8497e44c49" translate="yes" xml:space="preserve">
          <source>There are profilers now that sample the stack, even on wall-clock time, but &lt;em&gt;what comes out&lt;/em&gt; is measurements (or hot path, or hot spot, from which a &quot;bottleneck&quot; can easily hide). What they don't show you (and they easily could) is the actual samples themselves. And if your goal is to &lt;em&gt;find&lt;/em&gt; the bottleneck, the number of them you need to see is, &lt;em&gt;on average&lt;/em&gt;, 2 divided by the fraction of time it takes.
So if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%.</source>
          <target state="translated">Сейчас есть профилировщики, которые производят выборку стека, даже по времени настенных часов, но в результате получаются измерения (или &amp;laquo;горячая дорожка&amp;raquo;, или &amp;laquo;горячая точка&amp;raquo;, от которой &amp;laquo;узкое место&amp;raquo; может легко скрыться). То, что они вам не показывают (и они легко могут), это сами образцы. И если ваша цель - &lt;em&gt;найти&lt;/em&gt; узкие места, то количество их, которое вам нужно увидеть, &lt;em&gt;в среднем&lt;/em&gt; равно 2, деленному на долю времени, которое требуется. Таким образом, если это займет 30% времени, 2 / .3 = 6,7 выборки в среднем покажут это, и вероятность того, что 20 выборок покажет это, составляет 99,2%.</target>
        </trans-unit>
        <trans-unit id="7e09a7534638018a7af14062b8d9c917ce457a53" translate="yes" xml:space="preserve">
          <source>There is two different type of profiling</source>
          <target state="translated">Существует два различных типа профилирования</target>
        </trans-unit>
        <trans-unit id="571edc923bc5a6cee4f85a019f1c49bdbbf47a9d" translate="yes" xml:space="preserve">
          <source>These are the two methods I use for speeding up my code:</source>
          <target state="translated">Это два метода,которые я использую для ускорения своего кода:</target>
        </trans-unit>
        <trans-unit id="8311f0252f91f1308742d21d20d0472314d898dd" translate="yes" xml:space="preserve">
          <source>These come with classic sampling profilers (&lt;a href=&quot;http://manpages.ubuntu.com/manpages/trusty/man1/perf.1.html&quot;&gt;man-page&lt;/a&gt;) as well as the awesome &lt;a href=&quot;http://web.archive.org/web/20090922171904/http://blog.fenrus.org/?p=5&quot;&gt;timechart&lt;/a&gt;!</source>
          <target state="translated">Они идут с классическими профилировщиками сэмплирования ( &lt;a href=&quot;http://manpages.ubuntu.com/manpages/trusty/man1/perf.1.html&quot;&gt;man-page&lt;/a&gt; ), а также с &lt;a href=&quot;http://web.archive.org/web/20090922171904/http://blog.fenrus.org/?p=5&quot;&gt;отличной временной диаграммой&lt;/a&gt; !</target>
        </trans-unit>
        <trans-unit id="e0c6e507414a31dbfe361257f83996883b16fb14" translate="yes" xml:space="preserve">
          <source>They will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find.
They will say it sometimes finds things that aren't problems, but that is only true if you see something &lt;em&gt;once&lt;/em&gt;. If you see a problem on more than one sample, it is real.</source>
          <target state="translated">Они также скажут, что он работает только на игрушечных программах, когда на самом деле он работает на любой программе, и кажется, что он лучше работает на больших программах, потому что у них, как правило, больше проблем для поиска. Они скажут, что иногда он находит вещи, которые не являются проблемами, но это правда, если вы видите что-то &lt;em&gt;один раз&lt;/em&gt; . Если вы видите проблему более чем на одном образце, это реально.</target>
        </trans-unit>
        <trans-unit id="83b6b75b50c6b06f6bb30d23afad367e7399b38c" translate="yes" xml:space="preserve">
          <source>This added 0.2s to execution, so we are fine time-wise, but I still don't see much of interest, after expanding the &lt;code&gt;common&lt;/code&gt; node with the keyboard right arrow:</source>
          <target state="translated">Это добавило 0,2 с к исполнению, поэтому у нас все хорошо, но я все еще не вижу особого интереса после расширения &lt;code&gt;common&lt;/code&gt; узла с помощью стрелки вправо на клавиатуре:</target>
        </trans-unit>
        <trans-unit id="6b876e96a3c3578737d673685356fe1f9dcb0ab6" translate="yes" xml:space="preserve">
          <source>This is a response to &lt;a href=&quot;https://stackoverflow.com/a/375930/321731&quot;&gt;Nazgob's Gprof answer&lt;/a&gt;.</source>
          <target state="translated">Это ответ на ответ &lt;a href=&quot;https://stackoverflow.com/a/375930/321731&quot;&gt;Назгоба от Gprof&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b830cecda0a3aff113570c5b101b80608993a7f6" translate="yes" xml:space="preserve">
          <source>This turns profiling on. To turn it off and stop whole task we might use:</source>
          <target state="translated">Это включает профилирование.Чтобы выключить его и остановить всю задачу,которую мы можем использовать:</target>
        </trans-unit>
        <trans-unit id="ae3ef8d5cd3e8ccedaacfb1558e954d08cae24db" translate="yes" xml:space="preserve">
          <source>This was GNU &lt;a href=&quot;https://en.wikipedia.org/wiki/Gprof&quot;&gt;Gprof&lt;/a&gt; (GNU Binutils for Debian) 2.18.0.20080103 running under 64-bit Debian Lenny, if that helps anyone.</source>
          <target state="translated">Это был GNU &lt;a href=&quot;https://en.wikipedia.org/wiki/Gprof&quot;&gt;Gprof&lt;/a&gt; (GNU Binutils для Debian) 2.18.0.20080103, работающий под 64-битным Debian Lenny, если это кому-нибудь поможет.</target>
        </trans-unit>
        <trans-unit id="4809190e35f35121b8cef92d7260543e2698ad83" translate="yes" xml:space="preserve">
          <source>To get more info you can look in &lt;a href=&quot;https://sourceware.org/binutils/docs-2.32/gprof/&quot;&gt;https://sourceware.org/binutils/docs-2.32/gprof/&lt;/a&gt;</source>
          <target state="translated">Чтобы получить больше информации вы можете посмотреть в &lt;a href=&quot;https://sourceware.org/binutils/docs-2.32/gprof/&quot;&gt;https://sourceware.org/binutils/docs-2.32/gprof/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d1e75d21749779f1783a936e0318ab574c9bb06" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;-pg&lt;/code&gt; flag when compiling and linking the code and run the executable file. While this program is executed, profiling data is collected in the file a.out.</source>
          <target state="translated">Используйте флаг &lt;code&gt;-pg&lt;/code&gt; при компиляции и компоновке кода и запустите исполняемый файл. Во время выполнения этой программы данные профилирования собираются в файле a.out.</target>
        </trans-unit>
        <trans-unit id="74fa418da05131589c58de20bc5cd8a74884137e" translate="yes" xml:space="preserve">
          <source>Use a profiler in DEBUG mode to identify questionable parts of your code</source>
          <target state="translated">Используйте профилировщик в DEBUG-режиме для идентификации сомнительных частей кода.</target>
        </trans-unit>
        <trans-unit id="5abe91df474f47b2ce52602a8d2c9a1a1dc9bcdb" translate="yes" xml:space="preserve">
          <source>Use a profiler in RELEASE mode to identify questionable parts of your code.</source>
          <target state="translated">Используйте профилировщик в режиме RELEASE для идентификации сомнительных частей кода.</target>
        </trans-unit>
        <trans-unit id="47e2b39318441908a26389043c5f493a08f3da25" translate="yes" xml:space="preserve">
          <source>Uses time sampling, I/O and CPU bottlenecks are revealed.</source>
          <target state="translated">Выявлены узкие места в использовании временной выборки,ввода-вывода и процессора.</target>
        </trans-unit>
        <trans-unit id="32ebf48279743cab72d7ff1b43c30c357fa0b5af" translate="yes" xml:space="preserve">
          <source>View gprof output in kcachegrind</source>
          <target state="translated">Просмотр gprof-выдачи в ккеш-машине</target>
        </trans-unit>
        <trans-unit id="90e10e752882a92276f4abc5b712de714bd30e0f" translate="yes" xml:space="preserve">
          <source>We can observe that file graphically with &lt;code&gt;gprof2dot&lt;/code&gt; as asked at: &lt;a href=&quot;https://stackoverflow.com/questions/2439060/is-it-possible-to-get-a-graphical-representation-of-gprof-results&quot;&gt;Is it possible to get a graphical representation of gprof results?&lt;/a&gt;</source>
          <target state="translated">Мы можем наблюдать этот файл графически с помощью &lt;code&gt;gprof2dot&lt;/code&gt; , как это было задано в разделе : &lt;a href=&quot;https://stackoverflow.com/questions/2439060/is-it-possible-to-get-a-graphical-representation-of-gprof-results&quot;&gt;Возможно ли получить графическое представление результатов gprof?&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10445757607ecf8a1d5924c1e702bf14a1ff75d2" translate="yes" xml:space="preserve">
          <source>We observe the following for the &lt;code&gt;-O0&lt;/code&gt; run:</source>
          <target state="translated">&lt;code&gt;-O0&lt;/code&gt; запуска -O0 мы наблюдаем следующее:</target>
        </trans-unit>
        <trans-unit id="9844986bd80729d071e13db938133404d11ba09f" translate="yes" xml:space="preserve">
          <source>Wherever in you code you can use :</source>
          <target state="translated">Где бы в вашем коде вы ни использовали :</target>
        </trans-unit>
        <trans-unit id="674dfbcd4d095f0cd2550aa16069c396575c13ec" translate="yes" xml:space="preserve">
          <source>Which is the best replacement for KProf?</source>
          <target state="translated">Какая из них является лучшей заменой для KProf?</target>
        </trans-unit>
        <trans-unit id="9f5da50867e51ac3a771fd9c2dea086874d61262" translate="yes" xml:space="preserve">
          <source>Yet another way to look at it is called the &lt;a href=&quot;http://en.wikipedia.org/wiki/Rule_of_succession&quot;&gt;Rule Of Succession&lt;/a&gt;.
If you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin?
The respected way to answer is to say that it's a Beta distribution, with average value (number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%.</source>
          <target state="translated">Еще один способ взглянуть на это называется &lt;a href=&quot;http://en.wikipedia.org/wiki/Rule_of_succession&quot;&gt;Правило наследования&lt;/a&gt; . Если вы подбрасываете монету 2 раза, и она выпадает в голову оба раза, что это говорит вам о вероятном весе монеты? Уважаемый способ ответить на этот вопрос - сказать, что это бета-распределение со средним значением (количество попаданий + 1) / (количество попыток + 2) = (2 + 1) / (2 + 2) = 75%.</target>
        </trans-unit>
        <trans-unit id="e477d44b67435b4f2a51bec584b8c8b5c70e29d8" translate="yes" xml:space="preserve">
          <source>You also define a few functions in &lt;code&gt;toolname.hpp&lt;/code&gt; :</source>
          <target state="translated">Вы также определяете несколько функций в &lt;code&gt;toolname.hpp&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="d06ead62c5754d4f55d6c94097738323320c25d0" translate="yes" xml:space="preserve">
          <source>You can however use the color map to mitigate those problems a bit. For example, on the previous huge image, I finally managed to find the critical path on the left when I made the brilliant deduction that green comes after red, followed finally by darker and darker blue.</source>
          <target state="translated">Однако вы можете использовать цветную карту,чтобы немного смягчить эти проблемы.Например,на предыдущем огромном изображении,мне наконец-то удалось найти критический путь слева,когда я сделал блестящую дедукцию,что зеленый идет после красного,а затем,наконец,более темный и темно-синий.</target>
        </trans-unit>
        <trans-unit id="ff319bc3545afd5e52b97cb66321e2f3c78b6c30" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt; with the following options</source>
          <target state="translated">Вы можете использовать &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt; со следующими опциями</target>
        </trans-unit>
        <trans-unit id="eff4537042a246b1bfc5a7ac9053825ab352cfb3" translate="yes" xml:space="preserve">
          <source>You can use a logging framework like &lt;a href=&quot;https://github.com/emilk/loguru&quot;&gt;&lt;code&gt;loguru&lt;/code&gt;&lt;/a&gt; since it includes timestamps and total uptime which can be used nicely for profiling:</source>
          <target state="translated">Вы можете использовать каркас журналирования, такой как &lt;a href=&quot;https://github.com/emilk/loguru&quot;&gt; &lt;code&gt;loguru&lt;/code&gt; ,&lt;/a&gt; так как он включает метки времени и общее время безотказной работы, которые можно использовать для профилирования:</target>
        </trans-unit>
        <trans-unit id="57bb7c327c284cab00d7dbfef1ffa24df1be7086" translate="yes" xml:space="preserve">
          <source>You can use the iprof library:</source>
          <target state="translated">Вы можете использовать библиотеку iprof:</target>
        </trans-unit>
        <trans-unit id="09eee30b7f6c8d8c09d32bfa040a796ee7c00fe5" translate="yes" xml:space="preserve">
          <source>You customize the amount of events generated to focus solely on what you desire. It helped us a lot for scheduling issues while consuming the amount of CPU we wanted based on the amount of logged events per second.</source>
          <target state="translated">Вы настраиваете количество генерируемых событий,чтобы сконцентрироваться исключительно на том,что вы хотите.Это очень помогло нам в планировании проблем при потреблении нужного нам количества процессора,исходя из количества регистрируемых событий в секунду.</target>
        </trans-unit>
        <trans-unit id="5885a798125a50436ce410ba3e52f4fbdf4173ce" translate="yes" xml:space="preserve">
          <source>You may have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes.
This &lt;em&gt;magnification effect&lt;/em&gt;, when compounded over multiple problems, can lead to truly massive speedup factors.</source>
          <target state="translated">У вас может быть несколько проблем с производительностью разных размеров. Если вы уберете какой-либо из них, остальные будут занимать больший процент, и их будет легче обнаружить при последующих проходах. Этот &lt;em&gt;эффект увеличения в&lt;/em&gt; сочетании с несколькими проблемами может привести к действительно огромным факторам ускорения.</target>
        </trans-unit>
        <trans-unit id="016b297a8bba32365f38f766a39676ea6cbcfd2b" translate="yes" xml:space="preserve">
          <source>You need 3 files :</source>
          <target state="translated">Вам нужно 3 файла :</target>
        </trans-unit>
        <trans-unit id="747c3ce81ca5b275ec245943d96de7239bf6b766" translate="yes" xml:space="preserve">
          <source>You retrieve the so-called large buffer with all the data and a small interface parses it and shows events with name (up/down + value) like an oscilloscope does with colors (configured in &lt;code&gt;.hpp&lt;/code&gt; file).</source>
          <target state="translated">Вы получаете так называемый большой буфер со всеми данными, а небольшой интерфейс анализирует его и показывает события с именем (вверх / вниз + значение), как осциллограф с цветами (настроенный в файле &lt;code&gt;.hpp&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="2922e093bcf4e627dba20bdf0f73a9644a37a709" translate="yes" xml:space="preserve">
          <source>and for &lt;code&gt;-O3&lt;/code&gt;:</source>
          <target state="translated">и для &lt;code&gt;-O3&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="2a5be5a09792a69cac7d084de41932a15ba3728f" translate="yes" xml:space="preserve">
          <source>and for the &lt;code&gt;-O3&lt;/code&gt; run:</source>
          <target state="translated">и для запуска &lt;code&gt;-O3&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="faa969782037f341d207ee39f51209d6317fc20e" translate="yes" xml:space="preserve">
          <source>and the program does &lt;code&gt;O(n^2)&lt;/code&gt; loops in total. &lt;code&gt;seed&lt;/code&gt; is just to get different output without affecting runtime.</source>
          <target state="translated">и программа делает &lt;code&gt;O(n^2)&lt;/code&gt; циклов в общей сложности. &lt;code&gt;seed&lt;/code&gt; - это просто получить другой вывод, не влияя на время выполнения.</target>
        </trans-unit>
        <trans-unit id="ce2455b67d76414f51f9fe06a8ce80817a3d7dbb" translate="yes" xml:space="preserve">
          <source>are there locks that are proving to be bottle necks ?</source>
          <target state="translated">Есть ли замки,которые доказывают,что это бутылочные горлышки?</target>
        </trans-unit>
        <trans-unit id="a6f071b118d3c8c52f2a76d5173897fc74f14d94" translate="yes" xml:space="preserve">
          <source>both &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;maybe_slow&lt;/code&gt; call &lt;code&gt;common&lt;/code&gt;, which accounts for the bulk of the program execution</source>
          <target state="translated">и &lt;code&gt;fast&lt;/code&gt; и может быть &lt;code&gt;maybe_slow&lt;/code&gt; , который составляет основную часть выполнения программы</target>
        </trans-unit>
        <trans-unit id="9684498d10b2a6f3e91e84082350f59fe31df044" translate="yes" xml:space="preserve">
          <source>but even then, you will be dragging the image around a lot to find what you want, see e.g. this image from a &quot;real&quot; software example taken from &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;this ticket&lt;/a&gt;:</source>
          <target state="translated">но даже тогда вы будете перетаскивать изображение вокруг, чтобы найти то, что вы хотите, например, посмотрите это изображение из &amp;laquo;реального&amp;raquo; примера программного обеспечения, взятого из &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;этого билета&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="3af4c4be531f706f742d60135390bd70be4af5f9" translate="yes" xml:space="preserve">
          <source>but in such a simple program the output is not very easy to understand, since we can't easily see neither &lt;code&gt;maybe_slow&lt;/code&gt; nor &lt;code&gt;fast&lt;/code&gt; on that graph:</source>
          <target state="translated">но в такой простой программе вывод не очень прост для понимания, так как мы не можем легко увидеть ни &lt;code&gt;maybe_slow&lt;/code&gt; ни медленный, ни &lt;code&gt;fast&lt;/code&gt; на этом графике:</target>
        </trans-unit>
        <trans-unit id="a7dd0b976062c449381eb00b3b4071e2c243cb98" translate="yes" xml:space="preserve">
          <source>by running the command &lt;code&gt;gprog --flat-profile a.out&lt;/code&gt; you got the following data</source>
          <target state="translated">запустив команду &lt;code&gt;gprog --flat-profile a.out&lt;/code&gt; , вы получите следующие данные</target>
        </trans-unit>
        <trans-unit id="4ad25e6079270f854bc1ab4b0f5c15dda777da63" translate="yes" xml:space="preserve">
          <source>callgrind is the valgrind's tool to profile code and kcachegrind is a KDE program that can visualize cachegrind output.</source>
          <target state="translated">callgrind-это инструмент valgrind для профилирования кода,а kcachegrind-это программа KDE,которая может визуализировать вывод cachegrind.</target>
        </trans-unit>
        <trans-unit id="fdde301a4277b76ba71eeffc0b565064e8e3eb36" translate="yes" xml:space="preserve">
          <source>centers around the function that is left indented (&lt;code&gt;maybe_flow&lt;/code&gt;). &lt;code&gt;[3]&lt;/code&gt; is the ID of that function. Above the function, are its callers, and below it the callees.</source>
          <target state="translated">центрируется вокруг функции, которая имеет отступ ( &lt;code&gt;maybe_flow&lt;/code&gt; ). &lt;code&gt;[3]&lt;/code&gt; это идентификатор этой функции. Над функцией находятся ее вызывающие, а ниже - вызываемые.</target>
        </trans-unit>
        <trans-unit id="c86da089418268adb10c8acdbbba40db282822e6" translate="yes" xml:space="preserve">
          <source>generates callgrind.out.x. Read it using kcachegrind.</source>
          <target state="translated">генерирует callgrind.out.x.Читайте его с помощью kcachegrind.</target>
        </trans-unit>
        <trans-unit id="b03467560afe04df21ced900b226b5f9dadcb62d" translate="yes" xml:space="preserve">
          <source>gprof is built-into GCC/binutils, so all we have to do is to compile with the &lt;code&gt;-pg&lt;/code&gt; option to enable gprof. We then run the program normally with a size CLI parameter that produces a run of reasonable duration of a few seconds (&lt;code&gt;10000&lt;/code&gt;):</source>
          <target state="translated">gprof встроен в GCC / binutils, поэтому все, что нам нужно сделать, это скомпилировать с опцией &lt;code&gt;-pg&lt;/code&gt; , чтобы включить gprof. Затем мы обычно запускаем программу с параметром CLI размера, который производит разумную продолжительность в несколько секунд ( &lt;code&gt;10000&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="9cb1273641689838d08c035718b933b581323243" translate="yes" xml:space="preserve">
          <source>gprof requires recompiling the software with instrumentation, and it also uses a sampling approach together with that instrumentation. It therefore strikes a balance between accuracy (sampling is not always fully accurate and can skip functions) and execution slowdown (instrumentation and sampling are relatively fast techniques that don't slow down execution very much).</source>
          <target state="translated">gprof требует перекомпиляции программного обеспечения с контрольно-измерительными приборами,а также использует выборочный подход вместе с этими контрольно-измерительными приборами.Таким образом,он обеспечивает баланс между точностью (выборка не всегда является полностью точной и может пропускать функции)и замедлением исполнения (контрольно-измерительные приборы и выборка являются относительно быстрыми методами,которые не очень сильно замедляют исполнение).</target>
        </trans-unit>
        <trans-unit id="6c20dbe559048f4187157de781dccf6f5ba1544e" translate="yes" xml:space="preserve">
          <source>how about IO, handled and optimized ?</source>
          <target state="translated">как насчет ввода-вывода,обработанного и оптимизированного?</target>
        </trans-unit>
        <trans-unit id="8ad78a2d8b81d1f48b603777d625c316ec818e1d" translate="yes" xml:space="preserve">
          <source>is my algorithm correct ?</source>
          <target state="translated">верен ли мой алгоритм?</target>
        </trans-unit>
        <trans-unit id="3a13f69d29ec474c66705e3aaadaa6bf50574a2c" translate="yes" xml:space="preserve">
          <source>is there a specific section of code that's proving to be a culprit ?</source>
          <target state="translated">есть ли определенный участок кода,который доказывает,что он виновен?</target>
        </trans-unit>
        <trans-unit id="406e031b8824ea26ae0bf4d7579a1d89e3fb5906" translate="yes" xml:space="preserve">
          <source>main.c</source>
          <target state="translated">main.c</target>
        </trans-unit>
        <trans-unit id="d72ae9adcbb77a799278937f8a9954bf7d5fee38" translate="yes" xml:space="preserve">
          <source>they don't summarize at the instruction level, and</source>
          <target state="translated">они не суммируют на уровне инструкций,и</target>
        </trans-unit>
        <trans-unit id="813d13060cfdfe274f9dedbcdaad7e87361c8245" translate="yes" xml:space="preserve">
          <source>they give confusing summaries in the presence of recursion.</source>
          <target state="translated">они дают запутанные резюме при наличии рекурсии.</target>
        </trans-unit>
        <trans-unit id="b38e2cc31a913ba13d49dd56d1a341b5650300c3" translate="yes" xml:space="preserve">
          <source>us the command &lt;code&gt;gprof --graph a.out&lt;/code&gt; to get the following data for each function which includes</source>
          <target state="translated">используя команду &lt;code&gt;gprof --graph a.out&lt;/code&gt; , чтобы получить следующие данные для каждой функции, которая включает</target>
        </trans-unit>
        <trans-unit id="5e1acf1cde93e84e5121533952a55ce3fcfa7a9a" translate="yes" xml:space="preserve">
          <source>valgrind runs the program through the valgrind virtual machine. This makes the profiling very accurate, but it also produces a very large slowdown of the program. I have also mentioned kcachegrind previously at: &lt;a href=&quot;https://stackoverflow.com/questions/517589/tools-to-get-a-pictorial-function-call-graph-of-code/31190167#31190167&quot;&gt;Tools to get a pictorial function call graph of code&lt;/a&gt;</source>
          <target state="translated">valgrind запускает программу через виртуальную машину valgrind. Это делает профилирование очень точным, но также вызывает очень большое замедление программы. Ранее я также упоминал kcachegrind по адресу: &lt;a href=&quot;https://stackoverflow.com/questions/517589/tools-to-get-a-pictorial-function-call-graph-of-code/31190167#31190167&quot;&gt;Инструменты для получения графического графического вызова функции.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5572540656d11e87dd5bd966d28d6665bd7fe5af" translate="yes" xml:space="preserve">
          <source>which gives as a familiar call graph like other tools, but with the clunky unit of number of samples rather than seconds.</source>
          <target state="translated">что дает как знакомый граф вызовов,как и другие инструменты,но с неуклюжей единицей количества образцов,а не секунд.</target>
        </trans-unit>
        <trans-unit id="88dc6e662ab6827a52e6b9e9027101485ddfb787" translate="yes" xml:space="preserve">
          <source>which gives:</source>
          <target state="translated">что дает:</target>
        </trans-unit>
        <trans-unit id="6e4de60efe1156a81e465d013cb2669ea775fcd4" translate="yes" xml:space="preserve">
          <source>which shows a GUI that contains data similar to the textual gprof output:</source>
          <target state="translated">который показывает графический интерфейс,который содержит данные,похожие на текстовый вывод gprof:</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
