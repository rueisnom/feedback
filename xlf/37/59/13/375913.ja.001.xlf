<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="https://stackoverflow.com/questions/375913">
    <body>
      <group id="375913">
        <trans-unit id="474f686377fbd8012f361b7bd0929092b87eaedd" translate="yes" xml:space="preserve">
          <source>(The key is that we see &lt;code&gt;I&lt;/code&gt; more than once. If we only see it once, that doesn't tell us much except that &lt;code&gt;f&lt;/code&gt; &amp;gt; 0.)</source>
          <target state="translated">（重要なのは、 &lt;code&gt;I&lt;/code&gt; が2回以上表示されることです。1回しか表示されない場合、 &lt;code&gt;f&lt;/code&gt; &amp;gt; 0であること以外はあまりわかりません。）</target>
        </trans-unit>
        <trans-unit id="6bddfcbf9effc6af0dc2a4017b8af4d6d8c3b612" translate="yes" xml:space="preserve">
          <source>(not so good for multi-threads, function pointers)</source>
          <target state="translated">(マルチスレッドや関数ポインタにはあまり向いていません)</target>
        </trans-unit>
        <trans-unit id="ba000b98349f454ff4d963d272eea56d9076b1f0" translate="yes" xml:space="preserve">
          <source>(wikipedia) Valgrind is in essence a virtual
  machine using just-in-time (JIT)
  compilation techniques, including
  dynamic recompilation. Nothing from
  the original program ever gets run
  directly on the host processor.
  Instead, Valgrind first translates the
  program into a temporary, simpler form
  called Intermediate Representation
  (IR), which is a processor-neutral,
  SSA-based form. After the conversion,
  a tool (see below) is free to do
  whatever transformations it would like
  on the IR, before Valgrind translates
  the IR back into machine code and lets
  the host processor run it.</source>
          <target state="translated">(wikipedia)ヴァルグラインドは、本質的には動的再コンパイルを含むジャストインタイム(JIT)コンパイル技術を用いた仮想マシンである。元のプログラムがホストプロセッサ上で直接実行されることはありません。その代わりに、Valgrindは最初にプログラムを中間表現(IR)と呼ばれる一時的でシンプルな形に変換します。変換の後、ツール(下記参照)はIR上で好きな変換を自由に行うことができます。</target>
        </trans-unit>
        <trans-unit id="2f52699e83e4b55e1f403f7c6079898edd6b4dff" translate="yes" xml:space="preserve">
          <source>- Above function , there is a list of functions that call the function .</source>
          <target state="translated">-上記の関数,関数を呼び出す関数のリストがあります .</target>
        </trans-unit>
        <trans-unit id="97381d92a175352738f31c6b84ed1b50492ba724" translate="yes" xml:space="preserve">
          <source>- Below function , there is a list of functions that are called by the function .</source>
          <target state="translated">-以下の関数は、その関数によって呼び出される関数のリストです。</target>
        </trans-unit>
        <trans-unit id="2a06d6944b31ca287d1197fb91866bf150b9273f" translate="yes" xml:space="preserve">
          <source>- In each section, one function is marked with an index number.</source>
          <target state="translated">-各セクションでは、1つの関数にインデックス番号を付けています。</target>
        </trans-unit>
        <trans-unit id="579a41d12eaf05b9059712857073fbbb03bff3f1" translate="yes" xml:space="preserve">
          <source>- how many seconds were spent in a function&amp;mdash;including and excluding calls to sub-functions,</source>
          <target state="translated">-関数で費やされた秒数-サブ関数の呼び出しを含め、除外します</target>
        </trans-unit>
        <trans-unit id="2e6d2ff4ea07291f0fe68b6a1592baa107889c9d" translate="yes" xml:space="preserve">
          <source>- the average time per call.</source>
          <target state="translated">-1回の通話あたりの平均時間。</target>
        </trans-unit>
        <trans-unit id="09049524fc0fe3657417bd54beda8ddfcc7d00b5" translate="yes" xml:space="preserve">
          <source>- the number of calls,</source>
          <target state="translated">-の通話数を表示しています。</target>
        </trans-unit>
        <trans-unit id="726e946052f1dbb2b5959a244967231f79036c38" translate="yes" xml:space="preserve">
          <source>- what percentage of the overall time was spent for the function,</source>
          <target state="translated">-全体の時間の何%がその機能に費やされたのか。</target>
        </trans-unit>
        <trans-unit id="e299449c036492af510a743e9982f023ddc5e7c0" translate="yes" xml:space="preserve">
          <source>1- Flat profiling:</source>
          <target state="translated">1-フラットプロファイリング</target>
        </trans-unit>
        <trans-unit id="961cb4afe9142078530eb983e36df03834cb40bb" translate="yes" xml:space="preserve">
          <source>2- graph profiling</source>
          <target state="translated">2-グラフプロファイリング</target>
        </trans-unit>
        <trans-unit id="45d30831218fba6255f04ee5d6cb69901aae44b4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;main&lt;/code&gt; calls &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;maybe_slow&lt;/code&gt; 3 times, one of the &lt;code&gt;maybe_slow&lt;/code&gt; calls being slow</source>
          <target state="translated">&lt;code&gt;main&lt;/code&gt; コールが &lt;code&gt;fast&lt;/code&gt; 、 &lt;code&gt;maybe_slow&lt;/code&gt; が 3回、 &lt;code&gt;maybe_slow&lt;/code&gt; コールの1つが遅い</target>
        </trans-unit>
        <trans-unit id="2b26d60b77140f5edaf92172d3607731805526d8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;perf&lt;/code&gt; seems to use exclusively Linux kernel sampling mechanisms. This makes it very simple to setup, but also not fully accurate.</source>
          <target state="translated">&lt;code&gt;perf&lt;/code&gt; はLinuxカーネルサンプリングメカニズムのみを使用しているようです。 これにより、セットアップが非常に簡単になりますが、完全に正確ではありません。</target>
        </trans-unit>
        <trans-unit id="beaa2542bdd5cb48d735e110bbd66e279a970967" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;valgrind&lt;/code&gt; with the combination of &lt;code&gt;callrind&lt;/code&gt; and &lt;code&gt;kcachegrind&lt;/code&gt; should provide a decent estimation on the points above and once it's established that there are issues with some section of code, I'd suggest do a micro bench mark &lt;code&gt;google benchmark&lt;/code&gt; is a good place to start.</source>
          <target state="translated">&lt;code&gt;callrind&lt;/code&gt; と &lt;code&gt;kcachegrind&lt;/code&gt; を組み合わせた &lt;code&gt;valgrind&lt;/code&gt; は、上記の点について適切な見積もりを提供するはずです。コードの一部のセクションに問題があることが確認されたら、マイクロ &lt;code&gt;google benchmark&lt;/code&gt; を開始するのに適しています。</target>
        </trans-unit>
        <trans-unit id="558433641cab85097025b8b72bc823c8bf5e82ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;code&gt;perf&lt;/code&gt; from &lt;code&gt;linux-tools&lt;/code&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt; &lt;code&gt;linux-tools&lt;/code&gt; の &lt;code&gt;perf&lt;/code&gt; &lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1e49cc3868d9deb4e8335aa49828e8c34898c8a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;em&gt;For CPU bound applications:&lt;/em&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;&lt;em&gt;CPUバインドアプリケーションの場合：&lt;/em&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="7196658c799f4043d28d713837910b362f91ab93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;&lt;em&gt;For I/O bound applications:&lt;/em&gt;&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;&lt;em&gt;I / Oバウンドアプリケーションの場合：&lt;/em&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="ad2cef4043d111e1ae8c4692b0d3548a6613fcbd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Intel VTune is the best (free for educational purposes).&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;インテルVTuneは最高です（教育目的で無料）。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a2b5b23586b55133642cbd2c4d931e703f33536e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Others:&lt;/strong&gt; AMD Codeanalyst (since replaced with AMD CodeXL), OProfile, 'perf' tools (apt-get install linux-tools)</source>
          <target state="translated">&lt;strong&gt;その他：&lt;/strong&gt; AMD Codeanalyst（AMD CodeXLに置き換えられたため）、OProfile、 'perf'ツール（apt-get install linux-tools）</target>
        </trans-unit>
        <trans-unit id="9f805de8a6187ff8c605dc1b87c1dbf750af8806" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Survey of C++ profiling techniques&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;C ++プロファイリング技術の調査&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="5935609263c49f484c816bb47bd583d8ac724622" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use Valgrind, callgrind and kcachegrind:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Valgrind、callgrindおよびkcachegrindを使用します。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="f76b5fe3b1c9563ed7d1caedae895977e4729ca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use google-perftools:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;google-perftoolsを使用します。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="eaf91a71c594a624723a2785654641c0d49b648f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Use gprof (add -pg):&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;gprofを使用（-pgを追加）：&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="e2938d732361a260a7c9ca67f5add9a7cbbbdb25" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gperftools&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;gperftools&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b34e9a3fe97464e4681d8532723054a812e2edcd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gprof&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;gprof&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a645022e82b11913d78a887f81582e01e0a2ca4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;valgrind callgrind&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;valgrind callgrind&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b68ca6f37b8016941f5283f36f3759df87ef2002" translate="yes" xml:space="preserve">
          <source>A few other buzzwords if &lt;code&gt;gprof&lt;/code&gt; does not do the job for you: &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt;, Intel &lt;a href=&quot;http://en.wikipedia.org/wiki/VTune&quot;&gt;VTune&lt;/a&gt;, Sun &lt;a href=&quot;http://en.wikipedia.org/wiki/DTrace&quot;&gt;DTrace&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;gprof&lt;/code&gt; があなたのために仕事をしないなら、他のいくつかの流行語： &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt; 、Intel &lt;a href=&quot;http://en.wikipedia.org/wiki/VTune&quot;&gt;VTune&lt;/a&gt; 、Sun &lt;a href=&quot;http://en.wikipedia.org/wiki/DTrace&quot;&gt;DTrace&lt;/a&gt; 。</target>
        </trans-unit>
        <trans-unit id="7c42306a937ace4fd5a87d18a701b72889554283" translate="yes" xml:space="preserve">
          <source>ADDED, to give an intuitive feel for the difference between measuring and random stack sampling:</source>
          <target state="translated">測定とランダムスタックサンプリングの違いを直感的に感じられるように追加しました。</target>
        </trans-unit>
        <trans-unit id="9276e16e7cc14ecf9ae00f247b4196166d5d1aeb" translate="yes" xml:space="preserve">
          <source>ADDED: Let me make a Bayesian explanation of how it works.  Suppose there is some instruction &lt;code&gt;I&lt;/code&gt; (call or otherwise) which is on the call stack some fraction &lt;code&gt;f&lt;/code&gt; of the time (and thus costs that much). For simplicity, suppose we don't know what &lt;code&gt;f&lt;/code&gt; is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori.</source>
          <target state="translated">追加：それがどのように機能するかについてベイジアンの説明をさせてください。 呼び出しスタックにある時間 &lt;code&gt;I&lt;/code&gt; の一部である（したがって、それだけコストがかかる）命令I （呼び出しまたはその他）があるとします。 簡単にするために、 &lt;code&gt;f&lt;/code&gt; が何であるかはわかりませんが、0.1、0.2、0.3、... 0.9、1.0のいずれかであり、これらの各可能性の事前確率は0.1であるため、これらのコストはすべて等しくなります。おそらくアプリオリ。</target>
        </trans-unit>
        <trans-unit id="830b0bd9a847a1c514fcf9b261f15a81a0e87159" translate="yes" xml:space="preserve">
          <source>Actually a bit surprised not many mentioned about &lt;a href=&quot;https://github.com/google/benchmark&quot;&gt;google/benchmark&lt;/a&gt; , while it is a bit cumbersome to pin the specific area of code, specially if the code base is a little big one, however I found this really helpful when used in combination with &lt;code&gt;callgrind&lt;/code&gt;</source>
          <target state="translated">実際には少し驚いて、多くの&lt;a href=&quot;https://github.com/google/benchmark&quot;&gt;google / benchmark&lt;/a&gt;について言及していませんが、コードの特定の領域を固定するのは少し面倒ですが、特にコードベースが少し大きい場合は、これが &lt;code&gt;callgrind&lt;/code&gt; と組み合わせて使用​​すると非常に役立ちます</target>
        </trans-unit>
        <trans-unit id="d081153271ba73f6b08b5c733dfc600113ac8050" translate="yes" xml:space="preserve">
          <source>Added: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample.</source>
          <target state="translated">追加:自明ではないかもしれませんが、スタックサンプリング技術は再帰の存在下でも同じように動作します。その理由は、ある命令を削除することで節約される時間は、サンプル内で何回発生しても、その命令を含むサンプルの割合で近似されるからです。</target>
        </trans-unit>
        <trans-unit id="c111026e3becc4657525d1504f2a98b1227fa293" translate="yes" xml:space="preserve">
          <source>After running with either of those methods, we get a &lt;code&gt;prof.out&lt;/code&gt; profile data file as output. We can view that file graphically as an SVG with:</source>
          <target state="translated">これらのメソッドのいずれかで実行した後、出力として &lt;code&gt;prof.out&lt;/code&gt; プロファイルデータファイルを取得します。 以下のようにして、そのファイルをSVGとしてグラフィカルに表示できます。</target>
        </trans-unit>
        <trans-unit id="938c0204782973ed2cee8235fd6ed9aad9bd19a0" translate="yes" xml:space="preserve">
          <source>Also worth mentioning are</source>
          <target state="translated">また、言及する価値があるのは</target>
        </trans-unit>
        <trans-unit id="30c36d00bdcf5c119d2a78569796b3b993fd0320" translate="yes" xml:space="preserve">
          <source>Also, if we go on the bottom right &quot;Call Graph&quot; tab, we see a call graph which we can export by right clicking it to obtain the following image with unreasonable amounts of white border :-)</source>
          <target state="translated">また、右下の「Call Graph」タブに行くと、コールグラフが表示されるので、右クリックしてエクスポートすると、以下のような画像が得られます。)</target>
        </trans-unit>
        <trans-unit id="1ac3bae0296e72365db70cdbd1d168992f9eb4f9" translate="yes" xml:space="preserve">
          <source>Alternatively, we can also get some textual data with:</source>
          <target state="translated">あるいは、いくつかのテキストデータを取得することもできます。</target>
        </trans-unit>
        <trans-unit id="6fe0b9fdb5d375e1bdddd4970a95aeb96c822b66" translate="yes" xml:space="preserve">
          <source>Alternatively, we can also observe the text output of the &lt;code&gt;gprof&lt;/code&gt; built-in binutils tool which we previously saved at:</source>
          <target state="translated">または、以前に保存した &lt;code&gt;gprof&lt;/code&gt; 組み込みbinutilsツールのテキスト出力を確認することもできます。</target>
        </trans-unit>
        <trans-unit id="d9dc64edf60dc7f5a3736a9279e32f3c03a13aa5" translate="yes" xml:space="preserve">
          <source>Alternatively, we can build the library in at link time, dispensing passing &lt;code&gt;LD_PRELOAD&lt;/code&gt; at runtime:</source>
          <target state="translated">または、リンク時にライブラリをビルドして、実行時に &lt;code&gt;LD_PRELOAD&lt;/code&gt; を渡すことを省略できます。</target>
        </trans-unit>
        <trans-unit id="2cf1c27c41cddb303f6c128115968d14017c5f27" translate="yes" xml:space="preserve">
          <source>Another objection I often hear is: &quot;&lt;em&gt;It will stop someplace random, and it will miss the real problem&lt;/em&gt;&quot;.
This comes from having a prior concept of what the real problem is.
A key property of performance problems is that they defy expectations.
Sampling tells you something is a problem, and your first reaction is disbelief.
That is natural, but you can be sure if it finds a problem it is real, and vice-versa.</source>
          <target state="translated">私がよく聞く別の異論は、「 &lt;em&gt;どこかでランダムに停止し、本当の問題を見逃す&lt;/em&gt; 」です。 これは、実際の問題が何であるかについての事前の概念を持っていることに由来します。 パフォーマンスの問題の重要な特性は、期待に反することです。 サンプリングは何かが問題であることを告げ、あなたの最初の反応は不信です。 それは当たり前のことですが、それが本当の問題を見つけた場合には確信が持て、逆もまた同様です。</target>
        </trans-unit>
        <trans-unit id="fd2b8eb720b92068f67a32658ccfc03d658f34d9" translate="yes" xml:space="preserve">
          <source>Another perf GUI interfaces which might be worth it include:</source>
          <target state="translated">それは価値があるかもしれない別の perf GUI インターフェイスが含まれています。</target>
        </trans-unit>
        <trans-unit id="48122e4897dd407d27c90182539de52d682b669c" translate="yes" xml:space="preserve">
          <source>Another tool build upon Valgrind is Massif. I use it to profile heap memory usage. It works great. What it does is that it gives you snapshots of memory usage -- detailed information WHAT holds WHAT percentage of memory, and WHO had put it there. Such information is available at different points of time of application run.</source>
          <target state="translated">Valgrindをベースに作られたもう一つのツールがMassifです。私はこれを使ってヒープメモリの使用量をプロファイルしています。これは素晴らしい機能を持っています。何をしているのかというと、メモリ使用量のスナップショットを提供してくれるということです。このような情報は、アプリケーションを実行している様々な時点で利用可能です。</target>
        </trans-unit>
        <trans-unit id="26cfea3667d4951989c3328a2749151be15581ab" translate="yes" xml:space="preserve">
          <source>Arm MAP is the profiler for parallel, multithreaded or single threaded C, C++, Fortran and F90 codes.  It provides in-depth analysis and bottleneck pinpointing to the source line.  Unlike most profilers, it's designed to be able to profile pthreads, OpenMP or MPI for parallel and threaded code.</source>
          <target state="translated">Arm MAPは、並列、マルチスレッド、シングルスレッドのC、C++、Fortran、F90コードのプロファイラです。ソースラインまでの詳細な解析とボトルネックのピンポイント特定を提供します。ほとんどのプロファイラとは異なり、並列およびスレッドコード用にpthread、OpenMP、MPIをプロファイリングできるように設計されています。</target>
        </trans-unit>
        <trans-unit id="f607a78951293acbad31ccf19fd2a9c3fc0343e3" translate="yes" xml:space="preserve">
          <source>As a very quick summary for each section e.g.:</source>
          <target state="translated">各セクションの非常に簡単な要約として、例えば</target>
        </trans-unit>
        <trans-unit id="1361188e9146c170f0554ec525ed827cb7592cc2" translate="yes" xml:space="preserve">
          <source>As no one mentioned Arm MAP, I'd add it as personally I have successfully used Map to profile a C++ scientific program.</source>
          <target state="translated">誰もArm MAPについて言及していないので、個人的にはMapを使ってC++の科学プログラムをプロファイルすることに成功したので追加しておきます。</target>
        </trans-unit>
        <trans-unit id="33441507f930cc628d62c6420d02d66548f47be3" translate="yes" xml:space="preserve">
          <source>At runtime, we have to pass set the &lt;code&gt;LD_PRELOAD&lt;/code&gt; to point to &lt;code&gt;libprofiler.so&lt;/code&gt;, which you can find with &lt;code&gt;locate libprofiler.so&lt;/code&gt;, e.g. on my system:</source>
          <target state="translated">実行時に、 &lt;code&gt;LD_PRELOAD&lt;/code&gt; が &lt;code&gt;libprofiler.so&lt;/code&gt; を指すように設定を渡す必要があります。これは、たとえば、私のシステムで、 &lt;code&gt;locate libprofiler.so&lt;/code&gt; を使用して見つけることができます。</target>
        </trans-unit>
        <trans-unit id="275c32d1f4761fd0f70f1e315294ca1da95e4155" translate="yes" xml:space="preserve">
          <source>At work we have a really nice tool that helps us monitoring what we want in terms of scheduling. This has been useful numerous times.</source>
          <target state="translated">職場では、スケジューリングの面で何をしたいのかを監視するのに役立つ本当に素晴らしいツールを持っています。これは何度も役に立っています。</target>
        </trans-unit>
        <trans-unit id="c762222f2d1b7501653b936c0a39cd0b1aa6a933" translate="yes" xml:space="preserve">
          <source>Be sure to add &lt;code&gt;-pg&lt;/code&gt; to compilation before profiling:</source>
          <target state="translated">プロファイリングの前に、必ずコンパイルに &lt;code&gt;-pg&lt;/code&gt; を追加してください。</target>
        </trans-unit>
        <trans-unit id="d55e4a545eefcf858705baa9f8981e8dc001934b" translate="yes" xml:space="preserve">
          <source>Because we compiled with &lt;code&gt;-pg&lt;/code&gt;, running the program produces a file &lt;code&gt;gmon.out&lt;/code&gt; file containing the profiling data.</source>
          <target state="translated">&lt;code&gt;-pg&lt;/code&gt; を使用してコンパイルしたため、プログラムを実行すると、プロファイリングデータを含むファイル &lt;code&gt;gmon.out&lt;/code&gt; ファイルが生成されます。</target>
        </trans-unit>
        <trans-unit id="0e20564692b92dee75c5d2d38aa97448c7b86382" translate="yes" xml:space="preserve">
          <source>But this has the downside that you have to first convert the data to the Common Trace Format, which can be done with &lt;code&gt;perf data --to-ctf&lt;/code&gt;, but it needs to be enabled at build time/have &lt;code&gt;perf&lt;/code&gt; new enough, either of which is not the case for the perf in Ubuntu 18.04</source>
          <target state="translated">ただし、これには、最初にデータをCommon Trace Formatに変換する必要があるという欠点があります。これは、 &lt;code&gt;perf data --to-ctf&lt;/code&gt; で実行できますが、ビルド時に有効にする必要があります/ &lt;code&gt;perf&lt;/code&gt; を十分に新しくする必要があります。 Ubuntu 18.04のパフォーマンスには当てはまりません</target>
        </trans-unit>
        <trans-unit id="7940ac6d6de4ba483d9863a1db60f99151f2c050" translate="yes" xml:space="preserve">
          <source>By default, this produces an extremely verbose output that explains what the output data means. Since I can't explain better than that, I'll let you read it yourself.</source>
          <target state="translated">デフォルトでは、出力データが何を意味するのかを説明する非常に冗長な出力を生成します。これ以上の説明はできないので、自分で読んでみてください。</target>
        </trans-unit>
        <trans-unit id="0e030095a99fb3257e11106bd611c56f45c2b3ed" translate="yes" xml:space="preserve">
          <source>Callgrind is a profiler build upon that. Main benefit is that you don't have to run your aplication for hours to get reliable result. Even one second run is sufficient to get rock-solid, reliable results, because Callgrind is a &lt;strong&gt;non-probing&lt;/strong&gt; profiler.</source>
          <target state="translated">Callgrindは、その上に構築されたプロファイラーです。 主な利点は、信頼できる結果を得るために何時間もアプリケーションを実行する必要がないことです。 Callgrindは&lt;strong&gt;非&lt;/strong&gt;プロファイリングプロファイラーであるため、1秒の実行でさえ、確実で信頼できる結果を得るには十分です。</target>
        </trans-unit>
        <trans-unit id="5fea0991e44d8690969eca7425688fa735bb73f4" translate="yes" xml:space="preserve">
          <source>Can you find the most critical call stack easily with all those tiny unsorted spaghetti lines going over one another? There might be better &lt;code&gt;dot&lt;/code&gt; options I'm sure, but I don't want to go there now. What we really need is a proper dedicated viewer for it, but I haven't found one yet:</source>
          <target state="translated">並べ替えられていない小さなすべてのスパゲッティラインが互いに行き来することで、最も重要なコールスタックを簡単に見つけることができますか？ 確かにもっと良い &lt;code&gt;dot&lt;/code&gt; オプションがあるかもしれませんが、今はそこに行きたくありません。 私たちが本当に必要としているのは、そのための適切な専用ビューアですが、まだ見つけていません。</target>
        </trans-unit>
        <trans-unit id="20f2f816399d50a15985c861ae31ff174b730293" translate="yes" xml:space="preserve">
          <source>Caveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because</source>
          <target state="translated">警告:プログラマは自分自身でこのテクニックを使ったことがない限り、このテクニックに懐疑的になる傾向があります。プロファイラはこのような情報を与えてくれると言うでしょうが、それはコールスタック全体をサンプリングして、ランダムなサンプルのセットを調べた場合にのみ当てはまります。(サマリーは洞察力を失うところです。)コールグラフは同じ情報を与えてくれません。</target>
        </trans-unit>
        <trans-unit id="099dc36893aed4eafd86bced522e4eb9937e5b98" translate="yes" xml:space="preserve">
          <source>Eclipse Trace Compass plugin: &lt;a href=&quot;https://www.eclipse.org/tracecompass/&quot;&gt;https://www.eclipse.org/tracecompass/&lt;/a&gt;</source>
          <target state="translated">Eclipse Trace Compassプラグイン： &lt;a href=&quot;https://www.eclipse.org/tracecompass/&quot;&gt;https&lt;/a&gt; : //www.eclipse.org/tracecompass/</target>
        </trans-unit>
        <trans-unit id="b0500648de7f8cd809c18dfe1a12b0af1850fcf1" translate="yes" xml:space="preserve">
          <source>First install gperftools with:</source>
          <target state="translated">まずgperftoolsを一緒にインストールします。</target>
        </trans-unit>
        <trans-unit id="f718a4c61c9b86b8efe3e4a514c5978b1cf993ee" translate="yes" xml:space="preserve">
          <source>First we have to remove the &lt;code&gt;-pg&lt;/code&gt; flag to go back to normal compilation, otherwise the run actually fails with &lt;a href=&quot;https://stackoverflow.com/questions/2146082/valgrind-profiling-timer-expired&quot;&gt;&lt;code&gt;Profiling timer expired&lt;/code&gt;&lt;/a&gt;, and yes, this is so common that I did and there was a Stack Overflow question for it.</source>
          <target state="translated">最初に、通常のコンパイルに戻るには &lt;code&gt;-pg&lt;/code&gt; フラグを削除する必要があります。そうしないと、実際には&lt;a href=&quot;https://stackoverflow.com/questions/2146082/valgrind-profiling-timer-expired&quot;&gt; &lt;code&gt;Profiling timer expired&lt;/code&gt; &lt;/a&gt;で実行が失敗します。そうです、これは非常に一般的であり、スタックオーバーフローの質問がありました。</target>
        </trans-unit>
        <trans-unit id="731b082498e3f526227d4ecd0e76236c0bf482bd" translate="yes" xml:space="preserve">
          <source>First, &lt;code&gt;time&lt;/code&gt; tells us that the execution time with and without &lt;code&gt;-pg&lt;/code&gt; were the same, which is great: no slowdown! I have however seen accounts of 2x - 3x slowdowns on complex software, e.g. as &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;shown in this ticket&lt;/a&gt;.</source>
          <target state="translated">まず、 &lt;code&gt;time&lt;/code&gt; は、 &lt;code&gt;-pg&lt;/code&gt; を使用した場合と使用しない場合の実行時間が同じであることを示しています。 ただし、たとえば&lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;このチケットに示され&lt;/a&gt;ているように 、複雑なソフトウェアの2倍から3倍の速度低下の説明を目にしました。</target>
        </trans-unit>
        <trans-unit id="bcac6f94f0587cb573e61450977a4e3d79d79994" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;-O3&lt;/code&gt;, see here like in the graphical output that &lt;code&gt;maybe_slow&lt;/code&gt; and &lt;code&gt;fast&lt;/code&gt; don't have a known parent, which is what the documentation says that &lt;code&gt;&amp;lt;spontaneous&amp;gt;&lt;/code&gt; means.</source>
          <target state="translated">&lt;code&gt;-O3&lt;/code&gt; については、ここで、グラフィック出力のように、 &lt;code&gt;maybe_slow&lt;/code&gt; および &lt;code&gt;fast&lt;/code&gt; には既知の親がないことを参照してください。これは、ドキュメントで &lt;code&gt;&amp;lt;spontaneous&amp;gt;&lt;/code&gt; が意味するものです。</target>
        </trans-unit>
        <trans-unit id="06d456a661f5b9ba3d3687e35852bf5858fab879" translate="yes" xml:space="preserve">
          <source>For CPU, the reason for profiling in &lt;strong&gt;DEBUG&lt;/strong&gt; mode is because if your tried profiling in &lt;strong&gt;RELEASE&lt;/strong&gt; mode, the compiler is going to reduce math, vectorize loops, and inline functions which tends to glob your code into an un-mappable mess when it's assembled. &lt;strong&gt;An un-mappable mess means your profiler will not be able to clearly identify what is taking so long because the assembly may not correspond to the source code under optimization&lt;/strong&gt;. If you need the performance (e.g. timing sensitive) of &lt;strong&gt;RELEASE&lt;/strong&gt; mode, disable debugger features as needed to keep a usable performance.</source>
          <target state="translated">CPUの場合、 &lt;strong&gt;デバッグ&lt;/strong&gt;モードでプロファイリングを行う理由は、 &lt;strong&gt;RELEASE&lt;/strong&gt;モードでプロファイリングを試みた場合、コンパイラーは数学を削減し、ループをインライン化し、コードを組み立てたときにコードをマップ不可能な混乱に展開する傾向があるインライン関数であるためです。 &lt;strong&gt;マップできない混乱は、アセンブリが最適化中のソースコードに対応していない可能性があるため、プロファイラーがそれほど時間がかかっていることを明確に識別できないことを意味します&lt;/strong&gt; 。 &lt;strong&gt;RELEASE&lt;/strong&gt;モードのパフォーマンス（たとえば、タイミング依存）が必要な場合は、使用可能なパフォーマンスを維持するために、必要に応じてデバッガー機能を無効にします。</target>
        </trans-unit>
        <trans-unit id="1fd1a4e3732d0165baa94d16658f7291d1e77cb2" translate="yes" xml:space="preserve">
          <source>For I/O-bound, the profiler can still identify I/O operations in &lt;strong&gt;RELEASE&lt;/strong&gt; mode because I/O operations are either externally linked to a shared library (most of the time) or in the worst case, will result in a sys-call interrupt vector (which is also easily identifiable by the profiler).</source>
          <target state="translated">I / Oバウンドの場合、プロファイラは&lt;strong&gt;RELEASE&lt;/strong&gt;モードのI / O操作を識別できます。これは、I / O操作が共有ライブラリに外部的にリンクされている（ほとんどの場合）か、最悪の場合、sys-割り込みベクトルを呼び出します（これもプロファイラーによって簡単に識別できます）。</target>
        </trans-unit>
        <trans-unit id="da7a5db11d6d72fa7a5c6be30597dedf122892f3" translate="yes" xml:space="preserve">
          <source>For educational reasons, we will also do a run without optimizations enabled. Note that this is useless in practice, as you normally only care about optimizing the performance of the optimized program:</source>
          <target state="translated">教育上の理由から、最適化を有効にしていない状態での実行も行います。通常は最適化されたプログラムのパフォーマンスを最適化することにしか関心がないので、実際には役に立たないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="59ad9936a7b0f4788c6ad3b0ea79e48e4a42d309" translate="yes" xml:space="preserve">
          <source>For single-threaded programs you can use &lt;strong&gt;igprof&lt;/strong&gt;, The Ignominous Profiler: &lt;a href=&quot;https://igprof.org/&quot;&gt;https://igprof.org/&lt;/a&gt; .</source>
          <target state="translated">シングルスレッドプログラムの場合は、 &lt;strong&gt;igprof&lt;/strong&gt; 、The Ignominous Profiler： &lt;a href=&quot;https://igprof.org/&quot;&gt;https&lt;/a&gt; ://igprof.org/を使用できます 。</target>
        </trans-unit>
        <trans-unit id="e32962da9446269770cb3283319d83603bd59de6" translate="yes" xml:space="preserve">
          <source>HPCToolkit (&lt;a href=&quot;http://hpctoolkit.org/&quot;&gt;http://hpctoolkit.org/&lt;/a&gt;) - Open-source, works for parallel programs and has a GUI with which to look at the results multiple ways</source>
          <target state="translated">HPCToolkit（ &lt;a href=&quot;http://hpctoolkit.org/&quot;&gt;http://hpctoolkit.org/&lt;/a&gt; ）-オープンソース、並列プログラムで動作し、結果を複数の方法で確認できるGUIを備えています</target>
        </trans-unit>
        <trans-unit id="9717437adb9e366c40c178b8b430e79730bf5d20" translate="yes" xml:space="preserve">
          <source>Here is an off-the-cuff illustration of the difference between examining measurements and examining stack samples.
The bottleneck could be one big blob like this, or numerous small ones, it makes no difference.</source>
          <target state="translated">ここでは、測定値を調べることとスタックサンプルを調べることの違いについて、その場しのぎで説明します。ボトルネックは、このような大きな塊であっても、小さな塊であっても、違いはありません。</target>
        </trans-unit>
        <trans-unit id="84e40b82ddf20b2158fe8ae0544325f38d246cfd" translate="yes" xml:space="preserve">
          <source>Here, the &lt;code&gt;gprof&lt;/code&gt; tool reads the &lt;code&gt;gmon.out&lt;/code&gt; trace information, and generates a human readable report in &lt;code&gt;main.gprof&lt;/code&gt;, which &lt;code&gt;gprof2dot&lt;/code&gt; then reads to generate a graph.</source>
          <target state="translated">ここでは、 &lt;code&gt;gprof&lt;/code&gt; ツールが &lt;code&gt;gmon.out&lt;/code&gt; トレース情報を読み取り、人間が読める形式のレポートを &lt;code&gt;main.gprof&lt;/code&gt; に生成します。これを &lt;code&gt;gprof2dot&lt;/code&gt; が読み取ってグラフを生成します。</target>
        </trans-unit>
        <trans-unit id="966dcaa64447ac43f2c9e4440202155cac9e9802" translate="yes" xml:space="preserve">
          <source>Hope the idea is not obfuscated by the lack of sample code.</source>
          <target state="translated">サンプルコードがないことでアイデアが難読化されないことを願っています。</target>
        </trans-unit>
        <trans-unit id="b3431131b2f01fa3ab4147cebf53065a9fed2f0e" translate="yes" xml:space="preserve">
          <source>How can I profile C++ code running on Linux</source>
          <target state="translated">Linux上で実行されているC++コードをプロファイリングするには</target>
        </trans-unit>
        <trans-unit id="e8d9679c58e452301713e88a029c43b1b26959f7" translate="yes" xml:space="preserve">
          <source>However, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems.</source>
          <target state="translated">しかし、急いでいて、主観的に遅くなっている間にデバッガの下で手動でプログラムを割込むことができるのであれば、パフォーマンスの問題を見つける簡単な方法があります。</target>
        </trans-unit>
        <trans-unit id="469ae7f984de3b3fd05c657ff55c2e05a4bb68f3" translate="yes" xml:space="preserve">
          <source>I assume you're using GCC. The standard solution would be to profile with &lt;a href=&quot;http://www.math.utah.edu/docs/info/gprof_toc.html&quot;&gt;gprof&lt;/a&gt;.</source>
          <target state="translated">GCCを使用していると思います。 標準的な解決策は、 &lt;a href=&quot;http://www.math.utah.edu/docs/info/gprof_toc.html&quot;&gt;gprof&lt;/a&gt;でプロファイリングすることです。</target>
        </trans-unit>
        <trans-unit id="2626ed11413be172901c236c0ce46711b1e4e409" translate="yes" xml:space="preserve">
          <source>I choose SVG output instead of PNG because the SVG is searchable with Ctrl + F and the file size can be about 10x smaller. Also, the width and height of the generated image can be humoungous with tens of thousands of pixels for complex software, and GNOME &lt;code&gt;eog&lt;/code&gt; 3.28.1 bugs out in that case for PNGs, while SVGs get opened by my browser automatically. gimp 2.8 worked well though, see also:</source>
          <target state="translated">PNGではなくSVG出力を選択します。SVGはCtrl + Fで検索可能であり、ファイルサイズは約10倍小さくできるためです。 また、生成された画像の幅と高さは、複雑なソフトウェアの場合は数万ピクセルと不自然で、PNGの場合はGNOME &lt;code&gt;eog&lt;/code&gt; 3.28.1でバグが発生しますが、SVGはブラウザーによって自動的に開かれます。 gimp 2.8はうまく機能しました。以下も参照してください：</target>
        </trans-unit>
        <trans-unit id="219d1034d60f6bcc0c754cc1eb67709e077e407e" translate="yes" xml:space="preserve">
          <source>I enable &lt;code&gt;--dump-instr=yes --collect-jumps=yes&lt;/code&gt; because this also dumps information that enables us to view a per assembly line breakdown of performance, at a relatively small added overhead cost.</source>
          <target state="translated">&lt;code&gt;--dump-instr=yes --collect-jumps=yes&lt;/code&gt; も有効にしています。これにより、比較的小さな追加のオーバーヘッドコストで、アセンブリラインごとのパフォーマンスの内訳を表示できる情報もダンプされます。</target>
        </trans-unit>
        <trans-unit id="161bfcf11ea394e1742c7e0a58a6044adc301c18" translate="yes" xml:space="preserve">
          <source>I have a C++ application, running on Linux, which I'm in the process of optimizing. How can I pinpoint which areas of my code are running slowly?</source>
          <target state="translated">Linux上で実行されているC++アプリケーションを持っています。コードのどの部分の動作が遅いかを特定するにはどうしたらよいでしょうか?</target>
        </trans-unit>
        <trans-unit id="3fa235219dffe6626130e2fa7a49a904b35f5be5" translate="yes" xml:space="preserve">
          <source>I have used HPCToolkit and VTune and they are very effective at finding the long pole in the tent and do not need your code to be recompiled (except that you have to use -g -O or RelWithDebInfo type build in CMake to get meaningful output). I have heard TAU is similar in capabilities.</source>
          <target state="translated">私はHPCToolkitとVTuneを使用してきましたが、テントの中の長いポールを見つけるのに非常に効果的で、コードを再コンパイルする必要がありません(意味のある出力を得るためにCMakeで-g -OまたはRelWithDebInfoタイプのビルドを使用しなければならないことを除いて)。TAUも似たような機能を持っていると聞いたことがあります。</target>
        </trans-unit>
        <trans-unit id="d652bdc8e2d715973adba2c14a8aeac6ea5b5520" translate="yes" xml:space="preserve">
          <source>I haven't tried it yet but I've heard good things about &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;google-perftools&lt;/a&gt;. It is definitely worth a try.</source>
          <target state="translated">まだ試していませんが、 &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;google-perftools&lt;/a&gt;について良いことは聞いています。 それは間違いなく試してみる価値があります。</target>
        </trans-unit>
        <trans-unit id="9adb36d7693cd006e9f81ed5125c898080cee016" translate="yes" xml:space="preserve">
          <source>I recommend in next window to click on &quot;Self&quot; column header, otherwise it shows that &quot;main()&quot; is most time consuming task. &quot;Self&quot; shows how much each function itself took time, not together with dependents.</source>
          <target state="translated">次のウィンドウでは、&quot;Self &quot;カラムのヘッダをクリックすることをお勧めします。&quot;Self &quot;は、依存関係のある関数との比較ではなく、それぞれの関数自体にどれだけ時間がかかったかを示しています。</target>
        </trans-unit>
        <trans-unit id="0f482aa371b33a0d0d5638abd01afc2e298063e0" translate="yes" xml:space="preserve">
          <source>I think &lt;code&gt;fast&lt;/code&gt; is not showing on that graph because kcachegrind must have simplified the visualization because that call takes up too little time, this will likely be the behavior you want on a real program. The right click menu has some settings to control when to cull such nodes, but I couldn't get it to show such a short call after a quick attempt. If I click on &lt;code&gt;fast&lt;/code&gt; on the left window, it does show a call graph with &lt;code&gt;fast&lt;/code&gt;, so that stack was actually captured. No one had yet found a way to show the complete graph call graph: &lt;a href=&quot;https://stackoverflow.com/questions/33769323/make-callgrind-show-all-function-calls-in-the-kcachegrind-callgraph&quot;&gt;Make callgrind show all function calls in the kcachegrind callgraph&lt;/a&gt;</source>
          <target state="translated">kcachegrindは視覚化を単純化する必要があるため、そのグラフに &lt;code&gt;fast&lt;/code&gt; が表示されていないと思います。これは、呼び出しにかかる時間が少なすぎるためです。これは、実際のプログラムで必要な動作になる可能性があります。 右クリックメニューには、そのようなノードをカリングするタイミングを制御するためのいくつかの設定がありますが、すばやく試行した後、このような短い呼び出しを表示することができませんでした。 左側のウィンドウで[ &lt;code&gt;fast&lt;/code&gt; ]をクリックすると、 fastの呼び出しグラフが表示されるため、実際にスタックがキャプチャされました。 完全なグラフ呼び出しグラフを表示する方法はまだ誰も見つけていません&lt;a href=&quot;https://stackoverflow.com/questions/33769323/make-callgrind-show-all-function-calls-in-the-kcachegrind-callgraph&quot;&gt;。callgrindにすべての関数呼び出しをkcachegrind&lt;/a&gt;呼び出しグラフに表示させる</target>
        </trans-unit>
        <trans-unit id="9b793d633b0f9e951abdde18b8e2544cd6ea68b3" translate="yes" xml:space="preserve">
          <source>I would use Valgrind and Callgrind as a base for my profiling tool suite. What is important to know is that Valgrind is basically a Virtual Machine:</source>
          <target state="translated">私は、プロファイリングツールスイートのベースとしてValgrindとCallgrindを使用します。知っておくべき重要なことは、Valgrindは基本的に仮想マシンであるということです。</target>
        </trans-unit>
        <trans-unit id="6263011d671a27f31d355d03e88575c38e353dc8" translate="yes" xml:space="preserve">
          <source>I'm not sure if there is a nice way to do line-by-line profiling with gprof: &lt;a href=&quot;https://stackoverflow.com/questions/9608949/gprof-time-spent-in-particular-lines-of-code&quot;&gt;`gprof` time spent in particular lines of code&lt;/a&gt;</source>
          <target state="translated">gprofを使用して行&lt;a href=&quot;https://stackoverflow.com/questions/9608949/gprof-time-spent-in-particular-lines-of-code&quot;&gt;ごとの&lt;/a&gt;プロファイリングを行う良い方法があるかどうかはわかりません。特定のコード行で費やされた `gprof`時間</target>
        </trans-unit>
        <trans-unit id="bf065948e194a11f5b37f951703925e3fcde2b09" translate="yes" xml:space="preserve">
          <source>I've been using Gprof the last couple of days and have already found three significant limitations, one of which I've not seen documented anywhere else (yet):</source>
          <target state="translated">ここ数日Gprofを使っていますが、すでに3つの重要な制限があり、そのうちの1つは他のどこにも文書化されていません(まだ)。</target>
        </trans-unit>
        <trans-unit id="9d8fb54a20b1fdf3a9f7cf18def00021f5a8cb9f" translate="yes" xml:space="preserve">
          <source>IMHO identifying the piece that is causing bottleneck is the key here. I'd however try and answer the following questions first and choose tool based on that</source>
          <target state="translated">IMHOでは、ボトルネックの原因となっている部分を特定することが重要です。しかし、私は試してみて、最初に次の質問に答えて、それに基づいてツールを選択します。</target>
        </trans-unit>
        <trans-unit id="dc4e7b05ff6973f04bea57e88cf21f888a6f86ea" translate="yes" xml:space="preserve">
          <source>If you don't have a profiler, use the poor man's profiler. Hit pause while debugging your application. Most developer suites will break into assembly with commented line numbers. You're statistically likely to land in a region that is eating most of your CPU cycles.</source>
          <target state="translated">プロファイラを持っていない場合は、貧乏人のプロファイラを使用してください。アプリケーションのデバッグ中に一時停止を押してください。ほとんどの開発者スイートは、コメントされた行番号でアセンブリを分解します。統計的には、CPU サイクルの大部分を消費しているリージョンに着陸する可能性が高いのです。</target>
        </trans-unit>
        <trans-unit id="41540dddcb3ba901435fd0caa48e769fcf817d8a" translate="yes" xml:space="preserve">
          <source>If your goal is to use a profiler, use one of the suggested ones.</source>
          <target state="translated">プロファイラを使用することを目的としている場合は、推奨されているものを使用してください。</target>
        </trans-unit>
        <trans-unit id="be4b7a0ea0d89ea3adbdc8138fbc2d0f2de5e625" translate="yes" xml:space="preserve">
          <source>In our example, outputs were for &lt;code&gt;-O0&lt;/code&gt;:</source>
          <target state="translated">この例では、出力は &lt;code&gt;-O0&lt;/code&gt; に対するものでした。</target>
        </trans-unit>
        <trans-unit id="431412748fb4a5baa6b65245373a7cfce7f17b4e" translate="yes" xml:space="preserve">
          <source>In this answer, I will use several different tools to a analyze a few very simple test programs, in order to concretely compare how those tools work.</source>
          <target state="translated">この回答では、いくつかの異なるツールを使用して、いくつかの非常に簡単なテストプログラムを分析し、それらのツールがどのように動作するかを具体的に比較します。</target>
        </trans-unit>
        <trans-unit id="635f12c9ec4169045833041b2619bfd5f883a755" translate="yes" xml:space="preserve">
          <source>Intel VTune (&lt;a href=&quot;https://software.intel.com/en-us/vtune&quot;&gt;https://software.intel.com/en-us/vtune&lt;/a&gt;) - If you have intel compilers this is very good</source>
          <target state="translated">Intel VTune（ &lt;a href=&quot;https://software.intel.com/en-us/vtune&quot;&gt;https://software.intel.com/en-us/vtune&lt;/a&gt; ）-Intelコンパイラを使用している場合、これは非常に優れています</target>
        </trans-unit>
        <trans-unit id="4642763219e0fa4ea52daaf7bd5c245926adf1ae" translate="yes" xml:space="preserve">
          <source>It doesn't work properly on multi-threaded code, unless you use a &lt;a href=&quot;http://sam.zoy.org/writings/programming/gprof.html&quot;&gt;workaround&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;http://sam.zoy.org/writings/programming/gprof.html&quot;&gt;回避策&lt;/a&gt;を使用しない限り、マルチスレッドコードでは正しく機能しません。</target>
        </trans-unit>
        <trans-unit id="0a9760c557903dfa3fa680464b187e1b7fe3f2d6" translate="yes" xml:space="preserve">
          <source>It is a sampling profiler, along the lines of the... long... answer by Mike Dunlavey, which will gift wrap the results in a browsable call stack tree, annotated with the time or memory spent in each function, either cumulative or per-function.</source>
          <target state="translated">これはサンプリング・プロファイラで、Mike Dunlaveyの「長い...長い...答え」に沿ったもので、結果をブラウズ可能なコール・スタック・ツリーにラップし、各関数で使用した時間やメモリを累積または関数ごとに注釈を付けてくれます。</target>
        </trans-unit>
        <trans-unit id="2ba19127395eb53bf0dd24f844c9a45fd905b0fe" translate="yes" xml:space="preserve">
          <source>It says &lt;a href=&quot;http://www.cs.utah.edu/dept/old/texinfo/as/gprof.html&quot;&gt;here&lt;/a&gt; that &quot;... the number-of-calls figures are derived by counting, not sampling. They are completely accurate...&quot;. Yet I find my call graph giving me 5345859132+784984078 as call stats to my most-called function, where the first number is supposed to be direct calls, and the second recursive calls (which are all from itself). Since this implied I had a bug, I put in long (64-bit) counters into the code and did the same run again. My counts: 5345859132 direct, and 78094395406 self-recursive calls.  There are a lot of digits there, so I'll point out the recursive calls I measure are 78bn, versus 784m from Gprof: a factor of 100 different. Both runs were single threaded and unoptimised code, one compiled &lt;code&gt;-g&lt;/code&gt; and the other &lt;code&gt;-pg&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://www.cs.utah.edu/dept/old/texinfo/as/gprof.html&quot;&gt;ここでは&lt;/a&gt; 、「呼び出し回数の数値はサンプリングではなく、カウントによって得られたものです。完全に正確です...」と述べています。 それでも、私のコールグラフでは、5345859132 + 784984078が私の最も呼び出された関数の呼び出し統計として、最初の番号が直接呼び出しであり、2番目の再帰呼び出し（すべてそれ自体）であることになっています。 これはバグがあることを意味していたので、長い（64ビット）カウンターをコードに入れ、同じようにもう一度実行しました。 私のカウント：5345859132直接、および78094395406自己再帰呼び出し。 桁数が多いので、測定した再帰呼び出しが78bnであるのに対し、Gprofからの784mは100倍異なることを指摘しておきます。 どちらの実行も、シングルスレッドで最適化されていないコードで、一方は &lt;code&gt;-g&lt;/code&gt; をコンパイルし、もう一方は &lt;code&gt;-pg&lt;/code&gt; をコンパイルしました 。</target>
        </trans-unit>
        <trans-unit id="7cb7e9d2c15a7ea8f0115ba5bd906e6333b013da" translate="yes" xml:space="preserve">
          <source>It will generate a file called &lt;code&gt;callgrind.out.x&lt;/code&gt;. You can then use &lt;code&gt;kcachegrind&lt;/code&gt; tool to read this file. It will give you a graphical analysis of things with results like which lines cost how much.</source>
          <target state="translated">&lt;code&gt;callgrind.out.x&lt;/code&gt; というファイルが生成されます 。 その後、 &lt;code&gt;kcachegrind&lt;/code&gt; ツールを使用してこのファイルを読み取ることができます。 それはあなたに物事のグラフィカルな分析を与え、どの行がどれくらいの費用がかかるかのような結果をもたらします。</target>
        </trans-unit>
        <trans-unit id="76e28acade3cc2a27154df90bec362b0a631dfad" translate="yes" xml:space="preserve">
          <source>It's cross-platform and allows you not to measure performance of your application also in real-time. You can even couple it with a live graph.
Full disclaimer: I am the author.</source>
          <target state="translated">クロスプラットフォームで、アプリケーションのパフォーマンスをリアルタイムで測定することができます。ライブグラフと組み合わせることもできます。完全な免責事項:私は著者です。</target>
        </trans-unit>
        <trans-unit id="4b1a94bb5d0f0a36818c07bf5e21ac7db7f6e83a" translate="yes" xml:space="preserve">
          <source>It's in C++ and must be customized to your needs. Unfortunately I can't share code, just concepts.
You use a &quot;large&quot; &lt;code&gt;volatile&lt;/code&gt; buffer containing timestamps and event ID that you can dump post mortem or after stopping the logging system (and dump this into a file for example).</source>
          <target state="translated">これはC ++で提供されており、ニーズに合わせてカスタマイズする必要があります。 残念ながら、コードを共有することはできません。概念だけです。 タイムスタンプとイベントIDを含む「大きな」 &lt;code&gt;volatile&lt;/code&gt; バッファーを使用します。これは、事後分析またはロギングシステムの停止後にダンプできます（これをファイルにダンプするなど）。</target>
        </trans-unit>
        <trans-unit id="6866c589c53df9bdbafd58f6594aa3b9926e0556" translate="yes" xml:space="preserve">
          <source>Just halt it several times, and each time look at the call stack. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So that is roughly the percentage of samples on which you will see it. There is no educated guesswork required.
If you do have a guess as to what the problem is, this will prove or disprove it.</source>
          <target state="translated">何度か停止させて、その都度コールスタックを見てください。時間を無駄にしているコードがあるとしたら、20%でも50%でも何でもよいのですが、それは各サンプルでそのコードが動作中に見つかる確率です。つまり、これが、それを見ることができるサンプルのおおよその割合です。推測は必要ありません。問題が何であるかを推測することができれば、それを証明するか反証することになります。</target>
        </trans-unit>
        <trans-unit id="c54056bc2b49a6ba4b6c533b7638afae9a9d85da" translate="yes" xml:space="preserve">
          <source>MAP is commercial software.</source>
          <target state="translated">MAPは商用ソフトです。</target>
        </trans-unit>
        <trans-unit id="7f9d5d60edf957a9efb30c849d25e99af6c8e0ff" translate="yes" xml:space="preserve">
          <source>Measurement is horizontal; it tells you what fraction of time specific routines take.
Sampling is vertical.
If there is any way to avoid what the whole program is doing at that moment, &lt;em&gt;and if you see it on a second sample&lt;/em&gt;, you've found the bottleneck.
That's what makes the difference - seeing the whole reason for the time being spent, not just how much.</source>
          <target state="translated">測定は水平です。 特定のルーチンにかかる時間の割合がわかります。 サンプリングは垂直です。 その時点でプログラム全体が行っていることを回避する方法があり、 &lt;em&gt;それが2番目のサンプル&lt;/em&gt;で見られる場合は、ボトルネックが見つかります。 それが違いを生むものです。どれだけ時間がかかっているのかではなく、費やされた時間の全体的な理由を見ることです。</target>
        </trans-unit>
        <trans-unit id="477fe7fb42d087f23d433845410b477d61ad6d95" translate="yes" xml:space="preserve">
          <source>N.B.</source>
          <target state="translated">N.B.</target>
        </trans-unit>
        <trans-unit id="5f635737b21ddea700a64d9ba1681ee8be0ba798" translate="yes" xml:space="preserve">
          <source>Newer kernels (e.g. the latest Ubuntu kernels) come with the new 'perf' tools (&lt;code&gt;apt-get install linux-tools&lt;/code&gt;) AKA &lt;a href=&quot;https://en.wikipedia.org/wiki/Perf_(Linux)&quot;&gt;perf_events&lt;/a&gt;.</source>
          <target state="translated">新しいカーネル（たとえば、最新のUbuntuカーネル）には、新しい「perf」ツール（ &lt;code&gt;apt-get install linux-tools&lt;/code&gt; ）AKA &lt;a href=&quot;https://en.wikipedia.org/wiki/Perf_(Linux)&quot;&gt;perf_eventsが付属してい&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="130b95199b8439c21a930c61f8c68941d88450a0" translate="yes" xml:space="preserve">
          <source>Now it says P(f &amp;gt;= 0.5) is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of &lt;code&gt;I&lt;/code&gt;. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing.</source>
          <target state="translated">ここで、P（f&amp;gt; = 0.5）は26％であり、以前の仮定である0.6％から増加しています。 したがって、ベイズでは、 &lt;code&gt;I&lt;/code&gt; の推定コストの見積もりを更新できます。 データの量が少ない場合、それはコストが正確に何であるかを教えてくれません、それは修正する価値があるほど十分に大きいということだけです。</target>
        </trans-unit>
        <trans-unit id="1cc1ff9a05639f9a0179486bc64f7be0e48efc59" translate="yes" xml:space="preserve">
          <source>Now we have some files named callgrind.out.* in current directory. To see profiling results use:</source>
          <target state="translated">これで、カレントディレクトリに callgrind.out.*という名前のファイルができました。プロファイリングの結果を見るには</target>
        </trans-unit>
        <trans-unit id="3440a6fe929867ee09b71eda8a51b92ff532c181" translate="yes" xml:space="preserve">
          <source>Now when it works and we want to start profiling we should run in another window:</source>
          <target state="translated">これで動作し、プロファイリングを開始したい場合は、別のウィンドウで実行する必要があります。</target>
        </trans-unit>
        <trans-unit id="d3cb823c58e17cf865b583e5a20e385601ec48b1" translate="yes" xml:space="preserve">
          <source>Off the bat, &lt;code&gt;time&lt;/code&gt; tells us that the program took 29.5 seconds to execute, so we had a slowdown of about 15x on this example. Clearly, this slowdown is going to be a serious limitation for larger workloads. On the &quot;real world software example&quot; &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;mentioned here&lt;/a&gt;, I observed a slowdown of 80x.</source>
          <target state="translated">すぐに、 &lt;code&gt;time&lt;/code&gt; はプログラムの実行に29.5秒かかったことを示しているため、この例では約15倍のスローダウンがありました。 明らかに、このスローダウンは、より大きなワークロードにとって深刻な制限になるでしょう。 &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;ここ&lt;/a&gt;で言及した「実際のソフトウェアの例」では、80倍の速度低下が見られました 。</target>
        </trans-unit>
        <trans-unit id="a2a01fb750150dbf6d32038f978233485a2955b5" translate="yes" xml:space="preserve">
          <source>On the a more complex example it becomes clear what the graph means:</source>
          <target state="translated">より複雑な例では、グラフが何を意味するのかが明らかになります。</target>
        </trans-unit>
        <trans-unit id="7ea07b1121db66a159bd732b96f60b6003126f27" translate="yes" xml:space="preserve">
          <source>Once you have understood the data output format, you can reduce verbosity to show just the data without the tutorial with the &lt;code&gt;-b&lt;/code&gt; option:</source>
          <target state="translated">データ出力形式を理解したら、 &lt;code&gt;-b&lt;/code&gt; オプションを使用して、詳細を減らし、チュートリアルなしでデータのみを表示できます。</target>
        </trans-unit>
        <trans-unit id="dbba8950c83f558b0a5b23878c05f60878612272" translate="yes" xml:space="preserve">
          <source>One cool thing about &lt;code&gt;perf&lt;/code&gt; is the FlameGraph tool from Brendan Gregg which displays the call stack timings in a very neat way that allows you to quickly see the big calls. The tool is available at: &lt;a href=&quot;https://github.com/brendangregg/FlameGraph&quot;&gt;https://github.com/brendangregg/FlameGraph&lt;/a&gt; and is also mentioned on his perf tutorial at: &lt;a href=&quot;http://www.brendangregg.com/perf.html#FlameGraphs&quot;&gt;http://www.brendangregg.com/perf.html#FlameGraphs&lt;/a&gt; When I ran &lt;code&gt;perf&lt;/code&gt; without &lt;code&gt;sudo&lt;/code&gt; I got &lt;a href=&quot;https://github.com/brendangregg/FlameGraph/issues/132&quot;&gt;&lt;code&gt;ERROR: No stack counts found&lt;/code&gt;&lt;/a&gt; so for now I'll be doing it with &lt;code&gt;sudo&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;perf&lt;/code&gt; の優れた点の1つは、Brendan GreggのFlameGraphツールです。これにより、コールスタックのタイミングが非常にきちんと表示され、大きなコールをすばやく確認できます。 このツールは、 &lt;a href=&quot;https://github.com/brendangregg/FlameGraph&quot;&gt;https&lt;/a&gt; ： //github.com/brendangregg/FlameGraphで入手できます。また、彼のperfチュートリアルでも言及されてい&lt;a href=&quot;http://www.brendangregg.com/perf.html#FlameGraphs&quot;&gt;ます。http&lt;/a&gt; ： &lt;code&gt;perf&lt;/code&gt; &lt;code&gt;sudo&lt;/code&gt; なしでperfを実行すると、 &lt;a href=&quot;https://github.com/brendangregg/FlameGraph/issues/132&quot;&gt; &lt;code&gt;ERROR: No stack counts found&lt;/code&gt; &lt;/a&gt;ないため、今のところ &lt;code&gt;sudo&lt;/code&gt; で実行します。</target>
        </trans-unit>
        <trans-unit id="e1e2d5fff1404430f80a9893a77239e1b369f4c6" translate="yes" xml:space="preserve">
          <source>P.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup).</source>
          <target state="translated">P.P.S 大まかな一般論として、ソフトウェアに抽象度の高い層があればあるほど、それがパフォーマンスの問題の原因(および高速化の機会)であることに気づく可能性が高くなります。</target>
        </trans-unit>
        <trans-unit id="bbd10fe9dd107bcf29e061a1dbca691e2b9849ec" translate="yes" xml:space="preserve">
          <source>P.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java.</source>
          <target state="translated">追伸:Java のように、ある時点でスレッドプールのコールスタックサンプルを収集する方法があれば、マルチスレッドプログラムでも可能です。</target>
        </trans-unit>
        <trans-unit id="4d12df151686c7a7b5c9580f37caebf54fd9c01a" translate="yes" xml:space="preserve">
          <source>Previously called &quot;Google Performance Tools&quot;, source: &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;https://github.com/gperftools/gperftools&lt;/a&gt; Sample based.</source>
          <target state="translated">以前は「Google Performance Tools」と呼ばれていました。ソース： &lt;a href=&quot;https://github.com/gperftools/gperftools&quot;&gt;https&lt;/a&gt; : //github.com/gperftools/gperftoolsサンプルベース。</target>
        </trans-unit>
        <trans-unit id="4830d80b5bfe85f29931b456dde61e5a468406a7" translate="yes" xml:space="preserve">
          <source>Related question &lt;a href=&quot;https://stackoverflow.com/questions/56672/how-do-you-profile-your-code&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">関連質問は&lt;a href=&quot;https://stackoverflow.com/questions/56672/how-do-you-profile-your-code&quot;&gt;こちら&lt;/a&gt; 。</target>
        </trans-unit>
        <trans-unit id="2577e776d1182d8b8493c8c47c6882960c233679" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;https://stackoverflow.com/questions/10874308/how-to-use-google-perf-tools&quot;&gt;How to use google perf tools&lt;/a&gt;</source>
          <target state="translated">参照： &lt;a href=&quot;https://stackoverflow.com/questions/10874308/how-to-use-google-perf-tools&quot;&gt;Google Perfツールの使用方法&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d6bdcd52d3599e74ca39aae086a3b346358703f1" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;https://stackoverflow.com/questions/46949407/gperftools-profile-file-not-dumped&quot;&gt;gperftools - profile file not dumped&lt;/a&gt;</source>
          <target state="translated">参照： &lt;a href=&quot;https://stackoverflow.com/questions/46949407/gperftools-profile-file-not-dumped&quot;&gt;gperftools-ダンプされないプロファイルファイル&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6298bf00768899707674b3da8584b8c3f21f0334" translate="yes" xml:space="preserve">
          <source>So then I try to benchmark the &lt;code&gt;-O0&lt;/code&gt; program to see if that shows anything, and only now, at last, do I see a call graph:</source>
          <target state="translated">それで、私は &lt;code&gt;-O0&lt;/code&gt; プログラムをベンチマークしてそれが何かを示しているかどうかを確認しようとしています、そして今、ついに、私はコールグラフを見るでしょう：</target>
        </trans-unit>
        <trans-unit id="72cc02d3d1195fc59d61046450268e28e14c7f19" translate="yes" xml:space="preserve">
          <source>So this is what I recommend. Run program first:</source>
          <target state="translated">そこで、私がおすすめするのがこれです。まずプログラムを実行する。</target>
        </trans-unit>
        <trans-unit id="f6772b5f69ff63328b7702c6bb60c75468582ac8" translate="yes" xml:space="preserve">
          <source>So we compile and run as:</source>
          <target state="translated">ということで、コンパイルして実行しています。</target>
        </trans-unit>
        <trans-unit id="cd0d4cbba9f07fc22442ddaca962fad827eac83d" translate="yes" xml:space="preserve">
          <source>So, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If &lt;code&gt;n&lt;/code&gt; samples are taken, and &lt;code&gt;f&lt;/code&gt; is the cost, then &lt;code&gt;I&lt;/code&gt; will appear on &lt;code&gt;nf+/-sqrt(nf(1-f))&lt;/code&gt; samples. Example, &lt;code&gt;n=10&lt;/code&gt;, &lt;code&gt;f=0.3&lt;/code&gt;, that is &lt;code&gt;3+/-1.4&lt;/code&gt; samples.)</source>
          <target state="translated">そのため、非常に少数のサンプルでも、表示される指示のコストについて多くを知ることができます。 （そして、平均して、それらのコストに比例する頻度でそれらを表示します &lt;code&gt;n&lt;/code&gt; サンプルが取得され、 &lt;code&gt;f&lt;/code&gt; がコストである場合、 &lt;code&gt;nf+/-sqrt(nf(1-f))&lt;/code&gt; サンプルに表示されます。例、 &lt;code&gt;n=10&lt;/code&gt; 、 &lt;code&gt;f=0.3&lt;/code&gt; 、つまり &lt;code&gt;3+/-1.4&lt;/code&gt; サンプル）</target>
        </trans-unit>
        <trans-unit id="08239f177013e0b069b1f213aca8eed8d3e8fd03" translate="yes" xml:space="preserve">
          <source>Suppose the prior assumptions are different. Suppose we assume P(f=0.1) is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that &lt;code&gt;I&lt;/code&gt; is cheap. Then we get:</source>
          <target state="translated">以前の仮定が異なると仮定します。 P（f = 0.1）が.991（ほぼ確実）であり、他のすべての可能性はほとんど不可能（0.001）であると仮定します。 言い換えれば、私が一番の確信は &lt;code&gt;I&lt;/code&gt; が安いということです。 その後、次のようになります。</target>
        </trans-unit>
        <trans-unit id="d3b210cd62d3d15648f1f008cbd6a6ff99536cd2" translate="yes" xml:space="preserve">
          <source>TAU (&lt;a href=&quot;http://www.cs.uoregon.edu/research/tau/home.php&quot;&gt;http://www.cs.uoregon.edu/research/tau/home.php&lt;/a&gt;)</source>
          <target state="translated">TAU（ &lt;a href=&quot;http://www.cs.uoregon.edu/research/tau/home.php&quot;&gt;http://www.cs.uoregon.edu/research/tau/home.php&lt;/a&gt; ）</target>
        </trans-unit>
        <trans-unit id="ed5f5a3f654a364aa389b4161a87b5a87e7b8ec1" translate="yes" xml:space="preserve">
          <source>TODO on complex C++ software, I see some entries of type &lt;code&gt;&amp;lt;cycle N&amp;gt;&lt;/code&gt;, e.g. &lt;code&gt;&amp;lt;cycle 11&amp;gt;&lt;/code&gt; where I'd expect function names, what does that mean? I noticed there is a &quot;Cycle Detection&quot; button to toggle that on and off, but what does it mean?</source>
          <target state="translated">複雑なC ++ソフトウェアでTODOを実行すると、タイプ &lt;code&gt;&amp;lt;cycle N&amp;gt;&lt;/code&gt; のエントリがいくつか表示されます。たとえば、 &lt;code&gt;&amp;lt;cycle 11&amp;gt;&lt;/code&gt; では、関数名が必要ですが、どういう意味ですか？ オンとオフを切り替える「サイクル検出」ボタンがあることに気づきましたが、どういう意味ですか？</target>
        </trans-unit>
        <trans-unit id="b13a96071f0d7fdcbc2465e3e45593db4c6ebbfd" translate="yes" xml:space="preserve">
          <source>TODO there are a log of &lt;code&gt;[unknown]&lt;/code&gt; functions in that example, why is that?</source>
          <target state="translated">TODOその例には &lt;code&gt;[unknown]&lt;/code&gt; 関数のログがありますが、それはなぜですか？</target>
        </trans-unit>
        <trans-unit id="a19af3eb40fbc53ad472e0220f8b098385c16862" translate="yes" xml:space="preserve">
          <source>TODO: what happened on the &lt;code&gt;-O3&lt;/code&gt; execution? Is it simply that &lt;code&gt;maybe_slow&lt;/code&gt; and &lt;code&gt;fast&lt;/code&gt; were too fast and did not get any samples? Does it work well with &lt;code&gt;-O3&lt;/code&gt; on larger programs that take longer to execute? Did I miss some CLI option? I found out about &lt;code&gt;-F&lt;/code&gt; to control the sample frequency in Hertz, but I turned it up to the max allowed by default of &lt;code&gt;-F 39500&lt;/code&gt; (could be increased with &lt;code&gt;sudo&lt;/code&gt;) and I still don't see clear calls.</source>
          <target state="translated">TODO： &lt;code&gt;-O3&lt;/code&gt; の実行時に何が起こりましたか？ 単に &lt;code&gt;maybe_slow&lt;/code&gt; と &lt;code&gt;fast&lt;/code&gt; が速すぎてサンプルを取得しなかっただけですか？ 実行に時間がかかる大きなプログラムで &lt;code&gt;-O3&lt;/code&gt; を使用するとうまく機能しますか？ 一部のCLIオプションを見逃しましたか？ ヘルツでサンプル周波数を制御するために &lt;code&gt;-F&lt;/code&gt; について知りましたが、デフォルトで &lt;code&gt;-F 39500&lt;/code&gt; の最大許容値（ &lt;code&gt;sudo&lt;/code&gt; で増やすことができます）まで上げましたが、それでも明確な呼び出しが表示されません。</target>
        </trans-unit>
        <trans-unit id="6dc4e6a8f235d6662619c2b13f904dd1fd3359cb" translate="yes" xml:space="preserve">
          <source>TODO: why is &lt;code&gt;main&lt;/code&gt; missing from the &lt;code&gt;-O3&lt;/code&gt; output, even though I can see it on a &lt;code&gt;bt&lt;/code&gt; in GDB? &lt;a href=&quot;https://stackoverflow.com/questions/39041871/missing-function-from-gprof-output&quot;&gt;Missing function from GProf output&lt;/a&gt; I think it is because gprof is also sampling based in addition to its compiled instrumentation, and the &lt;code&gt;-O3&lt;/code&gt;&lt;code&gt;main&lt;/code&gt; is just too fast and got no samples.</source>
          <target state="translated">TODO：GDBの &lt;code&gt;bt&lt;/code&gt; でそれを見ることができるのに、なぜ &lt;code&gt;-O3&lt;/code&gt; 出力から &lt;code&gt;main&lt;/code&gt; が欠落しているのですか？ &lt;a href=&quot;https://stackoverflow.com/questions/39041871/missing-function-from-gprof-output&quot;&gt;GProf出力からの関数の欠落&lt;/a&gt;私は、gprofがコンパイルされたインストルメンテーションに加えてサンプリングベースであり、 &lt;code&gt;-O3&lt;/code&gt; &lt;code&gt;main&lt;/code&gt; が速すぎてサンプルを得られなかったためだと思います。</target>
        </trans-unit>
        <trans-unit id="6e53b60f1e0dfa855a4eef9b666d7279dabbee1a" translate="yes" xml:space="preserve">
          <source>Tested in Ubuntu 18.04, gprof2dot 2019.11.30, valgrind 3.13.0, perf 4.15.18, Linux kernel 4.15.0, FLameGraph 1a0dc6985aad06e76857cf2a354bd5ba0c9ce96b, gperftools 2.5-2.</source>
          <target state="translated">Ubuntu 18.04、gprof2dot 2019.11.30、valgrind 3.13.0、perf 4.15.18、Linuxカーネル4.15.0、FLameGraph 1a0dc6985aad06e76857cf2a354bd5ba0c9ce96b、gperftools 2.5-2でテストしました。</target>
        </trans-unit>
        <trans-unit id="3a80a1a4fbc3469221b7d5afd5713915cd326c8f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;-O0&lt;/code&gt; output is pretty much self-explanatory. For example, it shows that the 3 &lt;code&gt;maybe_slow&lt;/code&gt; calls and their child calls take up 97.56% of the total runtime, although execution of &lt;code&gt;maybe_slow&lt;/code&gt; itself without children accounts for 0.00% of the total execution time, i.e. almost all the time spent in that function was spent on child calls.</source>
          <target state="translated">&lt;code&gt;-O0&lt;/code&gt; の出力は一目瞭然です。 たとえば、3つの &lt;code&gt;maybe_slow&lt;/code&gt; 呼び出しとその子呼び出しが合計実行時間の97.56％を占めることを示していますが、子なしで &lt;code&gt;maybe_slow&lt;/code&gt; 自体を実行すると、合計実行時間の0.00％を占めます。つまり、その関数で費やされた時間のほとんどすべてが子供の電話に費やした。</target>
        </trans-unit>
        <trans-unit id="e42365e1a6bff7fc2be05d355cadfefbdf5ea497" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;probe&lt;/code&gt; function uses a few assembly lines to retrieve the clock timestamp ASAP and then sets an entry in the buffer. We also have an atomic increment to safely find an index where to store the log event.
Of course buffer is circular.</source>
          <target state="translated">&lt;code&gt;probe&lt;/code&gt; 機能は、いくつかのアセンブリラインを使用してクロックタイムスタンプをできるだけ早く取得し、エントリをバッファに設定します。 ログイベントを格納するインデックスを安全に見つけるためのアトミックな増分もあります。 もちろんバッファは循環しています。</target>
        </trans-unit>
        <trans-unit id="f1066d2d94872d1ccbce2036cf5aac073098024e" translate="yes" xml:space="preserve">
          <source>The answer to run &lt;code&gt;valgrind --tool=callgrind&lt;/code&gt; is not quite complete without some options. We usually do not want to profile 10 minutes of slow startup time under Valgrind and want to profile our program when it is doing some task.</source>
          <target state="translated">&lt;code&gt;valgrind --tool=callgrind&lt;/code&gt; を実行する答えは、いくつかのオプションなしでは完全ではありません。 通常、Valgrindの下での10分の遅い起動時間をプロファイリングしたくないし、何らかのタスクを実行しているときにプログラムをプロファイリングしたいと考えています。</target>
        </trans-unit>
        <trans-unit id="36529a459a19fd1c86e51be05eccbd6859fb938f" translate="yes" xml:space="preserve">
          <source>The call graph gets confused by function pointers. Example: I have a function called &lt;code&gt;multithread()&lt;/code&gt; which enables me to multi-thread a specified function over a specified array (both passed as arguments). Gprof however, views all calls to &lt;code&gt;multithread()&lt;/code&gt; as equivalent for the purposes of computing time spent in children. Since some functions I pass to &lt;code&gt;multithread()&lt;/code&gt; take much longer than others my call graphs are mostly useless. (To those wondering if threading is the issue here: no, &lt;code&gt;multithread()&lt;/code&gt; can optionally, and did in this case, run everything sequentially on the calling thread only).</source>
          <target state="translated">呼び出しグラフは、関数ポインターによって混乱します。 例：私は &lt;code&gt;multithread()&lt;/code&gt; と呼ばれる関数を持っています。これにより、指定された配列（両方とも引数として渡されます）に対して指定された関数をマルチスレッド化できます。 ただし、Gprofは &lt;code&gt;multithread()&lt;/code&gt; へのすべての呼び出しを、子供で費やされた時間を計算する目的で同等と見なしています。 &lt;code&gt;multithread()&lt;/code&gt; に渡す一部の関数は他の関数よりも時間がかかるため、コールグラフはほとんど役に立ちません。 （ここでスレッド化が問題であるかどうか疑問に思う人には、いいえ、 &lt;code&gt;multithread()&lt;/code&gt; はオプションであり、この場合、呼び出しスレッドでのみすべてを順番に実行できます）。</target>
        </trans-unit>
        <trans-unit id="a13b1906e442733e77eedc379dcc29d514b536bc" translate="yes" xml:space="preserve">
          <source>The concept is to define events in &lt;code&gt;tool_events_id.hpp&lt;/code&gt; like that :</source>
          <target state="translated">コンセプトは、 &lt;code&gt;tool_events_id.hpp&lt;/code&gt; ようにtool_events_id.hppでイベントを定義することです：</target>
        </trans-unit>
        <trans-unit id="cdbc70168923d9d12dc32d25f0bf32b6568e5382" translate="yes" xml:space="preserve">
          <source>The downside of this is that there seems to be no Ubuntu package, and building it requires Qt 5.10 while Ubuntu 18.04 is at Qt 5.9.</source>
          <target state="translated">欠点はUbuntuのパッケージがないようで、Ubuntu 18.04がQt 5.9なのに対し、ビルドするにはQt 5.10が必要なことです。</target>
        </trans-unit>
        <trans-unit id="9b0a146d516aab93931f86859127170f3626293f" translate="yes" xml:space="preserve">
          <source>The following test program is very simple and does the following:</source>
          <target state="translated">以下のテストプログラムは非常にシンプルで、以下のようなことを行います。</target>
        </trans-unit>
        <trans-unit id="c15b8d0e65310a3d3e9195caeac933a4e6e84c5b" translate="yes" xml:space="preserve">
          <source>The important thing is that these tools can be &lt;strong&gt;system profiling&lt;/strong&gt; and not just process profiling - they can show the interaction between threads, processes and the kernel and let you understand the scheduling and I/O dependencies between processes.</source>
          <target state="translated">重要なことは、これらのツールはプロセスプロファイリングだけでなく、 &lt;strong&gt;システムプロファイリングに&lt;/strong&gt;もなり得ます。これらは、スレッド、プロセス、およびカーネル間の相互作用を示し、プロセス間のスケジューリングとI / Oの依存関係を理解させます。</target>
        </trans-unit>
        <trans-unit id="b0d289675b93f88ef384de46c84952610710e353" translate="yes" xml:space="preserve">
          <source>The last column says that, for example, the probability that &lt;code&gt;f&lt;/code&gt; &amp;gt;= 0.5 is 92%, up from the prior assumption of 60%.</source>
          <target state="translated">最後の列は、たとえば、 &lt;code&gt;f&lt;/code&gt; &amp;gt; = 0.5である確率が92％であることを示しています。これは、以前の仮定である60％から増加しています。</target>
        </trans-unit>
        <trans-unit id="627640c346afb672f5025becd9584112a15ea55e" translate="yes" xml:space="preserve">
          <source>The nicest way to view this data I've found so far is to make pprof output the same format that kcachegrind takes as input (yes, the Valgrind-project-viewer-tool) and use kcachegrind to view that:</source>
          <target state="translated">私がこれまでに見つけたこのデータを表示する最も良い方法は、kcachegrind が入力として受け取るのと同じ形式 (そう、Valgrind-project-viewer-tools)で pprof を出力させ、それを表示するために kcachegrind を使用することです。</target>
        </trans-unit>
        <trans-unit id="23eff0579ea840d749f7dacd94ef9acf84a98ca9" translate="yes" xml:space="preserve">
          <source>The program interface is:</source>
          <target state="translated">プログラムのインターフェースです。</target>
        </trans-unit>
        <trans-unit id="19c4249e44db6d866c57af334d73685ec61d153c" translate="yes" xml:space="preserve">
          <source>The run generates a profile data file named &lt;code&gt;callgrind.out.&amp;lt;pid&amp;gt;&lt;/code&gt; e.g. &lt;code&gt;callgrind.out.8554&lt;/code&gt; in my case. We view that file with:</source>
          <target state="translated">実行により、 &lt;code&gt;callgrind.out.&amp;lt;pid&amp;gt;&lt;/code&gt; という名前のプロファイルデータファイルが生成されます（私の場合は &lt;code&gt;callgrind.out.8554&lt;/code&gt; ) 。 そのファイルは次のように表示されます。</target>
        </trans-unit>
        <trans-unit id="ed9bf7107eccd71620c4c6d6bab4692580d8a7db" translate="yes" xml:space="preserve">
          <source>The slow call of &lt;code&gt;maybe_slow&lt;/code&gt; is 10x longer, and dominates runtime if we consider calls to the child function &lt;code&gt;common&lt;/code&gt;. Ideally, the profiling tool will be able to point us to the specific slow call.</source>
          <target state="translated">&lt;code&gt;maybe_slow&lt;/code&gt; の遅い呼び出しは10倍長く、子関数 &lt;code&gt;common&lt;/code&gt; の呼び出しを考えるとランタイムを支配します。 理想的には、プロファイリングツールは特定の遅い呼び出しを示すことができます。</target>
        </trans-unit>
        <trans-unit id="b6c8bf98ecf41059e3237cb533da10773d9fb4c5" translate="yes" xml:space="preserve">
          <source>The source for gprof2dot is at: &lt;a href=&quot;https://github.com/jrfonseca/gprof2dot&quot;&gt;https://github.com/jrfonseca/gprof2dot&lt;/a&gt;</source>
          <target state="translated">gprof2dotのソース： &lt;a href=&quot;https://github.com/jrfonseca/gprof2dot&quot;&gt;https&lt;/a&gt; : //github.com/jrfonseca/gprof2dot</target>
        </trans-unit>
        <trans-unit id="769adfccf68fa21aab6b3394b205656f5dab0061" translate="yes" xml:space="preserve">
          <source>Then suppose we take just 2 stack samples, and we see instruction &lt;code&gt;I&lt;/code&gt; on both samples, designated observation &lt;code&gt;o=2/2&lt;/code&gt;. This gives us new estimates of the frequency &lt;code&gt;f&lt;/code&gt; of &lt;code&gt;I&lt;/code&gt;, according to this:</source>
          <target state="translated">次に、2つのスタックサンプルのみを取得し、両方のサンプルに命令 &lt;code&gt;I&lt;/code&gt; が表示され、観測値 &lt;code&gt;o=2/2&lt;/code&gt; 2/2と指定されているとします。 これにより、 &lt;code&gt;f&lt;/code&gt; のよう &lt;code&gt;I&lt;/code&gt; 、 Iの周波数fの新しい推定値が得られます。</target>
        </trans-unit>
        <trans-unit id="7291eec49875f5d9df200c27efdf4f591116af3f" translate="yes" xml:space="preserve">
          <source>Then switch to RELEASE mode and comment out the questionable sections of your code (stub it with nothing) until you see changes in performance.</source>
          <target state="translated">その後、RELEASEモードに切り替えて、パフォーマンスの変化が表示されるまで、コードの疑わしい部分をコメントアウトしてください(何もない状態でスタブしてください)。</target>
        </trans-unit>
        <trans-unit id="2e742db948961b9c3cb6ead916f107d3e8dda15c" translate="yes" xml:space="preserve">
          <source>Then, we can enable the gperftools CPU profiler in two ways: at runtime, or at build time.</source>
          <target state="translated">次に、gperftoolsのCPUプロファイラを有効にするには、実行時とビルド時の2つの方法があります。</target>
        </trans-unit>
        <trans-unit id="924edd37a29a71ab9fe4c8baa007eb8497e44c49" translate="yes" xml:space="preserve">
          <source>There are profilers now that sample the stack, even on wall-clock time, but &lt;em&gt;what comes out&lt;/em&gt; is measurements (or hot path, or hot spot, from which a &quot;bottleneck&quot; can easily hide). What they don't show you (and they easily could) is the actual samples themselves. And if your goal is to &lt;em&gt;find&lt;/em&gt; the bottleneck, the number of them you need to see is, &lt;em&gt;on average&lt;/em&gt;, 2 divided by the fraction of time it takes.
So if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%.</source>
          <target state="translated">現在、実時間でもスタックをサンプリングするプロファイラーがありますが&lt;em&gt;、出てくるの&lt;/em&gt;は測定値（または「ボトルネック」が簡単に隠れてしまうホットパス、またはホットスポット）です。 彼らがあなたに示さない（そして彼らは簡単にできる）とは、実際のサンプルそのものです。 そして、あなたの目標がボトルネックを&lt;em&gt;見つけることで&lt;/em&gt;ある場合、あなたが見る必要があるそれらの数は、 &lt;em&gt;平均して&lt;/em&gt; 、2をそれがかかる時間の割合で割ったものです。 したがって、30％の時間がかかる場合、平均して2 / .3 = 6.7サンプルで表示され、20サンプルで表示される可能性は99.2％です。</target>
        </trans-unit>
        <trans-unit id="7e09a7534638018a7af14062b8d9c917ce457a53" translate="yes" xml:space="preserve">
          <source>There is two different type of profiling</source>
          <target state="translated">プロファイリングには2つのタイプがあります。</target>
        </trans-unit>
        <trans-unit id="571edc923bc5a6cee4f85a019f1c49bdbbf47a9d" translate="yes" xml:space="preserve">
          <source>These are the two methods I use for speeding up my code:</source>
          <target state="translated">これらは私がコードを高速化するために使っている2つの方法です。</target>
        </trans-unit>
        <trans-unit id="8311f0252f91f1308742d21d20d0472314d898dd" translate="yes" xml:space="preserve">
          <source>These come with classic sampling profilers (&lt;a href=&quot;http://manpages.ubuntu.com/manpages/trusty/man1/perf.1.html&quot;&gt;man-page&lt;/a&gt;) as well as the awesome &lt;a href=&quot;http://web.archive.org/web/20090922171904/http://blog.fenrus.org/?p=5&quot;&gt;timechart&lt;/a&gt;!</source>
          <target state="translated">これらには、クラシックなサンプリングプロファイラー（ &lt;a href=&quot;http://manpages.ubuntu.com/manpages/trusty/man1/perf.1.html&quot;&gt;manページ&lt;/a&gt; ）と素晴らしい&lt;a href=&quot;http://web.archive.org/web/20090922171904/http://blog.fenrus.org/?p=5&quot;&gt;タイムチャート&lt;/a&gt;が付属しています 。</target>
        </trans-unit>
        <trans-unit id="e0c6e507414a31dbfe361257f83996883b16fb14" translate="yes" xml:space="preserve">
          <source>They will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find.
They will say it sometimes finds things that aren't problems, but that is only true if you see something &lt;em&gt;once&lt;/em&gt;. If you see a problem on more than one sample, it is real.</source>
          <target state="translated">彼らはまた、実際にはどんなプログラムでも機能するのはおもちゃのプログラムでしか機能しないと言いますが、より大きなプログラムではより多くの問題を発見する傾向があるため、よりうまく機能するようです。 彼らはそれが問題ではないものを見つけることが時々あると言いますが、それはあなたが&lt;em&gt;一度&lt;/em&gt;何かを見た場合にのみ当てはまります。 複数のサンプルに問題がある場合、それは本当です。</target>
        </trans-unit>
        <trans-unit id="83b6b75b50c6b06f6bb30d23afad367e7399b38c" translate="yes" xml:space="preserve">
          <source>This added 0.2s to execution, so we are fine time-wise, but I still don't see much of interest, after expanding the &lt;code&gt;common&lt;/code&gt; node with the keyboard right arrow:</source>
          <target state="translated">これにより、実行に0.2秒が追加されたので、時間的には問題ありませんが、キーボードの右矢印で &lt;code&gt;common&lt;/code&gt; ノードを展開した後は、あまり関心がありません。</target>
        </trans-unit>
        <trans-unit id="6b876e96a3c3578737d673685356fe1f9dcb0ab6" translate="yes" xml:space="preserve">
          <source>This is a response to &lt;a href=&quot;https://stackoverflow.com/a/375930/321731&quot;&gt;Nazgob's Gprof answer&lt;/a&gt;.</source>
          <target state="translated">これは、 &lt;a href=&quot;https://stackoverflow.com/a/375930/321731&quot;&gt;NazgobのGprof回答に対する応答&lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="b830cecda0a3aff113570c5b101b80608993a7f6" translate="yes" xml:space="preserve">
          <source>This turns profiling on. To turn it off and stop whole task we might use:</source>
          <target state="translated">これはプロファイリングをオンにします。オフにしてタスク全体を停止するには、これを使用することができます。</target>
        </trans-unit>
        <trans-unit id="ae3ef8d5cd3e8ccedaacfb1558e954d08cae24db" translate="yes" xml:space="preserve">
          <source>This was GNU &lt;a href=&quot;https://en.wikipedia.org/wiki/Gprof&quot;&gt;Gprof&lt;/a&gt; (GNU Binutils for Debian) 2.18.0.20080103 running under 64-bit Debian Lenny, if that helps anyone.</source>
          <target state="translated">これは、64ビットのDebian Lennyの下で実行されているGNU &lt;a href=&quot;https://en.wikipedia.org/wiki/Gprof&quot;&gt;Gprof&lt;/a&gt; （GNU Binutils for Debian）2.18.0.20080103でした（誰かを助ける場合）。</target>
        </trans-unit>
        <trans-unit id="4809190e35f35121b8cef92d7260543e2698ad83" translate="yes" xml:space="preserve">
          <source>To get more info you can look in &lt;a href=&quot;https://sourceware.org/binutils/docs-2.32/gprof/&quot;&gt;https://sourceware.org/binutils/docs-2.32/gprof/&lt;/a&gt;</source>
          <target state="translated">詳細については、 &lt;a href=&quot;https://sourceware.org/binutils/docs-2.32/gprof/&quot;&gt;https：//sourceware.org/binutils/docs-2.32/gprof/をご覧ください。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d1e75d21749779f1783a936e0318ab574c9bb06" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;-pg&lt;/code&gt; flag when compiling and linking the code and run the executable file. While this program is executed, profiling data is collected in the file a.out.</source>
          <target state="translated">コードをコンパイルおよびリンクし、実行可能ファイルを実行するときは、 &lt;code&gt;-pg&lt;/code&gt; フラグを使用します。 このプログラムの実行中、プロファイリングデータはファイルa.outに収集されます。</target>
        </trans-unit>
        <trans-unit id="74fa418da05131589c58de20bc5cd8a74884137e" translate="yes" xml:space="preserve">
          <source>Use a profiler in DEBUG mode to identify questionable parts of your code</source>
          <target state="translated">DEBUG モードでプロファイラを使用して、コードの疑わしい部分を特定します。</target>
        </trans-unit>
        <trans-unit id="5abe91df474f47b2ce52602a8d2c9a1a1dc9bcdb" translate="yes" xml:space="preserve">
          <source>Use a profiler in RELEASE mode to identify questionable parts of your code.</source>
          <target state="translated">RELEASE モードでプロファイラを使用して、コードの疑わしい部分を特定します。</target>
        </trans-unit>
        <trans-unit id="47e2b39318441908a26389043c5f493a08f3da25" translate="yes" xml:space="preserve">
          <source>Uses time sampling, I/O and CPU bottlenecks are revealed.</source>
          <target state="translated">タイムサンプリングを使用し、IOとCPUのボトルネックを明らかにします。</target>
        </trans-unit>
        <trans-unit id="32ebf48279743cab72d7ff1b43c30c357fa0b5af" translate="yes" xml:space="preserve">
          <source>View gprof output in kcachegrind</source>
          <target state="translated">kcachegrind で gprof の出力を見る</target>
        </trans-unit>
        <trans-unit id="90e10e752882a92276f4abc5b712de714bd30e0f" translate="yes" xml:space="preserve">
          <source>We can observe that file graphically with &lt;code&gt;gprof2dot&lt;/code&gt; as asked at: &lt;a href=&quot;https://stackoverflow.com/questions/2439060/is-it-possible-to-get-a-graphical-representation-of-gprof-results&quot;&gt;Is it possible to get a graphical representation of gprof results?&lt;/a&gt;</source>
          <target state="translated">次のように &lt;code&gt;gprof2dot&lt;/code&gt; でそのファイルをグラフィカルに観察できます： &lt;a href=&quot;https://stackoverflow.com/questions/2439060/is-it-possible-to-get-a-graphical-representation-of-gprof-results&quot;&gt;gprofの結果をグラフィカルに表示することは可能ですか？&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10445757607ecf8a1d5924c1e702bf14a1ff75d2" translate="yes" xml:space="preserve">
          <source>We observe the following for the &lt;code&gt;-O0&lt;/code&gt; run:</source>
          <target state="translated">&lt;code&gt;-O0&lt;/code&gt; を実行すると、次のようになります。</target>
        </trans-unit>
        <trans-unit id="9844986bd80729d071e13db938133404d11ba09f" translate="yes" xml:space="preserve">
          <source>Wherever in you code you can use :</source>
          <target state="translated">あなたのコードのどこにいても、あなたが使用することができます。</target>
        </trans-unit>
        <trans-unit id="674dfbcd4d095f0cd2550aa16069c396575c13ec" translate="yes" xml:space="preserve">
          <source>Which is the best replacement for KProf?</source>
          <target state="translated">KProfの代わりに最適なのはどれですか?</target>
        </trans-unit>
        <trans-unit id="9f5da50867e51ac3a771fd9c2dea086874d61262" translate="yes" xml:space="preserve">
          <source>Yet another way to look at it is called the &lt;a href=&quot;http://en.wikipedia.org/wiki/Rule_of_succession&quot;&gt;Rule Of Succession&lt;/a&gt;.
If you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin?
The respected way to answer is to say that it's a Beta distribution, with average value (number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%.</source>
          <target state="translated">それを見る別の方法は、 &lt;a href=&quot;http://en.wikipedia.org/wiki/Rule_of_succession&quot;&gt;継承&lt;/a&gt;のルールと呼ばれます。 コインを2回裏返して、両方とも表に出た場合、コインの予想される重み付けについて何がわかりますか？ 尊敬される答えは、それがベータ分布であり、平均値（ヒット数+ 1）/（試行回数+ 2）=（2 + 1）/（2 + 2）= 75％であると言うことです。</target>
        </trans-unit>
        <trans-unit id="e477d44b67435b4f2a51bec584b8c8b5c70e29d8" translate="yes" xml:space="preserve">
          <source>You also define a few functions in &lt;code&gt;toolname.hpp&lt;/code&gt; :</source>
          <target state="translated">また、 &lt;code&gt;toolname.hpp&lt;/code&gt; にいくつかの関数を定義します。</target>
        </trans-unit>
        <trans-unit id="d06ead62c5754d4f55d6c94097738323320c25d0" translate="yes" xml:space="preserve">
          <source>You can however use the color map to mitigate those problems a bit. For example, on the previous huge image, I finally managed to find the critical path on the left when I made the brilliant deduction that green comes after red, followed finally by darker and darker blue.</source>
          <target state="translated">しかし、カラーマップを使えば、これらの問題を少しは軽減することができます。例えば、前の巨大画像では、赤の後に緑が来て、最後に青が濃くなっていくという見事な推理をしたときに、最終的に左のクリティカルパスを見つけることができました。</target>
        </trans-unit>
        <trans-unit id="ff319bc3545afd5e52b97cb66321e2f3c78b6c30" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt; with the following options</source>
          <target state="translated">次のオプションで&lt;a href=&quot;http://en.wikipedia.org/wiki/Valgrind&quot;&gt;Valgrind&lt;/a&gt;を使用できます</target>
        </trans-unit>
        <trans-unit id="eff4537042a246b1bfc5a7ac9053825ab352cfb3" translate="yes" xml:space="preserve">
          <source>You can use a logging framework like &lt;a href=&quot;https://github.com/emilk/loguru&quot;&gt;&lt;code&gt;loguru&lt;/code&gt;&lt;/a&gt; since it includes timestamps and total uptime which can be used nicely for profiling:</source>
          <target state="translated">タイムスタンプと合計稼働時間を含み、プロファイリングにうまく使用できるため、 &lt;a href=&quot;https://github.com/emilk/loguru&quot;&gt; &lt;code&gt;loguru&lt;/code&gt; の&lt;/a&gt;ようなロギングフレームワークを使用できます。</target>
        </trans-unit>
        <trans-unit id="57bb7c327c284cab00d7dbfef1ffa24df1be7086" translate="yes" xml:space="preserve">
          <source>You can use the iprof library:</source>
          <target state="translated">iprof ライブラリを使うことができます。</target>
        </trans-unit>
        <trans-unit id="09eee30b7f6c8d8c09d32bfa040a796ee7c00fe5" translate="yes" xml:space="preserve">
          <source>You customize the amount of events generated to focus solely on what you desire. It helped us a lot for scheduling issues while consuming the amount of CPU we wanted based on the amount of logged events per second.</source>
          <target state="translated">生成されるイベントの量をカスタマイズして、欲しいものだけに集中できる。1秒あたりのログイベント量に応じて必要なCPU量を消費しながら、スケジューリングの問題に大きく貢献してくれました。</target>
        </trans-unit>
        <trans-unit id="5885a798125a50436ce410ba3e52f4fbdf4173ce" translate="yes" xml:space="preserve">
          <source>You may have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes.
This &lt;em&gt;magnification effect&lt;/em&gt;, when compounded over multiple problems, can lead to truly massive speedup factors.</source>
          <target state="translated">サイズの異なる複数のパフォーマンスの問題がある場合があります。 それらのいずれかをクリーンアップすると、残りのパスのパーセンテージが大きくなり、後続のパスで見つけやすくなります。 この&lt;em&gt;倍率効果は&lt;/em&gt; 、複数の問題にまたがって複合すると、本当に大規模なスピードアップ要因につながる可能性があります。</target>
        </trans-unit>
        <trans-unit id="016b297a8bba32365f38f766a39676ea6cbcfd2b" translate="yes" xml:space="preserve">
          <source>You need 3 files :</source>
          <target state="translated">3つのファイルが必要です。</target>
        </trans-unit>
        <trans-unit id="747c3ce81ca5b275ec245943d96de7239bf6b766" translate="yes" xml:space="preserve">
          <source>You retrieve the so-called large buffer with all the data and a small interface parses it and shows events with name (up/down + value) like an oscilloscope does with colors (configured in &lt;code&gt;.hpp&lt;/code&gt; file).</source>
          <target state="translated">すべてのデータを含むいわゆる大きなバッファーを取得し、小さなインターフェースがそれを解析して、オシロスコープが色（ &lt;code&gt;.hpp&lt;/code&gt; ファイルで構成）で行うように名前（up / down + value）でイベントを表示します。</target>
        </trans-unit>
        <trans-unit id="2922e093bcf4e627dba20bdf0f73a9644a37a709" translate="yes" xml:space="preserve">
          <source>and for &lt;code&gt;-O3&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;-O3&lt;/code&gt; の場合 ：</target>
        </trans-unit>
        <trans-unit id="2a5be5a09792a69cac7d084de41932a15ba3728f" translate="yes" xml:space="preserve">
          <source>and for the &lt;code&gt;-O3&lt;/code&gt; run:</source>
          <target state="translated">&lt;code&gt;-O3&lt;/code&gt; 実行の場合：</target>
        </trans-unit>
        <trans-unit id="faa969782037f341d207ee39f51209d6317fc20e" translate="yes" xml:space="preserve">
          <source>and the program does &lt;code&gt;O(n^2)&lt;/code&gt; loops in total. &lt;code&gt;seed&lt;/code&gt; is just to get different output without affecting runtime.</source>
          <target state="translated">プログラムは合計で &lt;code&gt;O(n^2)&lt;/code&gt; ループします。 &lt;code&gt;seed&lt;/code&gt; は、ランタイムに影響を与えずに異なる出力を取得することです。</target>
        </trans-unit>
        <trans-unit id="ce2455b67d76414f51f9fe06a8ce80817a3d7dbb" translate="yes" xml:space="preserve">
          <source>are there locks that are proving to be bottle necks ?</source>
          <target state="translated">ボトルネックになっているロックはありますか?</target>
        </trans-unit>
        <trans-unit id="a6f071b118d3c8c52f2a76d5173897fc74f14d94" translate="yes" xml:space="preserve">
          <source>both &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;maybe_slow&lt;/code&gt; call &lt;code&gt;common&lt;/code&gt;, which accounts for the bulk of the program execution</source>
          <target state="translated">プログラムの実行の大部分を占める &lt;code&gt;fast&lt;/code&gt; と &lt;code&gt;maybe_slow&lt;/code&gt; の両方がcommonを呼び出します</target>
        </trans-unit>
        <trans-unit id="9684498d10b2a6f3e91e84082350f59fe31df044" translate="yes" xml:space="preserve">
          <source>but even then, you will be dragging the image around a lot to find what you want, see e.g. this image from a &quot;real&quot; software example taken from &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;this ticket&lt;/a&gt;:</source>
          <target state="translated">しかし、それでも、画像をたくさんドラッグして必要なものを見つけます。たとえば、 &lt;a href=&quot;https://gem5.atlassian.net/browse/GEM5-337&quot;&gt;このチケット&lt;/a&gt;から取得した「実際の」ソフトウェアの例からこの画像を参照してください。</target>
        </trans-unit>
        <trans-unit id="3af4c4be531f706f742d60135390bd70be4af5f9" translate="yes" xml:space="preserve">
          <source>but in such a simple program the output is not very easy to understand, since we can't easily see neither &lt;code&gt;maybe_slow&lt;/code&gt; nor &lt;code&gt;fast&lt;/code&gt; on that graph:</source>
          <target state="translated">しかし、そのような単純なプログラムでは、そのグラフで &lt;code&gt;maybe_slow&lt;/code&gt; も &lt;code&gt;fast&lt;/code&gt; も簡単に確認できないため、出力を理解するのは簡単ではありません。</target>
        </trans-unit>
        <trans-unit id="a7dd0b976062c449381eb00b3b4071e2c243cb98" translate="yes" xml:space="preserve">
          <source>by running the command &lt;code&gt;gprog --flat-profile a.out&lt;/code&gt; you got the following data</source>
          <target state="translated">コマンド &lt;code&gt;gprog --flat-profile a.out&lt;/code&gt; を実行すると、次のデータが得られます</target>
        </trans-unit>
        <trans-unit id="4ad25e6079270f854bc1ab4b0f5c15dda777da63" translate="yes" xml:space="preserve">
          <source>callgrind is the valgrind's tool to profile code and kcachegrind is a KDE program that can visualize cachegrind output.</source>
          <target state="translated">callgrind はコードをプロファイルするための valgrind のツールで、kcachegrind は cachegrind の出力を可視化する KDE プログラムです。</target>
        </trans-unit>
        <trans-unit id="fdde301a4277b76ba71eeffc0b565064e8e3eb36" translate="yes" xml:space="preserve">
          <source>centers around the function that is left indented (&lt;code&gt;maybe_flow&lt;/code&gt;). &lt;code&gt;[3]&lt;/code&gt; is the ID of that function. Above the function, are its callers, and below it the callees.</source>
          <target state="translated">インデントされたままの関数を中心に配置します（ &lt;code&gt;maybe_flow&lt;/code&gt; ）。 &lt;code&gt;[3]&lt;/code&gt; はその関数のIDです。 関数の上に呼び出し元があり、その下に呼び出し先があります。</target>
        </trans-unit>
        <trans-unit id="c86da089418268adb10c8acdbbba40db282822e6" translate="yes" xml:space="preserve">
          <source>generates callgrind.out.x. Read it using kcachegrind.</source>
          <target state="translated">callgrind.out.xを生成します。kcachegrind を使用して読み込みます。</target>
        </trans-unit>
        <trans-unit id="b03467560afe04df21ced900b226b5f9dadcb62d" translate="yes" xml:space="preserve">
          <source>gprof is built-into GCC/binutils, so all we have to do is to compile with the &lt;code&gt;-pg&lt;/code&gt; option to enable gprof. We then run the program normally with a size CLI parameter that produces a run of reasonable duration of a few seconds (&lt;code&gt;10000&lt;/code&gt;):</source>
          <target state="translated">gprofはGCC / binutilsに組み込まれているので、 &lt;code&gt;-pg&lt;/code&gt; オプションを使用してコンパイルしてgprofを有効にするだけです。 次に、通常は数秒（ &lt;code&gt;10000&lt;/code&gt; ）の妥当な期間の実行を生成するサイズCLIパラメーターを使用してプログラムを実行します。</target>
        </trans-unit>
        <trans-unit id="9cb1273641689838d08c035718b933b581323243" translate="yes" xml:space="preserve">
          <source>gprof requires recompiling the software with instrumentation, and it also uses a sampling approach together with that instrumentation. It therefore strikes a balance between accuracy (sampling is not always fully accurate and can skip functions) and execution slowdown (instrumentation and sampling are relatively fast techniques that don't slow down execution very much).</source>
          <target state="translated">gprofはインスツルメンテーションを使用してソフトウェアを再コンパイルする必要がありますが、そのインスツルメンテーションと一緒にサンプリング・アプローチも使用します。そのため、精度(サンプリングは常に完全に正確であるとは限らず、関数をスキップすることもあります)と実行速度の低下(インストルメンテーションとサンプリングは比較的高速な技術であり、実行速度はそれほど低下しません)のバランスをとっています。</target>
        </trans-unit>
        <trans-unit id="6c20dbe559048f4187157de781dccf6f5ba1544e" translate="yes" xml:space="preserve">
          <source>how about IO, handled and optimized ?</source>
          <target state="translated">IO、処理されて最適化されたものはどうですか?</target>
        </trans-unit>
        <trans-unit id="8ad78a2d8b81d1f48b603777d625c316ec818e1d" translate="yes" xml:space="preserve">
          <source>is my algorithm correct ?</source>
          <target state="translated">私のアルゴリズムは正しいのか?</target>
        </trans-unit>
        <trans-unit id="3a13f69d29ec474c66705e3aaadaa6bf50574a2c" translate="yes" xml:space="preserve">
          <source>is there a specific section of code that's proving to be a culprit ?</source>
          <target state="translated">犯人であることを証明しているコードの特定のセクションはありますか?</target>
        </trans-unit>
        <trans-unit id="406e031b8824ea26ae0bf4d7579a1d89e3fb5906" translate="yes" xml:space="preserve">
          <source>main.c</source>
          <target state="translated">main.c</target>
        </trans-unit>
        <trans-unit id="d72ae9adcbb77a799278937f8a9954bf7d5fee38" translate="yes" xml:space="preserve">
          <source>they don't summarize at the instruction level, and</source>
          <target state="translated">指導レベルではまとめてくれないし</target>
        </trans-unit>
        <trans-unit id="813d13060cfdfe274f9dedbcdaad7e87361c8245" translate="yes" xml:space="preserve">
          <source>they give confusing summaries in the presence of recursion.</source>
          <target state="translated">彼らは再帰があると混乱した要約を与えます。</target>
        </trans-unit>
        <trans-unit id="b38e2cc31a913ba13d49dd56d1a341b5650300c3" translate="yes" xml:space="preserve">
          <source>us the command &lt;code&gt;gprof --graph a.out&lt;/code&gt; to get the following data for each function which includes</source>
          <target state="translated">コマンド &lt;code&gt;gprof --graph a.out&lt;/code&gt; を使用して、以下を含む各関数の次のデータを取得します。</target>
        </trans-unit>
        <trans-unit id="5e1acf1cde93e84e5121533952a55ce3fcfa7a9a" translate="yes" xml:space="preserve">
          <source>valgrind runs the program through the valgrind virtual machine. This makes the profiling very accurate, but it also produces a very large slowdown of the program. I have also mentioned kcachegrind previously at: &lt;a href=&quot;https://stackoverflow.com/questions/517589/tools-to-get-a-pictorial-function-call-graph-of-code/31190167#31190167&quot;&gt;Tools to get a pictorial function call graph of code&lt;/a&gt;</source>
          <target state="translated">valgrindは、valgrind仮想マシンを介してプログラムを実行します。 これにより、プロファイリングは非常に正確になりますが、プログラムの速度が非常に遅くなります。 また、以前にkcachegrindについて言及しました： &lt;a href=&quot;https://stackoverflow.com/questions/517589/tools-to-get-a-pictorial-function-call-graph-of-code/31190167#31190167&quot;&gt;コードの画像関数呼び出しグラフを取得するツール&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5572540656d11e87dd5bd966d28d6665bd7fe5af" translate="yes" xml:space="preserve">
          <source>which gives as a familiar call graph like other tools, but with the clunky unit of number of samples rather than seconds.</source>
          <target state="translated">これは、他のツールと同じようにおなじみのコールグラフを提供しますが、サンプル数の単位が秒ではなく不器用なものになっています。</target>
        </trans-unit>
        <trans-unit id="88dc6e662ab6827a52e6b9e9027101485ddfb787" translate="yes" xml:space="preserve">
          <source>which gives:</source>
          <target state="translated">を与える。</target>
        </trans-unit>
        <trans-unit id="6e4de60efe1156a81e465d013cb2669ea775fcd4" translate="yes" xml:space="preserve">
          <source>which shows a GUI that contains data similar to the textual gprof output:</source>
          <target state="translated">これは、テキストのgprof出力と同様のデータを含むGUIを表示します。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
