<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="https://stackoverflow.com/questions/1711631">
    <body>
      <group id="1711631">
        <trans-unit id="cdefc7d8d0f502ac2649cb2130333beb8e549c0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SQLITE_STATIC&lt;/code&gt; tells it that the memory address you gave it will be valid until the query has been performed (which in this loop is always the case). This will save you several allocate, copy and deallocate operations per loop. Possibly a large improvement.</source>
          <target state="translated">&lt;code&gt;SQLITE_STATIC&lt;/code&gt; сообщает, что адрес памяти, который вы дали, будет действителен до тех пор, пока не будет выполнен запрос (что в этом цикле всегда имеет место). Это сэкономит вам несколько операций выделения, копирования и освобождения за цикл. Возможно, большое улучшение.</target>
        </trans-unit>
        <trans-unit id="dc841631c7f8778b9620c5a6aebf79da39172daf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; will cause SQLite to copy the string data before returning.</source>
          <target state="translated">&lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; заставит SQLite скопировать строковые данные перед возвратом.</target>
        </trans-unit>
        <trans-unit id="8e0bb93e0bdc0ef4869a544f1ec90a67170531be" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;I hope you're still with me!&lt;/em&gt; The reason we started down this road is that bulk-insert performance varies so wildly with SQLite, and it's not always obvious what changes need to be made to speed-up our operation. Using the same compiler (and compiler options), the same version of SQLite and the same data we've optimized our code and our usage of SQLite to go &lt;strong&gt;from a worst-case scenario of 85 inserts per second to over 96,000 inserts per second!&lt;/strong&gt;</source>
          <target state="translated">&lt;em&gt;Я надеюсь, что ты все еще со мной!&lt;/em&gt; Причина, по которой мы пошли по этому пути, заключается в том, что производительность массовой вставки так сильно варьируется в SQLite, и не всегда очевидно, какие изменения необходимо внести для ускорения нашей работы. Используя тот же компилятор (и опции компилятора), ту же версию SQLite и те же данные, мы оптимизировали наш код и используем SQLite, чтобы перейти &lt;strong&gt;от наихудшего сценария с 85 вставками в секунду к более чем 96 000 вставок в секунду!&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="651a2b8d1ad8078419cf895a15b4c0df27a8c401" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Let's write some code!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;Давайте напишем некоторый код!&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="b76b98300a521ccc66355329ebd7994a2475558c" translate="yes" xml:space="preserve">
          <source>&lt;s&gt;&lt;a href=&quot;https://github.com/rdpoor/CreateOrUpdate&quot;&gt;https://github.com/rdpoor/CreateOrUpdate&lt;/a&gt;&lt;/s&gt;</source>
          <target state="translated">&lt;s&gt;&lt;a href=&quot;https://github.com/rdpoor/CreateOrUpdate&quot;&gt;https://github.com/rdpoor/CreateOrUpdate&lt;/a&gt;&lt;/s&gt;</target>
        </trans-unit>
        <trans-unit id="7ff38676434e7065905a1e026ab3bdabb754fafc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Avoid &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt;&lt;code&gt;sqlite3_clear_bindings(stmt)&lt;/code&gt;&lt;/a&gt;.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Избегайте &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt; &lt;code&gt;sqlite3_clear_bindings(stmt)&lt;/code&gt; &lt;/a&gt; .&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b52454c570dc6b7585dff89d6bafeb4102012edb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Background:&lt;/strong&gt; We are using SQLite as part of a desktop application. We have large amounts of configuration data stored in XML files that are parsed and loaded into an SQLite database for further processing when the application is initialized. SQLite is ideal for this situation because it's fast, it requires no specialized configuration, and the database is stored on disk as a single file.</source>
          <target state="translated">&lt;strong&gt;Справочная информация:&lt;/strong&gt; Мы используем SQLite как часть настольного приложения. У нас есть большие объемы данных конфигурации, хранящихся в файлах XML, которые анализируются и загружаются в базу данных SQLite для дальнейшей обработки при инициализации приложения. SQLite идеально подходит для этой ситуации, потому что он быстрый, не требует специальной настройки, а база данных хранится на диске в виде одного файла.</target>
        </trans-unit>
        <trans-unit id="270000b21d15ce5fe27f22341bb7e2a04b3d7f99" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Create Index then Insert Data&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Создать индекс, затем вставить данные&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c801cbf9bc118950e73a5431424c376f22274ca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Insert Data then Create Index&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Вставьте данные, затем создайте индекс&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="dbe1b95758ace93ba6c358fe7b1aa18db2be2a7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Note: We are back to using a real database file. In-memory databases are fast, but not necessarily practical&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Примечание: мы вернулись к использованию реального файла базы данных.&lt;/strong&gt; &lt;strong&gt;Базы данных в памяти быстрые, но не обязательно практичные&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="26ea07b172d510db473fb482ce4002bc7313046a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Rationale:&lt;/strong&gt;&lt;em&gt;Initially I was disappointed with the performance I was seeing.&lt;/em&gt; It turns-out that the performance of SQLite can vary significantly (both for bulk-inserts and selects) depending on how the database is configured and how you're using the API. It was not a trivial matter to figure out what all of the options and techniques were, so I thought it prudent to create this community wiki entry to share the results with Stack&amp;nbsp;Overflow readers in order to save others the trouble of the same investigations.</source>
          <target state="translated">&lt;strong&gt;Обоснование:&lt;/strong&gt; &lt;em&gt;Первоначально я был разочарован выступлением, которое я видел.&lt;/em&gt; Оказывается, что производительность SQLite может значительно варьироваться (как для массовых вставок, так и для выборок) в зависимости от того, как настроена база данных и как вы используете API. Было непросто выяснить, какие были все варианты и методы, поэтому я подумал, что было бы разумно создать эту вики-запись сообщества, чтобы поделиться результатами с читателями Stack Overflow, чтобы избавить других от проблем, связанных с теми же исследованиями.</target>
        </trans-unit>
        <trans-unit id="a76bacf9fc05e4ab73ba39928377f27b7df97668" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;The Code:&lt;/strong&gt; A simple C program that reads the text file line-by-line, splits the string into values and then inserts the data into an SQLite database. In this &quot;baseline&quot; version of the code, the database is created, but we won't actually insert data:</source>
          <target state="translated">&lt;strong&gt;Код:&lt;/strong&gt; простая программа на C, которая читает текстовый файл построчно, разбивает строку на значения и затем вставляет данные в базу данных SQLite. В этой &amp;laquo;базовой&amp;raquo; версии кода база данных создана, но мы не будем вставлять данные:</target>
        </trans-unit>
        <trans-unit id="2dfc837caac3acc0839eec2ba05612c43327300d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;The Experiment:&lt;/strong&gt; Rather than simply talking about performance tips in the general sense (i.e. &lt;em&gt;&quot;Use a transaction!&quot;&lt;/em&gt;), I thought it best to write some C code and &lt;em&gt;actually measure&lt;/em&gt; the impact of various options. We're going to start with some simple data:</source>
          <target state="translated">&lt;strong&gt;Эксперимент:&lt;/strong&gt; Вместо того, чтобы просто говорить о советах по повышению производительности в общем смысле (например, &lt;em&gt;&amp;laquo;Использовать транзакцию!&amp;raquo;&lt;/em&gt; ), Я подумал, что лучше написать некоторый код на C и &lt;em&gt;фактически измерить&lt;/em&gt; влияние различных вариантов. Мы собираемся начать с некоторых простых данных:</target>
        </trans-unit>
        <trans-unit id="28ff78fa5b07af5d0e3d7492a98d06fe91ed622f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;UPDATE&lt;/strong&gt;:</source>
          <target state="translated">&lt;strong&gt;UPDATE&lt;/strong&gt;:</target>
        </trans-unit>
        <trans-unit id="d11a8e1d536d373238c3435a955657ece24fd305" translate="yes" xml:space="preserve">
          <source>A 28 MB TAB-delimited text file (approximately 865,000 records) of the &lt;a href=&quot;http://www.toronto.ca/open/datasets/ttc-routes&quot;&gt;complete transit schedule for the city of Toronto&lt;/a&gt;</source>
          <target state="translated">Текстовый файл с разделителями табуляции в 28 МБ (приблизительно 865 000 записей) &lt;a href=&quot;http://www.toronto.ca/open/datasets/ttc-routes&quot;&gt;полного расписания транзита для города Торонто&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7a43bd3a7ef7eab400ead152ddcab810fb34cbd0" translate="yes" xml:space="preserve">
          <source>A little slower than the previous optimization at &lt;strong&gt;64,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Немного медленнее, чем предыдущая оптимизация, со скоростью &lt;strong&gt;64 000 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="9f763d7016e134b7f26a749db3a5f6f6a28b8a9b" translate="yes" xml:space="preserve">
          <source>A slight refactoring to the string processing code used in our parameter binding has allowed us to perform &lt;strong&gt;96,700 inserts per second.&lt;/strong&gt; I think it's safe to say that this is &lt;em&gt;plenty fast&lt;/em&gt;. As we start to tweak other variables (i.e. page size, index creation, etc.) this will be our benchmark.</source>
          <target state="translated">Небольшой рефакторинг кода обработки строки, используемого в нашей привязке параметров, позволил нам выполнить &lt;strong&gt;96 700 вставок в секунду.&lt;/strong&gt; Я думаю, можно с уверенностью сказать, что это &lt;em&gt;достаточно быстро&lt;/em&gt; . Когда мы начнем настраивать другие переменные (например, размер страницы, создание индекса и т. Д.), Это будет нашим эталоном.</target>
        </trans-unit>
        <trans-unit id="8df6f713ac0e07c6021d93f5e0c15401d3336b1d" translate="yes" xml:space="preserve">
          <source>After reading this tutorial, I tried to implement it to my program.</source>
          <target state="translated">Прочитав это учебное пособие,я попытался реализовать его в своей программе.</target>
        </trans-unit>
        <trans-unit id="ea6e032fcc1739cdfb3de8cd3a6c6dfc44b90167" translate="yes" xml:space="preserve">
          <source>After two weeks of research and checking multiple resources: Hard Drive, Ram, Cache, I found out that some settings on your hard drive can affect the I/O rate. By clicking properties on your desired output drive you can see two options in the general tab. Opt1: Compress this drive, Opt2: Allow files of this drive to have contents indexed.</source>
          <target state="translated">После двух недель исследований и проверки множества ресурсов:Hard Drive,Ram,Cache,я обнаружил,что некоторые настройки на вашем жестком диске могут повлиять на скорость ввода-вывода.Щелкнув по свойствам желаемого выходного диска,вы можете увидеть два варианта на общей вкладке.Опция 1:Сожмите этот диск,Опт2:Разрешите индексировать содержимое файлов этого диска.</target>
        </trans-unit>
        <trans-unit id="123802917e1e1b5959658891a69eb20a10c75487" translate="yes" xml:space="preserve">
          <source>Also for us, SHAREDCACHE made the performance slower, so I manually put PRIVATECACHE (cause it was enabled globally for us)</source>
          <target state="translated">Также для нас SHAREDCACHE сделал производительность медленнее,поэтому я вручную поставил PRIVATECACHE (потому что для нас она была включена глобально)</target>
        </trans-unit>
        <trans-unit id="4583ff4050220eaa4631bc21a580cf8fe41b8f3b" translate="yes" xml:space="preserve">
          <source>Although not specifically an SQLite improvement, I don't like the extra &lt;code&gt;char*&lt;/code&gt; assignment operations in the &lt;code&gt;while&lt;/code&gt; loop. Let's quickly refactor that code to pass the output of &lt;code&gt;strtok()&lt;/code&gt; directly into &lt;code&gt;sqlite3_bind_text()&lt;/code&gt;, and let the compiler try to speed things up for us:</source>
          <target state="translated">Хотя это и не является улучшением SQLite, мне не нравятся дополнительные операции присваивания &lt;code&gt;char*&lt;/code&gt; в цикле while. Давайте быстро проведем рефакторинг этого кода, чтобы передать вывод &lt;code&gt;strtok()&lt;/code&gt; непосредственно в &lt;code&gt;sqlite3_bind_text()&lt;/code&gt; , и позволим компилятору попытаться ускорить процесс за нас:</target>
        </trans-unit>
        <trans-unit id="26e259678078857d966992a8f6abac77d4d0cd86" translate="yes" xml:space="preserve">
          <source>As expected, bulk-inserts are slower if one column is indexed, but it does make a difference if the index is created after the data is inserted. Our no-index baseline is 96,000 inserts per second. &lt;strong&gt;Creating the index first then inserting data gives us 47,700 inserts per second, whereas inserting the data first then creating the index gives us 63,300 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Как и ожидалось, массовая вставка выполняется медленнее, если индексирован один столбец, но это имеет значение, если индекс создается после вставки данных. Наш базовый уровень без индекса составляет 96 000 вставок в секунду. &lt;strong&gt;Сначала создание индекса, а затем вставка данных дает нам 47 700 вставок в секунду, тогда как вставка данных сначала, а затем создание индекса дает нам 63 300 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="087e0edf98958c039e2818a7fb1853f6115bf21c" translate="yes" xml:space="preserve">
          <source>Before we start measuring &lt;code&gt;SELECT&lt;/code&gt; performance, we know that we'll be creating indices. It's been suggested in one of the answers below that when doing bulk inserts, it is faster to create the index after the data has been inserted (as opposed to creating the index first then inserting the data). Let's try:</source>
          <target state="translated">Прежде чем мы начнем измерять производительность &lt;code&gt;SELECT&lt;/code&gt; , мы знаем, что будем создавать индексы. В одном из ответов ниже было предложено, чтобы при массовых вставках индекс быстрее создавался после вставки данных (в отличие от создания индекса сначала, а затем вставки данных). Давай попробуем:</target>
        </trans-unit>
        <trans-unit id="872e67d1abe340cdbf86668e654d983f7d5c9e25" translate="yes" xml:space="preserve">
          <source>Bulk imports seems to perform best if you can chunk your &lt;strong&gt;INSERT/UPDATE&lt;/strong&gt; statements.  A value of 10,000 or so has worked well for me on a table with only a few rows, YMMV...</source>
          <target state="translated">Массовый импорт лучше всего работает, если вы можете разделить свои операторы &lt;strong&gt;INSERT / UPDATE&lt;/strong&gt; . Значение 10 000 или около того хорошо сработало для меня в таблице с несколькими строками, YMMV ...</target>
        </trans-unit>
        <trans-unit id="671341a42a7c965624dd8daf9888d2a9ef366288" translate="yes" xml:space="preserve">
          <source>By default, SQLite will evaluate every INSERT / UPDATE statement within a unique transaction. If performing a large number of inserts, it's advisable to wrap your operation in a transaction:</source>
          <target state="translated">По умолчанию,SQLite будет оценивать каждый оператор INSERT UPDATE внутри уникальной транзакции.При выполнении большого количества вставок рекомендуется завершать операцию в транзакцию:</target>
        </trans-unit>
        <trans-unit id="bbd325acdd91b4ca873182b6a019ce434225ae43" translate="yes" xml:space="preserve">
          <source>By default, SQLite will pause after issuing a OS-level write command. This guarantees that the data is written to the disk. By setting &lt;code&gt;synchronous = OFF&lt;/code&gt;, we are instructing SQLite to simply hand-off the data to the OS for writing and then continue. There's a chance that the database file may become corrupted if the computer suffers a catastrophic crash (or power failure) before the data is written to the platter:</source>
          <target state="translated">По умолчанию SQLite приостанавливается после выдачи команды записи на уровне ОС. Это гарантирует, что данные будут записаны на диск. Устанавливая &lt;code&gt;synchronous = OFF&lt;/code&gt; , мы инструктируем SQLite просто передать данные в ОС для записи и затем продолжить. Существует вероятность того, что файл базы данных может быть поврежден, если на компьютере произойдет катастрофический сбой (или сбой питания) перед записью данных на диск:</target>
        </trans-unit>
        <trans-unit id="9021172ebb7b79e513f34761501efc24dc16188c" translate="yes" xml:space="preserve">
          <source>By disabling these two options all 3 PCs now take approximately the same time to finish (1hr and 20 to 40min). If you encounter slow inserts check whether your hard drive is configured with these options. It will save you lots of time and headaches trying to find the solution</source>
          <target state="translated">Отключив эти два варианта,все 3 компьютера теперь занимают примерно одинаковое время (1 час и от 20 до 40 минут).Если вы столкнулись с медленными вставками,проверьте,настроен ли ваш жесткий диск с этими опциями.Это сэкономит вам много времени и головной боли при попытке найти решение.</target>
        </trans-unit>
        <trans-unit id="b433a2b1f636acc88cf161d1b849771010a891d6" translate="yes" xml:space="preserve">
          <source>CREATE INDEX then INSERT vs. INSERT then CREATE INDEX</source>
          <target state="translated">CREATE INDEX затем INSERT vs.INSERT then CREATE INDEX</target>
        </trans-unit>
        <trans-unit id="3a324f600d2cc2caa3c71c2e0bb04baf34e8a893" translate="yes" xml:space="preserve">
          <source>Call bulkInsert method :</source>
          <target state="translated">Вызвать метод bulkInsert :</target>
        </trans-unit>
        <trans-unit id="bcdd9e61da1685f26f0ee4233e52764e50d2bfe3" translate="yes" xml:space="preserve">
          <source>Consider storing the rollback journal in memory by evaluating &lt;code&gt;PRAGMA journal_mode = MEMORY&lt;/code&gt;. Your transaction will be faster, but if you lose power or your program crashes during a transaction you database could be left in a corrupt state with a partially-completed transaction:</source>
          <target state="translated">Рассмотрите возможность сохранения журнала отката в памяти, оценивая &lt;code&gt;PRAGMA journal_mode = MEMORY&lt;/code&gt; . Ваша транзакция будет быстрее, но если вы потеряете энергию или ваша программа выйдет из строя во время транзакции, ваша база данных может остаться в поврежденном состоянии с частично завершенной транзакцией:</target>
        </trans-unit>
        <trans-unit id="9f72f2c529b0b1804a0aaf2ee6c8d2facf67621b" translate="yes" xml:space="preserve">
          <source>Don't use &lt;code&gt;!feof(file)&lt;/code&gt;!</source>
          <target state="translated">Не используйте &lt;code&gt;!feof(file)&lt;/code&gt; !</target>
        </trans-unit>
        <trans-unit id="4326aa174e0a3d69e5993b7a70921bb5ff0f2f6e" translate="yes" xml:space="preserve">
          <source>Fantastic! We're able to do &lt;strong&gt;72,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Фантастика! Мы можем сделать &lt;strong&gt;72 000 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="bfc83a3f5364bbc68fa36baf227468de56749928" translate="yes" xml:space="preserve">
          <source>First find the items, in the table:</source>
          <target state="translated">Сначала найдите предметы,в таблице:</target>
        </trans-unit>
        <trans-unit id="090aa308f4299a2ee89598663268aa093622fa6a" translate="yes" xml:space="preserve">
          <source>For older versions of SQLite - Consider a less paranoid journal mode (&lt;code&gt;pragma journal_mode&lt;/code&gt;). There is &lt;code&gt;NORMAL&lt;/code&gt;, and then there is &lt;code&gt;OFF&lt;/code&gt;, which can significantly increase insert speed if you're not too worried about the database possibly getting corrupted if the OS crashes. If your application crashes the data should be fine. Note that in newer versions, the &lt;code&gt;OFF/MEMORY&lt;/code&gt; settings are not safe for application level crashes.</source>
          <target state="translated">Для более старых версий SQLite - рассмотрите менее параноидальный режим журнала ( &lt;code&gt;pragma journal_mode&lt;/code&gt; ). Есть &lt;code&gt;NORMAL&lt;/code&gt; , а затем &lt;code&gt;OFF&lt;/code&gt; , что может значительно увеличить скорость вставки, если вы не слишком беспокоитесь о возможном повреждении базы данных в случае сбоя ОС. Если ваше приложение дает сбой, данные должны быть в порядке. Обратите внимание, что в более новых версиях настройки &lt;code&gt;OFF/MEMORY&lt;/code&gt; небезопасны для сбоев на уровне приложений.</target>
        </trans-unit>
        <trans-unit id="2195eed65de850d03a01f0bdc090231f2d372a07" translate="yes" xml:space="preserve">
          <source>For our small (200mb) db this made 50-75% speed-up (3.8.0.2 64-bit on Windows 7). Our tables are heavily non-normalized (1000-1500 columns, roughly 100,000 or more rows).</source>
          <target state="translated">Для нашего небольшого (200мб)дб это составило 50-75%-ное ускорение (3.8.0.2 64-битное на Windows 7).Наши таблицы сильно ненормализованы (1000-1500 столбцов,примерно 100 000 и более рядов).</target>
        </trans-unit>
        <trans-unit id="76b075177903579178f27a07d252a978c4cb462b" translate="yes" xml:space="preserve">
          <source>Great! We can do 920,000 inserts per second, provided we don't actually do any inserts :-)</source>
          <target state="translated">Здорово! Мы можем делать 920,000 вставок в секунду,при условии,что мы на самом деле не делаем никаких вставок :-).</target>
        </trans-unit>
        <trans-unit id="6f22b5c109f71a3ddf56af02c88cbacffcd2a204" translate="yes" xml:space="preserve">
          <source>Here is where your suggestion fails. You use a single transaction for all the records and a single insert with no errors/fails. Let's say that you are splitting each record into multiple inserts on different tables. What happens if the record is broken?</source>
          <target state="translated">Вот где ваше предложение провалилось.Вы используете одну транзакцию для всех записей и одну вставку без ошибок.Допустим,вы разбиваете каждую запись на несколько вставок на разных таблицах.Что произойдет,если запись будет разбита?</target>
        </trans-unit>
        <trans-unit id="026af1bc2703948250f4b6f33ec6faec09054f5b" translate="yes" xml:space="preserve">
          <source>I coudn't get any gain from transactions until I raised cache_size to a higher value i.e.  &lt;code&gt;PRAGMA cache_size=10000;&lt;/code&gt;</source>
          <target state="translated">Я не смог получить никакой прибыли от транзакций, пока не поднял cache_size до более высокого значения, т.е. &lt;code&gt;PRAGMA cache_size=10000;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8eecbe52b4dec4bfb03e25ab1108fd0f15070e96" translate="yes" xml:space="preserve">
          <source>I have 4-5 files that contain addresses. Each file has approx 30 million records. I am using the same configuration that you are suggesting but my number of INSERTs per second is way low (~10.000 records per sec).</source>
          <target state="translated">У меня есть 4-5 файлов,содержащих адреса.В каждом файле около 30 миллионов записей.Я использую ту же самую конфигурацию,что и вы,но мое количество INSERT в секунду очень мало (~10.000 записей в секунду).</target>
        </trans-unit>
        <trans-unit id="11917b0c226929497af8ba620faa1e4b102c1e64" translate="yes" xml:space="preserve">
          <source>I'd gladly take suggestions for other scenarios to try... And will be compiling similar data for SELECT queries soon.</source>
          <target state="translated">Я с удовольствием приму предложения по другим сценариям,чтобы попробовать...И в скором времени буду компилировать аналогичные данные для запросов SELECT.</target>
        </trans-unit>
        <trans-unit id="5172e4b2cd07b7be64b179445d83376ec1008f29" translate="yes" xml:space="preserve">
          <source>I'm using it in production code where I frequently need to import large datasets, and I'm pretty happy with it.</source>
          <target state="translated">Я использую его в производственном коде,где мне часто приходится импортировать большие наборы данных,и меня это вполне устраивает.</target>
        </trans-unit>
        <trans-unit id="3ac5e5ce6fc4a6695514c6dae964ca288c928cef" translate="yes" xml:space="preserve">
          <source>I'm using the SQLite &quot;Amalgamation&quot;, compiled directly into my test application. The SQLite version I happen to have is a bit older (3.6.7), but I suspect these results will be comparable to the latest release (please leave a comment if you think otherwise).</source>
          <target state="translated">Я использую SQLite &quot;Amalgamation&quot;,скомпилированный непосредственно в моем тестовом приложении.Так получилось,что версия SQLite у меня немного старше (3.6.7),но я подозреваю,что эти результаты будут сравнимы с последним релизом (пожалуйста,оставьте комментарий,если вы думаете иначе).</target>
        </trans-unit>
        <trans-unit id="46f70793f4a5cfd620882059cb0f77361cfd03c5" translate="yes" xml:space="preserve">
          <source>I've also asked similar questions &lt;a href=&quot;https://stackoverflow.com/questions/784173/what-are-the-performance-characteristics-of-sqlite-with-very-large-database-files&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://stackoverflow.com/questions/768708/are-there-known-issues-with-using-sqlite-and-file-locking-on-different-platforms&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">Я также задавал похожие вопросы &lt;a href=&quot;https://stackoverflow.com/questions/784173/what-are-the-performance-characteristics-of-sqlite-with-very-large-database-files&quot;&gt;здесь&lt;/a&gt; и &lt;a href=&quot;https://stackoverflow.com/questions/768708/are-there-known-issues-with-using-sqlite-and-file-locking-on-different-platforms&quot;&gt;здесь&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dfe5fd5527d0cb852bc797c4c3ee406f746ecc8c" translate="yes" xml:space="preserve">
          <source>If anyone has any other ideas on how to speed it up, I am open to suggestions.</source>
          <target state="translated">Если у кого-нибудь есть другие идеи,как ускорить процесс,я открыт для предложений.</target>
        </trans-unit>
        <trans-unit id="7d973398e85df8aa77d57e79abb3b81143a022d7" translate="yes" xml:space="preserve">
          <source>If you are using multiple threads, you can try using the &lt;a href=&quot;http://sqlite.org/c3ref/enable_shared_cache.html&quot;&gt;shared page cache&lt;/a&gt;, which will allow loaded pages to be shared between threads, which can avoid expensive I/O calls.</source>
          <target state="translated">Если вы используете несколько потоков, вы можете попробовать использовать &lt;a href=&quot;http://sqlite.org/c3ref/enable_shared_cache.html&quot;&gt;общий кеш страниц&lt;/a&gt; , который позволит загруженным страницам делиться между потоками, что позволит избежать дорогостоящих вызовов ввода-вывода.</target>
        </trans-unit>
        <trans-unit id="9909caa1776cc754ea391a5613c40fbd59f9912b" translate="yes" xml:space="preserve">
          <source>If you care only about reading, somewhat faster (but might read stale data) version is to read from multiple connections from multiple threads (connection per-thread).</source>
          <target state="translated">Если вас интересует только чтение,то несколько более быстрая (но,возможно,читающая залежавшиеся данные)версия-это чтение из нескольких соединений из нескольких потоков (соединение на поток).</target>
        </trans-unit>
        <trans-unit id="0b5e37f7ae64ee540105a2d6879bb33438066595" translate="yes" xml:space="preserve">
          <source>If you have indices, consider calling &lt;code&gt;CREATE INDEX&lt;/code&gt; after doing all your inserts. This is significantly faster than creating the index and then doing your inserts.</source>
          <target state="translated">Если у вас есть индексы, рассмотрите возможность вызова &lt;code&gt;CREATE INDEX&lt;/code&gt; после выполнения всех ваших вставок. Это значительно быстрее, чем создание индекса и последующая вставка.</target>
        </trans-unit>
        <trans-unit id="050d6cf06387f361bcb1b0a00b8117a50e73b6db" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 0.94
  seconds</source>
          <target state="translated">Импортированные 864913 записей за 0,94 секунды</target>
        </trans-unit>
        <trans-unit id="ffb4f30cad268801a7084f86177635a7739c17eb" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 10.94
  seconds</source>
          <target state="translated">Импортированные 864913 записей за 10,94 секунды</target>
        </trans-unit>
        <trans-unit id="ad66121de714d2631e9f96a8c355fd562e17c3d9" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 12.00
  seconds</source>
          <target state="translated">Импорт 864913 записей за 12.00 секунды</target>
        </trans-unit>
        <trans-unit id="7581475071859f0e2df5c5baa78a47d7b29eb343" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 12.41
  seconds</source>
          <target state="translated">Импорт 864913 записей за 12,41 секунды</target>
        </trans-unit>
        <trans-unit id="1fb6a8f5771eb996d9c96dec9c9972b1f7a9e674" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 13.50
  seconds</source>
          <target state="translated">Импорт 864913 записей за 13,50 секунды</target>
        </trans-unit>
        <trans-unit id="d736e88540c433cf8f1e9c878c95b8f56e1ea201" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 13.66
  seconds</source>
          <target state="translated">Импортированные 864913 записей за 13,66 секунды</target>
        </trans-unit>
        <trans-unit id="9cf20009ccbdebfe12b3df7ef0636a31ba57d3da" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 16.27
  seconds</source>
          <target state="translated">Импортированные 864913 записей за 16,27 секунды</target>
        </trans-unit>
        <trans-unit id="8df99d63ed560901211f5c08656f730de84694b0" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 18.13
  seconds</source>
          <target state="translated">Импорт 864913 записей за 18,13 секунды</target>
        </trans-unit>
        <trans-unit id="1c548ea621ed72950e828c5b68b12bf11f6ff451" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 38.03
  seconds</source>
          <target state="translated">Импорт 864913 записей за 38,03 секунды</target>
        </trans-unit>
        <trans-unit id="154309e441b9898bacf87ed35cc90b6b605fec43" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 8.94
  seconds</source>
          <target state="translated">Импортированные 864913 записей за 8,94 секунды</target>
        </trans-unit>
        <trans-unit id="e912b781943a231d89776110872a3ee052f22c58" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 9933.61
  seconds</source>
          <target state="translated">Импорт 864913 записей за 9933,61 секунды</target>
        </trans-unit>
        <trans-unit id="5c0542021a1c71e3d1128b2a31c3b68cde8950f7" translate="yes" xml:space="preserve">
          <source>Improve INSERT-per-second performance of SQLite</source>
          <target state="translated">Улучшение производительности INSERT в секунду для SQLite</target>
        </trans-unit>
        <trans-unit id="437377a502bface456863ef3ef3ca4aa7c7b5e37" translate="yes" xml:space="preserve">
          <source>In Addition to my answer above, you should keep in mind that inserts per second depending on the hard drive you are using too. I tested it on 3 different PCs with different hard drives and got massive differences in times. PC1 (1hr 30m), PC2 (6hrs) PC3 (14hrs), so I started wondering why would that be.</source>
          <target state="translated">В дополнение к моему ответу выше,вы должны помнить,что вставки в секунду в зависимости от жесткого диска,который вы используете также.Я тестировал его на 3-х разных компьютерах с разными жесткими дисками и получил огромную разницу во времени.PC1 (1 час 30 минут),PC2 (6 часов)PC3 (14 часов),поэтому я начал задаваться вопросом,с чего бы это.</target>
        </trans-unit>
        <trans-unit id="084c1b49fd936281f7874c2b66922cccc3363366" translate="yes" xml:space="preserve">
          <source>Inspired by this post and by the Stack Overflow question that led me here -- &lt;a href=&quot;https://stackoverflow.com/questions/1609637/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database&quot;&gt;Is it possible to insert multiple rows at a time in an SQLite database?&lt;/a&gt; -- I've posted my first &lt;a href=&quot;http://en.wikipedia.org/wiki/Git_%28software%29&quot;&gt;Git&lt;/a&gt; repository:</source>
          <target state="translated">Вдохновленный этим постом и вопросом о переполнении стека, который привел меня сюда - &lt;a href=&quot;https://stackoverflow.com/questions/1609637/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database&quot;&gt;можно ли одновременно вставлять несколько строк в базу данных SQLite?&lt;/a&gt; - Я разместил свой первый &lt;a href=&quot;http://en.wikipedia.org/wiki/Git_%28software%29&quot;&gt;Git-&lt;/a&gt; репозиторий:</target>
        </trans-unit>
        <trans-unit id="c680b9c6bf7b7bee16783907b9286d2edf9090e1" translate="yes" xml:space="preserve">
          <source>It's not super-practical to store our database in RAM, but it's impressive that we can perform &lt;strong&gt;79,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Хранить нашу базу данных в ОЗУ непросто, но впечатляет то, что мы можем выполнять &lt;strong&gt;79 000 операций вставки в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a48a72fa6f2a189900ebabff54aef564cc57e5d1" translate="yes" xml:space="preserve">
          <source>Just for kicks, let's build upon all of the previous optimizations and redefine the database filename so we're working entirely in RAM:</source>
          <target state="translated">Просто для удара,давайте будем основываться на всех предыдущих оптимизациях и переопределим имя файла базы данных,так что мы работаем полностью в оперативной памяти:</target>
        </trans-unit>
        <trans-unit id="def03dbbcc838f12adc51dd0a6831295811e8a51" translate="yes" xml:space="preserve">
          <source>Let's combine the previous two optimizations. It's a little more risky (in case of a crash), but we're just importing data (not running a bank):</source>
          <target state="translated">Давайте скомбинируем две предыдущие оптимизации.Это немного более рискованно (в случае краха),но мы просто импортируем данные (а не запускаем банк):</target>
        </trans-unit>
        <trans-unit id="fff50fdf32382d53297912d58830059c40882d48" translate="yes" xml:space="preserve">
          <source>Link: &lt;a href=&quot;https://www.vogella.com/tutorials/AndroidSQLite/article.html&quot;&gt;https://www.vogella.com/tutorials/AndroidSQLite/article.html&lt;/a&gt;
check Using ContentProvider Section for more details</source>
          <target state="translated">Ссылка: &lt;a href=&quot;https://www.vogella.com/tutorials/AndroidSQLite/article.html&quot;&gt;https://www.vogella.com/tutorials/AndroidSQLite/article.html&lt;/a&gt; проверка Использование раздела ContentProvider для получения более подробной информации</target>
        </trans-unit>
        <trans-unit id="cef93c612411b122f72e46695577441dc0b9538a" translate="yes" xml:space="preserve">
          <source>More detail: &lt;a href=&quot;http://www.hoogli.com/blogs/micro/index.html#Avoid_sqlite3_clear_bindings%28%29&quot;&gt;Avoid_sqlite3_clear_bindings()&lt;/a&gt;</source>
          <target state="translated">Более подробно: &lt;a href=&quot;http://www.hoogli.com/blogs/micro/index.html#Avoid_sqlite3_clear_bindings%28%29&quot;&gt;Avoid_sqlite3_clear_bindings ()&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd6066b18d7c77401d867d16f3862c393664eb4f" translate="yes" xml:space="preserve">
          <source>My solution was to use &lt;strong&gt;multiple&lt;/strong&gt; transactions. I begin and end a transaction every 10.000 records (Don't ask why that number, it was the fastest one I tested). I created an array sized 10.000 and insert the successful records there. When the error occurs, I do a rollback, begin a transaction, insert the records from my array, commit and then begin a new transaction after the broken record.</source>
          <target state="translated">Моим решением было использовать &lt;strong&gt;несколько&lt;/strong&gt; транзакций. Я начинаю и заканчиваю транзакцию каждые 10.000 записей (не спрашивайте, почему это число, оно было самым быстрым, которое я проверял). Я создал массив размером 10.000 и вставил туда успешные записи. Когда происходит ошибка, я делаю откат, начинаю транзакцию, вставляю записи из моего массива, фиксирую и затем начинаю новую транзакцию после поврежденной записи.</target>
        </trans-unit>
        <trans-unit id="6b739c10e74293364ba0d24439f65294b7e5a99a" translate="yes" xml:space="preserve">
          <source>My test machine is a 3.60 GHz P4 running Windows XP.</source>
          <target state="translated">Моя тестовая машина-это P4 с частотой 3,60 ГГц под управлением Windows XP.</target>
        </trans-unit>
        <trans-unit id="725b0e5796b8baedf9846345cfd466c118fc41d9" translate="yes" xml:space="preserve">
          <source>Nice! There's a little bit more code (don't forget to call &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; and &lt;code&gt;sqlite3_reset&lt;/code&gt;), but we've more than doubled our performance to &lt;strong&gt;53,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Ницца! Есть немного больше кода (не забудьте вызвать &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; и &lt;code&gt;sqlite3_reset&lt;/code&gt; ), но мы более чем удвоили нашу производительность до &lt;strong&gt;53 000 операций вставки в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="71cb481da4769935c7cb6729efb5b6f47e162d66" translate="yes" xml:space="preserve">
          <source>On bulk inserts</source>
          <target state="translated">На оптовых вставках</target>
        </trans-unit>
        <trans-unit id="23976e24ccb5c88d260af95f9f2b0d95e8f2c905" translate="yes" xml:space="preserve">
          <source>Optimizing SQLite is tricky. Bulk-insert performance of a C application can vary from 85 inserts per second to over 96,000 inserts per second!</source>
          <target state="translated">Оптимизировать SQLite сложно.Объемная производительность приложения на C может варьироваться от 85 вставок в секунду до более 96,000 вставок в секунду!</target>
        </trans-unit>
        <trans-unit id="b15b2b66aeaf59f9d4af467b7dce9e1e809af568" translate="yes" xml:space="preserve">
          <source>PRAGMA journal_mode = MEMORY</source>
          <target state="translated">PRAGMA log_mode=ПАМЯТЬ</target>
        </trans-unit>
        <trans-unit id="03a9d7f69c55c2b9bb13076c851bb0c196528d38" translate="yes" xml:space="preserve">
          <source>PRAGMA synchronous = OFF</source>
          <target state="translated">ПРАГМА синхронная=ВЫКЛЮЧЕНО</target>
        </trans-unit>
        <trans-unit id="e1c75641cd03f3af313aee27467012f92b04b104" translate="yes" xml:space="preserve">
          <source>PRAGMA synchronous = OFF &lt;em&gt;and&lt;/em&gt; PRAGMA journal_mode = MEMORY</source>
          <target state="translated">PRAGMA синхронно = ВЫКЛ &lt;em&gt;и&lt;/em&gt; PRAGMA journal_mode = ПАМЯТЬ</target>
        </trans-unit>
        <trans-unit id="847bfcdea40fa982b77f7b8713d9d1c6b544bfb7" translate="yes" xml:space="preserve">
          <source>Playing with page sizes makes a difference as well (&lt;code&gt;PRAGMA page_size&lt;/code&gt;). Having larger page sizes can make reads and writes go a bit faster as larger pages are held in memory. Note that more memory will be used for your database.</source>
          <target state="translated">Игра с размерами страниц также имеет значение ( &lt;code&gt;PRAGMA page_size&lt;/code&gt; ). Наличие страниц большего размера может сделать чтение и запись более быстрыми, поскольку большие страницы хранятся в памяти. Обратите внимание, что для вашей базы данных будет использовано больше памяти.</target>
        </trans-unit>
        <trans-unit id="e22067ebafc73b20c18e9861a705da211f5109b2" translate="yes" xml:space="preserve">
          <source>Prior to calling &lt;a href=&quot;https://www.sqlite.org/c3ref/step.html&quot;&gt;sqlite3_step()&lt;/a&gt; for the first time or immediately
  after &lt;a href=&quot;https://www.sqlite.org/c3ref/reset.html&quot;&gt;sqlite3_reset()&lt;/a&gt;, the application can invoke the
  &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind()&lt;/a&gt; interfaces to attach values to the parameters. Each
  call to &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind()&lt;/a&gt; overrides prior bindings on the same parameter</source>
          <target state="translated">Перед вызовом &lt;a href=&quot;https://www.sqlite.org/c3ref/step.html&quot;&gt;sqlite3_step ()&lt;/a&gt; в первый раз или сразу после &lt;a href=&quot;https://www.sqlite.org/c3ref/reset.html&quot;&gt;sqlite3_reset ()&lt;/a&gt; приложение может вызвать интерфейсы &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind ()&lt;/a&gt; для присоединения значений к параметрам. Каждый вызов &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind ()&lt;/a&gt; переопределяет предыдущие привязки для одного и того же параметра</target>
        </trans-unit>
        <trans-unit id="d1dc6289bf46af7ecb10109083938ec233b12f44" translate="yes" xml:space="preserve">
          <source>Put inserts/updates in a transaction.</source>
          <target state="translated">Вставляйте вставки в сделку.</target>
        </trans-unit>
        <trans-unit id="9d00bcd205db77802eec1f76d0bfc2a4e82e6fe2" translate="yes" xml:space="preserve">
          <source>Refactoring C Code</source>
          <target state="translated">Рефакторинг С-кода</target>
        </trans-unit>
        <trans-unit id="b25e791003c46490e0166b007c32a101c17271c5" translate="yes" xml:space="preserve">
          <source>Running the code as-is doesn't actually perform any database operations, but it will give us an idea of how fast the raw C file I/O and string processing operations are.</source>
          <target state="translated">Запуск кода на самом деле не производит никаких операций с базой данных,но даст нам представление о том,насколько быстро выполняются операции ввода-вывода и обработки строк в исходном C-файле.</target>
        </trans-unit>
        <trans-unit id="7801bb5ecd32d8d6426f3434d9102bfe5f65316d" translate="yes" xml:space="preserve">
          <source>Several tips:</source>
          <target state="translated">Несколько советов:</target>
        </trans-unit>
        <trans-unit id="bf198eba07fea151a8fb44062f5cf968092033e2" translate="yes" xml:space="preserve">
          <source>So here is where the rollback comes. The only issue with the rollback is that you lose all your inserts and start from the top. How can you solve this?</source>
          <target state="translated">Итак,вот где происходит откат.Единственная проблема с откатом заключается в том,что вы теряете все вставки и начинаете сверху.Как вы можете это решить?</target>
        </trans-unit>
        <trans-unit id="db1afd310be73362aa7fb7a0a2c83f7cc9be9db1" translate="yes" xml:space="preserve">
          <source>Summary (so far)</source>
          <target state="translated">Резюме (на данный момент)</target>
        </trans-unit>
        <trans-unit id="fda992cd350165c2f1d88bde9d7d98e92fe66347" translate="yes" xml:space="preserve">
          <source>Take advantage of saving space...smaller databases go faster. For instance, if you have key value pairs, try making the key an &lt;code&gt;INTEGER PRIMARY KEY&lt;/code&gt; if possible, which will replace the implied unique row number column in the table.</source>
          <target state="translated">Воспользуйтесь преимуществом экономии места ... меньшие базы данных работают быстрее. Например, если у вас есть пары ключ-значение, попробуйте сделать ключ &lt;code&gt;INTEGER PRIMARY KEY&lt;/code&gt; , если это возможно, который заменит столбец подразумеваемого уникального номера строки в таблице.</target>
        </trans-unit>
        <trans-unit id="c6c60bb2b9aa2a9dcf08905210c5336ed8ba1be0" translate="yes" xml:space="preserve">
          <source>That's better. Simply wrapping all of our inserts in a single transaction improved our performance to &lt;strong&gt;23,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Так-то лучше. Простое объединение всех наших вставок в одну транзакцию улучшило нашу производительность до &lt;strong&gt;23 000 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="017b6041e5e97ed016693e8cbc3c4c24484ab010" translate="yes" xml:space="preserve">
          <source>The &quot;Control&quot;</source>
          <target state="translated">&quot;Контроль&quot;</target>
        </trans-unit>
        <trans-unit id="88cbff81bd98a7e52e52c7d398a52f2faba9c9c8" translate="yes" xml:space="preserve">
          <source>The &quot;Worst-Case-Scenario&quot;</source>
          <target state="translated">&quot;Худший случай-сценарий&quot;.</target>
        </trans-unit>
        <trans-unit id="508178fc7a6c1685a9ce3f25f29c50b86c817345" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://www.sqlite.org/cintro.html&quot;&gt;C API intro&lt;/a&gt; from the SQLite docs says:</source>
          <target state="translated">&lt;a href=&quot;https://www.sqlite.org/cintro.html&quot;&gt;Введение в API C&lt;/a&gt; из документации по SQLite гласит:</target>
        </trans-unit>
        <trans-unit id="38372a1525b1bf61a2f5f0cc1ddbbf17915e0784" translate="yes" xml:space="preserve">
          <source>The ON CONFLICT command does not apply, cause if you have 10 elements in a record and you need each element inserted to a different table, if element 5 gets a CONSTRAINT error, then all previous 4 inserts need to go too.</source>
          <target state="translated">Команда ON CONFLICT не применяется,потому что если у Вас в записи 10 элементов и Вам нужно,чтобы каждый элемент был вставлен в другую таблицу,если элемент 5 получит ошибку CONSTRAINT,то все предыдущие 4 вставки тоже должны идти.</target>
        </trans-unit>
        <trans-unit id="8ea1fabbe4633c8d4db54d4c842da90c9441b97d" translate="yes" xml:space="preserve">
          <source>The algorithm I created helped me reduce my process by 2 hours. Final loading process of file 1hr 30m which is still slow but not compared to the 4hrs that it initially took. I managed to speed the inserts from 10.000/s to ~14.000/s</source>
          <target state="translated">Алгоритм,который я создал,помог мне сократить процесс на 2 часа.Окончательная загрузка файла 1ч 30м,которая все еще медленная,но не по сравнению с 4 часами,которые она занимала изначально.Мне удалось ускорить вставки с 10.000 до ~14.000.</target>
        </trans-unit>
        <trans-unit id="9f26c58828cd1c833c02f45b4f92100c4d5ab702" translate="yes" xml:space="preserve">
          <source>The answer to your question is that the newer SQLite&amp;nbsp;3 has improved performance, use that.</source>
          <target state="translated">Ответ на ваш вопрос заключается в том, что более новый SQLite 3 улучшил производительность, используйте это.</target>
        </trans-unit>
        <trans-unit id="3987d3dbe6e66d288d9494f0c4a889acd57d2876" translate="yes" xml:space="preserve">
          <source>The code in the test sets the bindings every time through which should be enough.</source>
          <target state="translated">Код в тесте каждый раз задает привязки,которых должно быть достаточно.</target>
        </trans-unit>
        <trans-unit id="03189b3c8c0eb7bf3b9cf95a8e187e585d96d60f" translate="yes" xml:space="preserve">
          <source>The code is compiled with &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_C%2B%2B#32-bit_versions&quot;&gt;Visual C++&lt;/a&gt; 2005 as &quot;Release&quot; with &quot;Full Optimization&quot; (/Ox) and Favor Fast Code (/Ot).</source>
          <target state="translated">Код компилируется с &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_C%2B%2B#32-bit_versions&quot;&gt;Visual C ++&lt;/a&gt; 2005 как &amp;laquo;Релиз&amp;raquo; с &amp;laquo;Полной оптимизацией&amp;raquo; (/ Ox) и Favor Fast Code (/ Ot).</target>
        </trans-unit>
        <trans-unit id="0ea5d284cecee101861f152c707c71f8fd74f317" translate="yes" xml:space="preserve">
          <source>The improvements are now smaller, but we're up to &lt;strong&gt;69,600 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Улучшения теперь меньше, но у нас до &lt;strong&gt;69 600 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="be2689c857db56817bdb470b056a287c52a2e0c0" translate="yes" xml:space="preserve">
          <source>There is nothing in the docs for &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt;&lt;code&gt;sqlite3_clear_bindings&lt;/code&gt;&lt;/a&gt; saying you must call it in addition to simply setting the bindings.</source>
          <target state="translated">В документах &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt; &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; &lt;/a&gt; ничего не сказано о том, что вы должны вызывать его в дополнение к простой установке привязок.</target>
        </trans-unit>
        <trans-unit id="bf20f7e886b3170f117100780131fac01a688cee" translate="yes" xml:space="preserve">
          <source>This answer &lt;em&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly/11769768#11769768&quot;&gt;Why is SQLAlchemy insert with sqlite 25 times slower than using sqlite3 directly?&lt;/a&gt;&lt;/em&gt; by SqlAlchemy Orm Author has 100k inserts in 0.5 sec, and I have seen similar results with python-sqlite and SqlAlchemy. Which leads me to believe that performance has improved with SQLite&amp;nbsp;3.</source>
          <target state="translated">Этот ответ &lt;em&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly/11769768#11769768&quot;&gt;Почему SQLAlchemy вставка с sqlite в 25 раз медленнее, чем использование sqlite3 напрямую?&lt;/a&gt;&lt;/em&gt; Автор SqlAlchemy Orm Автор имеет 100 тыс. вставок за 0,5 секунды, и я видел похожие результаты с python-sqlite и SqlAlchemy. Что заставляет меня верить, что производительность улучшилась с SQLite 3.</target>
        </trans-unit>
        <trans-unit id="c6adca7440b2ae1858c40b313a78614c3cd32177" translate="yes" xml:space="preserve">
          <source>This is going to be slow because the SQL will be compiled into VDBE code for every insert and every insert will happen in its own transaction. &lt;em&gt;How slow?&lt;/em&gt;</source>
          <target state="translated">Это будет медленно, потому что SQL будет скомпилирован в код VDBE для каждой вставки, и каждая вставка будет происходить в своей собственной транзакции. &lt;em&gt;Как медленно?&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="db63715f64683425fd01f5904246eab4178b65d8" translate="yes" xml:space="preserve">
          <source>This solution helped me bypass the issues I have when dealing with files containing bad/duplicate records (I had almost 4% bad records).</source>
          <target state="translated">Это решение помогло мне обойти проблемы,возникающие при работе с файлами,содержащими плохие дубликаты (у меня было почти 4% плохих записей).</target>
        </trans-unit>
        <trans-unit id="ed7f88668556c34e922129040d0b4cb1fff93abd" translate="yes" xml:space="preserve">
          <source>Too many or too little threads won't do it, you need to benchmark and profile yourself.</source>
          <target state="translated">Слишком много или слишком мало нитей не сделают этого,вам нужно провести сравнительный анализ и составить свой профиль.</target>
        </trans-unit>
        <trans-unit id="5e1b2a6b6d80f8d0e183b885c337e18d7f131c6e" translate="yes" xml:space="preserve">
          <source>Try using &lt;code&gt;SQLITE_STATIC&lt;/code&gt; instead of &lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; for those inserts.</source>
          <target state="translated">Попробуйте использовать &lt;code&gt;SQLITE_STATIC&lt;/code&gt; вместо &lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; для этих вставок.</target>
        </trans-unit>
        <trans-unit id="054498b4ab93a63c9779fb5e4449fc342376cebb" translate="yes" xml:space="preserve">
          <source>Use ContentProvider for inserting the bulk data in db.
The below method used for inserting bulk data in to database. This should Improve INSERT-per-second performance of SQLite.</source>
          <target state="translated">Используйте ContentProvider для вставки больших объемов данных в дб.Нижеприведенный метод используется для вставки больших объемов данных в БД.Это должно улучшить производительность INSERT в секунду для SQLite.</target>
        </trans-unit>
        <trans-unit id="86258bb2c189f1c4b45a4e393182d5e6be34a275" translate="yes" xml:space="preserve">
          <source>Using a Prepared Statement</source>
          <target state="translated">Использование подготовленного заявления</target>
        </trans-unit>
        <trans-unit id="27bfc98a791c846a44ceefffbe8088440beb0489" translate="yes" xml:space="preserve">
          <source>Using a Transaction</source>
          <target state="translated">Использование транзакции</target>
        </trans-unit>
        <trans-unit id="efa798e2337da1f597bb94d66f1cd12d1cc78d2f" translate="yes" xml:space="preserve">
          <source>Using a transaction was a huge improvement, but recompiling the SQL statement for every insert doesn't make sense if we using the same SQL over-and-over. Let's use &lt;code&gt;sqlite3_prepare_v2&lt;/code&gt; to compile our SQL statement once and then bind our parameters to that statement using &lt;code&gt;sqlite3_bind_text&lt;/code&gt;:</source>
          <target state="translated">Использование транзакции было огромным улучшением, но перекомпиляция оператора SQL для каждой вставки не имеет смысла, если мы используем один и тот же SQL снова и снова. Давайте с помощью &lt;code&gt;sqlite3_prepare_v2&lt;/code&gt; скомпилируем наш оператор SQL один раз, а затем свяжем наши параметры с этим оператором, используя &lt;code&gt;sqlite3_bind_text&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="674be12a68db41f5e65e8f6f5288f5307643a49c" translate="yes" xml:space="preserve">
          <source>Using an In-Memory Database</source>
          <target state="translated">Использование базы данных In-Memory</target>
        </trans-unit>
        <trans-unit id="a989490dc1086fbe60acc040f2077ee40bc910a4" translate="yes" xml:space="preserve">
          <source>We're going to generate the SQL string using the values read from the file and invoke that SQL operation using sqlite3_exec:</source>
          <target state="translated">Мы будем генерировать SQL-строку,используя значения,считанные из файла,и вызывать эту SQL-операцию с помощью sqlite3_exec:</target>
        </trans-unit>
        <trans-unit id="51a38e71a882481707d999fc28f7f0fcdeaf78ba" translate="yes" xml:space="preserve">
          <source>Yikes! 2 hours and 45 minutes! That's only &lt;strong&gt;85 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">Хлоп! 2 часа 45 минут! Это всего &lt;strong&gt;85 вставок в секунду.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="cc4e57454f2e22aeb719d5949b1a38ae2ba3ce02" translate="yes" xml:space="preserve">
          <source>You have to be quite careful if you have concurrent access to SQLite, as the whole database is locked when writes are done, and although multiple readers are possible, writes will be locked out. This has been improved somewhat with the addition of a WAL in newer SQLite versions.</source>
          <target state="translated">Вы должны быть достаточно осторожны,если у вас есть одновременный доступ к SQLite,так как при записи вся база данных блокируется,и хотя возможно использование нескольких читателей,запись будет заблокирована.Это было несколько улучшено с добавлением WAL в новых версиях SQLite.</target>
        </trans-unit>
        <trans-unit id="f84952b103a6b1fa35391ad802ceb45691b6a3c4" translate="yes" xml:space="preserve">
          <source>for each thread:</source>
          <target state="translated">для каждой нити:</target>
        </trans-unit>
        <trans-unit id="718651ac1e4d28eed11decc1cc7b263cdac1558f" translate="yes" xml:space="preserve">
          <source>then read in pages (LIMIT/OFFSET):</source>
          <target state="translated">затем читайте на страницах (LIMITOFFSET):</target>
        </trans-unit>
        <trans-unit id="779e8933edaa2a8b59f69f6c48510a0f1a6cf67a" translate="yes" xml:space="preserve">
          <source>where  and  are calculated per-thread, like this:</source>
          <target state="translated">где и где вычисляются на каждую резьбу,вот так:</target>
        </trans-unit>
        <trans-unit id="f4c7bc63d48e550900e1d3bed8080e1b721d1e85" translate="yes" xml:space="preserve">
          <source>which bulk loads an array of ActiveRecords into &lt;a href=&quot;http://en.wikipedia.org/wiki/MySQL&quot;&gt;MySQL&lt;/a&gt;, SQLite or &lt;a href=&quot;http://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; databases. It includes an option to ignore existing records, overwrite them or raise an error. My rudimentary benchmarks show a 10x speed improvement compared to sequential writes -- YMMV.</source>
          <target state="translated">какая масса загружает массив ActiveRecords в &lt;a href=&quot;http://en.wikipedia.org/wiki/MySQL&quot;&gt;базы данных MySQL&lt;/a&gt; , SQLite или &lt;a href=&quot;http://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; . Он включает в себя возможность игнорировать существующие записи, перезаписать их или вызвать ошибку. Мои элементарные тесты показывают 10-кратное улучшение скорости по сравнению с последовательными записями - YMMV.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
