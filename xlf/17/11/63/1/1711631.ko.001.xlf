<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="https://stackoverflow.com/questions/1711631">
    <body>
      <group id="1711631">
        <trans-unit id="cdefc7d8d0f502ac2649cb2130333beb8e549c0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SQLITE_STATIC&lt;/code&gt; tells it that the memory address you gave it will be valid until the query has been performed (which in this loop is always the case). This will save you several allocate, copy and deallocate operations per loop. Possibly a large improvement.</source>
          <target state="translated">&lt;code&gt;SQLITE_STATIC&lt;/code&gt; 은 사용자가 제공 한 메모리 주소가 조회가 수행 될 때까지 유효 함을 알려줍니다 (이 루프에서는 항상 그렇습니다). 이를 통해 루프 당 여러 할당, 복사 및 할당 해제 작업을 줄일 수 있습니다. 아마 큰 개선.</target>
        </trans-unit>
        <trans-unit id="dc841631c7f8778b9620c5a6aebf79da39172daf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; will cause SQLite to copy the string data before returning.</source>
          <target state="translated">&lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; 는 리턴하기 전에 SQLite가 문자열 데이터를 복사하게합니다.</target>
        </trans-unit>
        <trans-unit id="8e0bb93e0bdc0ef4869a544f1ec90a67170531be" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;I hope you're still with me!&lt;/em&gt; The reason we started down this road is that bulk-insert performance varies so wildly with SQLite, and it's not always obvious what changes need to be made to speed-up our operation. Using the same compiler (and compiler options), the same version of SQLite and the same data we've optimized our code and our usage of SQLite to go &lt;strong&gt;from a worst-case scenario of 85 inserts per second to over 96,000 inserts per second!&lt;/strong&gt;</source>
          <target state="translated">&lt;em&gt;나는 당신이 여전히 나와 함께 있기를 바랍니다!&lt;/em&gt; 이 길을 시작한 이유는 대량 삽입 성능이 SQLite에 따라 크게 다르기 때문에 운영 속도를 높이기 위해 어떤 변경이 필요한지 항상 명확하지 않기 때문입니다. 동일한 컴파일러 (및 컴파일러 옵션), 동일한 버전의 SQLite 및 동일한 데이터를 사용하여 코드와 SQLite 사용을 최적화하여 &lt;strong&gt;초당 85 삽입의 최악의 시나리오에서 초당 96,000 이상의 삽입으로 이동합니다!&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="651a2b8d1ad8078419cf895a15b4c0df27a8c401" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Let's write some code!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;코드를 작성하자!&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="b76b98300a521ccc66355329ebd7994a2475558c" translate="yes" xml:space="preserve">
          <source>&lt;s&gt;&lt;a href=&quot;https://github.com/rdpoor/CreateOrUpdate&quot;&gt;https://github.com/rdpoor/CreateOrUpdate&lt;/a&gt;&lt;/s&gt;</source>
          <target state="translated">&lt;s&gt;&lt;a href=&quot;https://github.com/rdpoor/CreateOrUpdate&quot;&gt;https://github.com/rdpoor/CreateOrUpdate&lt;/a&gt;&lt;/s&gt;</target>
        </trans-unit>
        <trans-unit id="7ff38676434e7065905a1e026ab3bdabb754fafc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Avoid &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt;&lt;code&gt;sqlite3_clear_bindings(stmt)&lt;/code&gt;&lt;/a&gt;.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;&lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt; &lt;code&gt;sqlite3_clear_bindings(stmt)&lt;/code&gt; &lt;/a&gt; 피하십시오.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="b52454c570dc6b7585dff89d6bafeb4102012edb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Background:&lt;/strong&gt; We are using SQLite as part of a desktop application. We have large amounts of configuration data stored in XML files that are parsed and loaded into an SQLite database for further processing when the application is initialized. SQLite is ideal for this situation because it's fast, it requires no specialized configuration, and the database is stored on disk as a single file.</source>
          <target state="translated">&lt;strong&gt;배경 :&lt;/strong&gt; 데스크톱 응용 프로그램의 일부로 SQLite를 사용하고 있습니다. 애플리케이션이 초기화 될 때 추가 처리를 위해 구문 분석되어 SQLite 데이터베이스로로드되는 XML 파일에 많은 양의 구성 데이터가 저장되어 있습니다. SQLite는 속도가 빠르며 특수한 구성이 필요하지 않으며 데이터베이스가 단일 파일로 디스크에 저장되므로 이러한 상황에 이상적입니다.</target>
        </trans-unit>
        <trans-unit id="270000b21d15ce5fe27f22341bb7e2a04b3d7f99" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Create Index then Insert Data&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;인덱스 생성 후 데이터 삽입&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c801cbf9bc118950e73a5431424c376f22274ca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Insert Data then Create Index&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;데이터 삽입 후 인덱스 생성&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="dbe1b95758ace93ba6c358fe7b1aa18db2be2a7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Note: We are back to using a real database file. In-memory databases are fast, but not necessarily practical&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;참고 : 실제 데이터베이스 파일을 다시 사용합니다.&lt;/strong&gt; &lt;strong&gt;인 메모리 데이터베이스는 빠르지 만 실용적이지는 않습니다.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="26ea07b172d510db473fb482ce4002bc7313046a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Rationale:&lt;/strong&gt;&lt;em&gt;Initially I was disappointed with the performance I was seeing.&lt;/em&gt; It turns-out that the performance of SQLite can vary significantly (both for bulk-inserts and selects) depending on how the database is configured and how you're using the API. It was not a trivial matter to figure out what all of the options and techniques were, so I thought it prudent to create this community wiki entry to share the results with Stack&amp;nbsp;Overflow readers in order to save others the trouble of the same investigations.</source>
          <target state="translated">&lt;strong&gt;근거 :&lt;/strong&gt; &lt;em&gt;처음에는 내가보고있는 성능에 실망했습니다.&lt;/em&gt; 데이터베이스 구성 방법과 API 사용 방법에 따라 SQLite의 성능이 크게 달라질 수 있습니다 (대량 삽입 및 선택). 모든 옵션과 기술이 무엇인지 알아내는 것은 사소한 일이 아니므로 동일한 커뮤니티의 조사 문제를 다른 사람들이 해결하기 위해 스택 오버플로 리더와 결과를 공유하기 위해이 커뮤니티 위키 항목을 작성하는 것이 현명하다고 생각했습니다.</target>
        </trans-unit>
        <trans-unit id="a76bacf9fc05e4ab73ba39928377f27b7df97668" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;The Code:&lt;/strong&gt; A simple C program that reads the text file line-by-line, splits the string into values and then inserts the data into an SQLite database. In this &quot;baseline&quot; version of the code, the database is created, but we won't actually insert data:</source>
          <target state="translated">&lt;strong&gt;코드 :&lt;/strong&gt; 텍스트 파일을 한 줄씩 읽고 문자열을 값으로 분할 한 다음 SQLite 데이터베이스에 데이터를 삽입하는 간단한 C 프로그램입니다. 이 &quot;기본&quot;버전의 코드에서는 데이터베이스가 생성되지만 실제로 데이터를 삽입하지는 않습니다.</target>
        </trans-unit>
        <trans-unit id="2dfc837caac3acc0839eec2ba05612c43327300d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;The Experiment:&lt;/strong&gt; Rather than simply talking about performance tips in the general sense (i.e. &lt;em&gt;&quot;Use a transaction!&quot;&lt;/em&gt;), I thought it best to write some C code and &lt;em&gt;actually measure&lt;/em&gt; the impact of various options. We're going to start with some simple data:</source>
          <target state="translated">&lt;strong&gt;실험 :&lt;/strong&gt; 일반적인 의미의 성능 팁 (예 : &lt;em&gt;&quot;트랜잭션 사용&quot;&lt;/em&gt; )에 대해서만 이야기하는 대신 C 코드를 작성하고 &lt;em&gt;실제로&lt;/em&gt; 다양한 옵션의 영향을 &lt;em&gt;측정&lt;/em&gt; 하는 것이 가장 좋습니다. 간단한 데이터부터 시작하겠습니다.</target>
        </trans-unit>
        <trans-unit id="28ff78fa5b07af5d0e3d7492a98d06fe91ed622f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;UPDATE&lt;/strong&gt;:</source>
          <target state="translated">&lt;strong&gt;UPDATE&lt;/strong&gt;:</target>
        </trans-unit>
        <trans-unit id="d11a8e1d536d373238c3435a955657ece24fd305" translate="yes" xml:space="preserve">
          <source>A 28 MB TAB-delimited text file (approximately 865,000 records) of the &lt;a href=&quot;http://www.toronto.ca/open/datasets/ttc-routes&quot;&gt;complete transit schedule for the city of Toronto&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;http://www.toronto.ca/open/datasets/ttc-routes&quot;&gt;토론토시의 전체 대중 교통 스케줄에 대한&lt;/a&gt; 28MB의 탭으로 구분 된 텍스트 파일 (약 865,000 개의 레코드)</target>
        </trans-unit>
        <trans-unit id="7a43bd3a7ef7eab400ead152ddcab810fb34cbd0" translate="yes" xml:space="preserve">
          <source>A little slower than the previous optimization at &lt;strong&gt;64,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;초당 64,000 개의 인서트&lt;/strong&gt; 에서 이전 최적화보다 약간 느립니다 &lt;strong&gt;.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="9f763d7016e134b7f26a749db3a5f6f6a28b8a9b" translate="yes" xml:space="preserve">
          <source>A slight refactoring to the string processing code used in our parameter binding has allowed us to perform &lt;strong&gt;96,700 inserts per second.&lt;/strong&gt; I think it's safe to say that this is &lt;em&gt;plenty fast&lt;/em&gt;. As we start to tweak other variables (i.e. page size, index creation, etc.) this will be our benchmark.</source>
          <target state="translated">매개 변수 바인딩에 사용 된 문자열 처리 코드를 약간 리팩토링하면 &lt;strong&gt;초당 96,700 개의 삽입&lt;/strong&gt; 을 수행 할 수있었습니다 &lt;strong&gt;.&lt;/strong&gt; 나는 이것이 &lt;em&gt;매우 빠르다고&lt;/em&gt; 말하는 것이 안전하다고 생각합니다. 다른 변수 (예 : 페이지 크기, 색인 작성 등)를 조정하기 시작하면 이것이 벤치 마크가됩니다.</target>
        </trans-unit>
        <trans-unit id="8df6f713ac0e07c6021d93f5e0c15401d3336b1d" translate="yes" xml:space="preserve">
          <source>After reading this tutorial, I tried to implement it to my program.</source>
          <target state="translated">이 튜토리얼을 읽은 후 프로그램에 구현하려고했습니다.</target>
        </trans-unit>
        <trans-unit id="ea6e032fcc1739cdfb3de8cd3a6c6dfc44b90167" translate="yes" xml:space="preserve">
          <source>After two weeks of research and checking multiple resources: Hard Drive, Ram, Cache, I found out that some settings on your hard drive can affect the I/O rate. By clicking properties on your desired output drive you can see two options in the general tab. Opt1: Compress this drive, Opt2: Allow files of this drive to have contents indexed.</source>
          <target state="translated">하드 드라이브, 램, 캐시 등 2 주 동안 여러 리소스를 조사하고 점검 한 결과, 하드 드라이브의 일부 설정이 I / O 속도에 영향을 줄 수 있음을 알게되었습니다. 원하는 출력 드라이브에서 속성을 클릭하면 일반 탭에서 두 가지 옵션을 볼 수 있습니다. Opt1 :이 드라이브를 압축합니다. Opt2 :이 드라이브의 파일이 색인을 생성하도록 허용합니다.</target>
        </trans-unit>
        <trans-unit id="123802917e1e1b5959658891a69eb20a10c75487" translate="yes" xml:space="preserve">
          <source>Also for us, SHAREDCACHE made the performance slower, so I manually put PRIVATECACHE (cause it was enabled globally for us)</source>
          <target state="translated">또한 우리를 위해 SHAREDCACHE는 성능을 느리게 만들었으므로 PRIVATECACHE를 수동으로 넣었습니다 (전 세계적으로 활성화되어 있기 때문에)</target>
        </trans-unit>
        <trans-unit id="4583ff4050220eaa4631bc21a580cf8fe41b8f3b" translate="yes" xml:space="preserve">
          <source>Although not specifically an SQLite improvement, I don't like the extra &lt;code&gt;char*&lt;/code&gt; assignment operations in the &lt;code&gt;while&lt;/code&gt; loop. Let's quickly refactor that code to pass the output of &lt;code&gt;strtok()&lt;/code&gt; directly into &lt;code&gt;sqlite3_bind_text()&lt;/code&gt;, and let the compiler try to speed things up for us:</source>
          <target state="translated">특별히 SQLite 개선은 아니지만 &lt;code&gt;while&lt;/code&gt; 루프에서 추가 &lt;code&gt;char*&lt;/code&gt; 할당 작업을 좋아하지 않습니다. &lt;code&gt;strtok()&lt;/code&gt; 의 출력을 &lt;code&gt;sqlite3_bind_text()&lt;/code&gt; 로 직접 전달하기 위해 해당 코드를 신속하게 리팩터링하고 컴파일러가 속도를 높이도록하겠습니다.</target>
        </trans-unit>
        <trans-unit id="26e259678078857d966992a8f6abac77d4d0cd86" translate="yes" xml:space="preserve">
          <source>As expected, bulk-inserts are slower if one column is indexed, but it does make a difference if the index is created after the data is inserted. Our no-index baseline is 96,000 inserts per second. &lt;strong&gt;Creating the index first then inserting data gives us 47,700 inserts per second, whereas inserting the data first then creating the index gives us 63,300 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">예상대로, 하나의 열이 색인화되면 대량 삽입이 느려지지만 데이터가 삽입 된 후 색인이 작성되면 차이가 발생합니다. 인덱스가없는 기준은 초당 96,000 개의 인서트입니다. &lt;strong&gt;먼저 인덱스를 작성하고 데이터를 삽입하면 초당 47,700 개의 삽입이 발생하지만, 데이터를 먼저 삽입 한 다음 인덱스를 작성하면 초당 63,300 개의 삽입이 발생합니다.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="087e0edf98958c039e2818a7fb1853f6115bf21c" translate="yes" xml:space="preserve">
          <source>Before we start measuring &lt;code&gt;SELECT&lt;/code&gt; performance, we know that we'll be creating indices. It's been suggested in one of the answers below that when doing bulk inserts, it is faster to create the index after the data has been inserted (as opposed to creating the index first then inserting the data). Let's try:</source>
          <target state="translated">&lt;code&gt;SELECT&lt;/code&gt; 성능 측정을 시작하기 전에 인덱스를 만들 것임을 알고 있습니다. 아래 답변 중 하나에서 대량 삽입을 수행 할 때 데이터를 삽입 한 후 색인을 만드는 것이 더 빠릅니다 (먼저 색인을 만든 다음 데이터를 삽입하는 것이 아니라). 해보자:</target>
        </trans-unit>
        <trans-unit id="872e67d1abe340cdbf86668e654d983f7d5c9e25" translate="yes" xml:space="preserve">
          <source>Bulk imports seems to perform best if you can chunk your &lt;strong&gt;INSERT/UPDATE&lt;/strong&gt; statements.  A value of 10,000 or so has worked well for me on a table with only a few rows, YMMV...</source>
          <target state="translated">&lt;strong&gt;INSERT / UPDATE&lt;/strong&gt; 문을 청크 할 수 있으면 대량 가져 오기가 가장 잘 수행되는 것 같습니다. 10,000 개 정도의 값은 YMMV ... 몇 행만있는 테이블에서 잘 작동했습니다.</target>
        </trans-unit>
        <trans-unit id="671341a42a7c965624dd8daf9888d2a9ef366288" translate="yes" xml:space="preserve">
          <source>By default, SQLite will evaluate every INSERT / UPDATE statement within a unique transaction. If performing a large number of inserts, it's advisable to wrap your operation in a transaction:</source>
          <target state="translated">기본적으로 SQLite는 고유 한 트랜잭션 내의 모든 INSERT / UPDATE 문을 평가합니다. 많은 수의 인서트를 수행하는 경우 작업을 트랜잭션으로 래핑하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="bbd325acdd91b4ca873182b6a019ce434225ae43" translate="yes" xml:space="preserve">
          <source>By default, SQLite will pause after issuing a OS-level write command. This guarantees that the data is written to the disk. By setting &lt;code&gt;synchronous = OFF&lt;/code&gt;, we are instructing SQLite to simply hand-off the data to the OS for writing and then continue. There's a chance that the database file may become corrupted if the computer suffers a catastrophic crash (or power failure) before the data is written to the platter:</source>
          <target state="translated">기본적으로 SQLite는 OS 수준 쓰기 명령을 실행 한 후 일시 중지됩니다. 이를 통해 데이터가 디스크에 기록됩니다. &lt;code&gt;synchronous = OFF&lt;/code&gt; 로 설정하면 SQLite에 데이터를 OS로 전달하여 쓰기를 계속하도록 지시합니다. 데이터가 플래터에 기록되기 전에 컴퓨터에 치명적인 충돌 (또는 정전)이 발생하면 데이터베이스 파일이 손상 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9021172ebb7b79e513f34761501efc24dc16188c" translate="yes" xml:space="preserve">
          <source>By disabling these two options all 3 PCs now take approximately the same time to finish (1hr and 20 to 40min). If you encounter slow inserts check whether your hard drive is configured with these options. It will save you lots of time and headaches trying to find the solution</source>
          <target state="translated">이 두 가지 옵션을 비활성화하면 3 대의 PC가 모두 거의 같은 시간이 걸립니다 (1 시간 20 분에서 40 분). 삽입 속도가 느리면 하드 드라이브가이 옵션으로 구성되어 있는지 확인하십시오. 솔루션을 찾으려고 노력하면 많은 시간과 두통을 줄일 수 있습니다</target>
        </trans-unit>
        <trans-unit id="b433a2b1f636acc88cf161d1b849771010a891d6" translate="yes" xml:space="preserve">
          <source>CREATE INDEX then INSERT vs. INSERT then CREATE INDEX</source>
          <target state="translated">INDEX 작성 후 INSERT vs. INSERT 작성 후 INDEX 작성</target>
        </trans-unit>
        <trans-unit id="3a324f600d2cc2caa3c71c2e0bb04baf34e8a893" translate="yes" xml:space="preserve">
          <source>Call bulkInsert method :</source>
          <target state="translated">bulkInsert 메소드를 호출하십시오.</target>
        </trans-unit>
        <trans-unit id="bcdd9e61da1685f26f0ee4233e52764e50d2bfe3" translate="yes" xml:space="preserve">
          <source>Consider storing the rollback journal in memory by evaluating &lt;code&gt;PRAGMA journal_mode = MEMORY&lt;/code&gt;. Your transaction will be faster, but if you lose power or your program crashes during a transaction you database could be left in a corrupt state with a partially-completed transaction:</source>
          <target state="translated">&lt;code&gt;PRAGMA journal_mode = MEMORY&lt;/code&gt; 평가하여 롤백 저널을 메모리에 저장하십시오. 트랜잭션 속도는 빨라지지만 트랜잭션 도중 전원이 꺼 지거나 프로그램이 충돌하면 데이터베이스가 부분적으로 완료된 트랜잭션으로 인해 손상된 상태로 남아있을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9f72f2c529b0b1804a0aaf2ee6c8d2facf67621b" translate="yes" xml:space="preserve">
          <source>Don't use &lt;code&gt;!feof(file)&lt;/code&gt;!</source>
          <target state="translated">&lt;code&gt;!feof(file)&lt;/code&gt; 사용하지 마십시오!</target>
        </trans-unit>
        <trans-unit id="4326aa174e0a3d69e5993b7a70921bb5ff0f2f6e" translate="yes" xml:space="preserve">
          <source>Fantastic! We're able to do &lt;strong&gt;72,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">환상적인! &lt;strong&gt;초당 72,000 개의 인서트&lt;/strong&gt; 를 수행 할 수 &lt;strong&gt;있습니다.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="bfc83a3f5364bbc68fa36baf227468de56749928" translate="yes" xml:space="preserve">
          <source>First find the items, in the table:</source>
          <target state="translated">먼저 표에서 항목을 찾으십시오.</target>
        </trans-unit>
        <trans-unit id="090aa308f4299a2ee89598663268aa093622fa6a" translate="yes" xml:space="preserve">
          <source>For older versions of SQLite - Consider a less paranoid journal mode (&lt;code&gt;pragma journal_mode&lt;/code&gt;). There is &lt;code&gt;NORMAL&lt;/code&gt;, and then there is &lt;code&gt;OFF&lt;/code&gt;, which can significantly increase insert speed if you're not too worried about the database possibly getting corrupted if the OS crashes. If your application crashes the data should be fine. Note that in newer versions, the &lt;code&gt;OFF/MEMORY&lt;/code&gt; settings are not safe for application level crashes.</source>
          <target state="translated">이전 버전의 SQLite의 경우 덜 편집증적인 저널 모드 ( &lt;code&gt;pragma journal_mode&lt;/code&gt; )를 고려하십시오. &lt;code&gt;NORMAL&lt;/code&gt; 이 있고 &lt;code&gt;OFF&lt;/code&gt; 가있어 OS 충돌시 데이터베이스가 손상 될 염려가 없으면 삽입 속도를 크게 높일 수 있습니다. 응용 프로그램이 충돌하면 데이터가 정상이어야합니다. 최신 버전에서는 &lt;code&gt;OFF/MEMORY&lt;/code&gt; 설정이 응용 프로그램 수준 충돌에 안전하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2195eed65de850d03a01f0bdc090231f2d372a07" translate="yes" xml:space="preserve">
          <source>For our small (200mb) db this made 50-75% speed-up (3.8.0.2 64-bit on Windows 7). Our tables are heavily non-normalized (1000-1500 columns, roughly 100,000 or more rows).</source>
          <target state="translated">우리의 작은 (200mb) db의 경우 50-75 %의 속도가 향상되었습니다 (Windows 7의 경우 3.8.0.2 64 비트). 테이블은 정규화되지 않았으며 (1000-1500 개의 열, 약 100,000 개 이상의 행).</target>
        </trans-unit>
        <trans-unit id="76b075177903579178f27a07d252a978c4cb462b" translate="yes" xml:space="preserve">
          <source>Great! We can do 920,000 inserts per second, provided we don't actually do any inserts :-)</source>
          <target state="translated">큰! 실제로 인서트를 수행하지 않으면 초당 920,000 개의 인서트를 수행 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6f22b5c109f71a3ddf56af02c88cbacffcd2a204" translate="yes" xml:space="preserve">
          <source>Here is where your suggestion fails. You use a single transaction for all the records and a single insert with no errors/fails. Let's say that you are splitting each record into multiple inserts on different tables. What happens if the record is broken?</source>
          <target state="translated">여기 당신의 제안이 실패합니다. 모든 레코드에 단일 트랜잭션을 사용하고 오류 / 실패없이 단일 삽입을 사용합니다. 각 레코드를 다른 테이블의 여러 삽입으로 분할한다고 가정 해 봅시다. 기록이 깨지면 어떻게 되나요?</target>
        </trans-unit>
        <trans-unit id="026af1bc2703948250f4b6f33ec6faec09054f5b" translate="yes" xml:space="preserve">
          <source>I coudn't get any gain from transactions until I raised cache_size to a higher value i.e.  &lt;code&gt;PRAGMA cache_size=10000;&lt;/code&gt;</source>
          <target state="translated">cache_size를 더 높은 값, 즉 &lt;code&gt;PRAGMA cache_size=10000;&lt;/code&gt; 올릴 때까지 트랜잭션에서 이익을 얻지 못했습니다 .</target>
        </trans-unit>
        <trans-unit id="8eecbe52b4dec4bfb03e25ab1108fd0f15070e96" translate="yes" xml:space="preserve">
          <source>I have 4-5 files that contain addresses. Each file has approx 30 million records. I am using the same configuration that you are suggesting but my number of INSERTs per second is way low (~10.000 records per sec).</source>
          <target state="translated">주소가 포함 된 4-5 개의 파일이 있습니다. 각 파일에는 약 3 천만 개의 레코드가 있습니다. 나는 당신이 제안하는 것과 동일한 구성을 사용하고 있지만 초당 INSERTs의 수는 매우 적습니다 (초당 ~ 10,000 레코드).</target>
        </trans-unit>
        <trans-unit id="11917b0c226929497af8ba620faa1e4b102c1e64" translate="yes" xml:space="preserve">
          <source>I'd gladly take suggestions for other scenarios to try... And will be compiling similar data for SELECT queries soon.</source>
          <target state="translated">다른 시나리오에 대한 제안을 기쁘게 생각합니다 ... 곧 SELECT 쿼리에 대한 유사한 데이터를 컴파일 할 것입니다.</target>
        </trans-unit>
        <trans-unit id="5172e4b2cd07b7be64b179445d83376ec1008f29" translate="yes" xml:space="preserve">
          <source>I'm using it in production code where I frequently need to import large datasets, and I'm pretty happy with it.</source>
          <target state="translated">대용량 데이터 세트를 자주 가져와야하는 프로덕션 코드에서 사용하고 있으며 매우 만족합니다.</target>
        </trans-unit>
        <trans-unit id="3ac5e5ce6fc4a6695514c6dae964ca288c928cef" translate="yes" xml:space="preserve">
          <source>I'm using the SQLite &quot;Amalgamation&quot;, compiled directly into my test application. The SQLite version I happen to have is a bit older (3.6.7), but I suspect these results will be comparable to the latest release (please leave a comment if you think otherwise).</source>
          <target state="translated">테스트 애플리케이션에 직접 컴파일 된 SQLite &quot;Amalgamation&quot;을 사용하고 있습니다. 내가 가지고있는 SQLite 버전은 조금 오래되었지만 (3.6.7)이 결과가 최신 릴리스와 비슷할 것으로 생각됩니다 (그렇지 않으면 의견을 남겨주세요).</target>
        </trans-unit>
        <trans-unit id="46f70793f4a5cfd620882059cb0f77361cfd03c5" translate="yes" xml:space="preserve">
          <source>I've also asked similar questions &lt;a href=&quot;https://stackoverflow.com/questions/784173/what-are-the-performance-characteristics-of-sqlite-with-very-large-database-files&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://stackoverflow.com/questions/768708/are-there-known-issues-with-using-sqlite-and-file-locking-on-different-platforms&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">나는 또한 &lt;a href=&quot;https://stackoverflow.com/questions/784173/what-are-the-performance-characteristics-of-sqlite-with-very-large-database-files&quot;&gt;여기&lt;/a&gt; 와 &lt;a href=&quot;https://stackoverflow.com/questions/768708/are-there-known-issues-with-using-sqlite-and-file-locking-on-different-platforms&quot;&gt;여기에&lt;/a&gt; 비슷한 질문을 했다 .</target>
        </trans-unit>
        <trans-unit id="dfe5fd5527d0cb852bc797c4c3ee406f746ecc8c" translate="yes" xml:space="preserve">
          <source>If anyone has any other ideas on how to speed it up, I am open to suggestions.</source>
          <target state="translated">누구나 속도를 높이는 방법에 대한 다른 아이디어가 있다면 제안을 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7d973398e85df8aa77d57e79abb3b81143a022d7" translate="yes" xml:space="preserve">
          <source>If you are using multiple threads, you can try using the &lt;a href=&quot;http://sqlite.org/c3ref/enable_shared_cache.html&quot;&gt;shared page cache&lt;/a&gt;, which will allow loaded pages to be shared between threads, which can avoid expensive I/O calls.</source>
          <target state="translated">다중 스레드를 사용하는 경우 &lt;a href=&quot;http://sqlite.org/c3ref/enable_shared_cache.html&quot;&gt;공유 페이지 캐시를&lt;/a&gt; 사용하여로드 된 페이지를 스레드간에 공유 할 수 있으므로 값 비싼 I / O 호출을 피할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9909caa1776cc754ea391a5613c40fbd59f9912b" translate="yes" xml:space="preserve">
          <source>If you care only about reading, somewhat faster (but might read stale data) version is to read from multiple connections from multiple threads (connection per-thread).</source>
          <target state="translated">읽기에만 관심이있는 경우 다소 빠른 (그러나 오래된 데이터를 읽을 수 있음) 버전은 여러 스레드 (스레드 당 연결)의 여러 연결에서 읽는 것입니다.</target>
        </trans-unit>
        <trans-unit id="0b5e37f7ae64ee540105a2d6879bb33438066595" translate="yes" xml:space="preserve">
          <source>If you have indices, consider calling &lt;code&gt;CREATE INDEX&lt;/code&gt; after doing all your inserts. This is significantly faster than creating the index and then doing your inserts.</source>
          <target state="translated">&lt;code&gt;CREATE INDEX&lt;/code&gt; 이있는 경우 모든 삽입을 수행 한 후 CREATE INDEX 호출을 고려하십시오. 이것은 색인을 작성하고 삽입을 수행하는 것보다 훨씬 빠릅니다.</target>
        </trans-unit>
        <trans-unit id="050d6cf06387f361bcb1b0a00b8117a50e73b6db" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 0.94
  seconds</source>
          <target state="translated">0.94 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="ffb4f30cad268801a7084f86177635a7739c17eb" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 10.94
  seconds</source>
          <target state="translated">10.94 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="ad66121de714d2631e9f96a8c355fd562e17c3d9" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 12.00
  seconds</source>
          <target state="translated">12.00 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="7581475071859f0e2df5c5baa78a47d7b29eb343" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 12.41
  seconds</source>
          <target state="translated">12.41 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="1fb6a8f5771eb996d9c96dec9c9972b1f7a9e674" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 13.50
  seconds</source>
          <target state="translated">13.50 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="d736e88540c433cf8f1e9c878c95b8f56e1ea201" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 13.66
  seconds</source>
          <target state="translated">13.66 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="9cf20009ccbdebfe12b3df7ef0636a31ba57d3da" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 16.27
  seconds</source>
          <target state="translated">16.27 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="8df99d63ed560901211f5c08656f730de84694b0" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 18.13
  seconds</source>
          <target state="translated">18.13 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="1c548ea621ed72950e828c5b68b12bf11f6ff451" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 38.03
  seconds</source>
          <target state="translated">38.03 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="154309e441b9898bacf87ed35cc90b6b605fec43" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 8.94
  seconds</source>
          <target state="translated">8.94 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="e912b781943a231d89776110872a3ee052f22c58" translate="yes" xml:space="preserve">
          <source>Imported 864913 records in 9933.61
  seconds</source>
          <target state="translated">9933.61 초 내에 864913 개의 레코드를 가져 왔습니다.</target>
        </trans-unit>
        <trans-unit id="5c0542021a1c71e3d1128b2a31c3b68cde8950f7" translate="yes" xml:space="preserve">
          <source>Improve INSERT-per-second performance of SQLite</source>
          <target state="translated">SQLite의 초당 INSERT 성능 향상</target>
        </trans-unit>
        <trans-unit id="437377a502bface456863ef3ef3ca4aa7c7b5e37" translate="yes" xml:space="preserve">
          <source>In Addition to my answer above, you should keep in mind that inserts per second depending on the hard drive you are using too. I tested it on 3 different PCs with different hard drives and got massive differences in times. PC1 (1hr 30m), PC2 (6hrs) PC3 (14hrs), so I started wondering why would that be.</source>
          <target state="translated">위의 답변 이외에도 사용중인 하드 드라이브에 따라 초당 삽입 횟수를 명심해야합니다. 다른 하드 드라이브가있는 3 개의 다른 PC에서 테스트했으며 시간이 크게 다릅니다. PC1 (1 시간 30 분), PC2 (6 시간) PC3 (14 시간), 나는 왜 그런지 궁금해하기 시작했습니다.</target>
        </trans-unit>
        <trans-unit id="084c1b49fd936281f7874c2b66922cccc3363366" translate="yes" xml:space="preserve">
          <source>Inspired by this post and by the Stack Overflow question that led me here -- &lt;a href=&quot;https://stackoverflow.com/questions/1609637/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database&quot;&gt;Is it possible to insert multiple rows at a time in an SQLite database?&lt;/a&gt; -- I've posted my first &lt;a href=&quot;http://en.wikipedia.org/wiki/Git_%28software%29&quot;&gt;Git&lt;/a&gt; repository:</source>
          <target state="translated">이 게시물과 스택 오버플로 질문에서 영감을 얻었습니다 &lt;a href=&quot;https://stackoverflow.com/questions/1609637/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database&quot;&gt;.SQLite 데이터베이스에 한 번에 여러 행을 삽입 할 수 있습니까?&lt;/a&gt; -첫 &lt;a href=&quot;http://en.wikipedia.org/wiki/Git_%28software%29&quot;&gt;Git&lt;/a&gt; 저장소를 게시했습니다.</target>
        </trans-unit>
        <trans-unit id="c680b9c6bf7b7bee16783907b9286d2edf9090e1" translate="yes" xml:space="preserve">
          <source>It's not super-practical to store our database in RAM, but it's impressive that we can perform &lt;strong&gt;79,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">데이터베이스를 RAM에 저장하는 것은 실용적이지는 않지만 &lt;strong&gt;초당 79,000 개의 삽입을&lt;/strong&gt; 수행 할 수 있다는 점이 인상적입니다 &lt;strong&gt;.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a48a72fa6f2a189900ebabff54aef564cc57e5d1" translate="yes" xml:space="preserve">
          <source>Just for kicks, let's build upon all of the previous optimizations and redefine the database filename so we're working entirely in RAM:</source>
          <target state="translated">킥을 위해 이전의 모든 최적화를 기반으로하고 데이터베이스 파일 이름을 재정 의하여 RAM에서 완전히 작업하도록하겠습니다.</target>
        </trans-unit>
        <trans-unit id="def03dbbcc838f12adc51dd0a6831295811e8a51" translate="yes" xml:space="preserve">
          <source>Let's combine the previous two optimizations. It's a little more risky (in case of a crash), but we're just importing data (not running a bank):</source>
          <target state="translated">이전 두 가지 최적화를 결합 해 봅시다. 좀 더 위험하지만 (충돌의 경우) 은행을 운영하지 않고 데이터를 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="fff50fdf32382d53297912d58830059c40882d48" translate="yes" xml:space="preserve">
          <source>Link: &lt;a href=&quot;https://www.vogella.com/tutorials/AndroidSQLite/article.html&quot;&gt;https://www.vogella.com/tutorials/AndroidSQLite/article.html&lt;/a&gt;
check Using ContentProvider Section for more details</source>
          <target state="translated">링크 : &lt;a href=&quot;https://www.vogella.com/tutorials/AndroidSQLite/article.html&quot;&gt;https://www.vogella.com/tutorials/AndroidSQLite/article.html&lt;/a&gt; 자세한 내용은 ContentProvider 섹션 사용을 확인하십시오.</target>
        </trans-unit>
        <trans-unit id="cef93c612411b122f72e46695577441dc0b9538a" translate="yes" xml:space="preserve">
          <source>More detail: &lt;a href=&quot;http://www.hoogli.com/blogs/micro/index.html#Avoid_sqlite3_clear_bindings%28%29&quot;&gt;Avoid_sqlite3_clear_bindings()&lt;/a&gt;</source>
          <target state="translated">자세한 내용 : &lt;a href=&quot;http://www.hoogli.com/blogs/micro/index.html#Avoid_sqlite3_clear_bindings%28%29&quot;&gt;avoid_sqlite3_clear_bindings ()&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd6066b18d7c77401d867d16f3862c393664eb4f" translate="yes" xml:space="preserve">
          <source>My solution was to use &lt;strong&gt;multiple&lt;/strong&gt; transactions. I begin and end a transaction every 10.000 records (Don't ask why that number, it was the fastest one I tested). I created an array sized 10.000 and insert the successful records there. When the error occurs, I do a rollback, begin a transaction, insert the records from my array, commit and then begin a new transaction after the broken record.</source>
          <target state="translated">내 솔루션은 &lt;strong&gt;여러&lt;/strong&gt; 트랜잭션을 사용 &lt;strong&gt;하는&lt;/strong&gt; 것이 었습니다. 나는 10.000 레코드마다 거래를 시작하고 종료합니다 (그 숫자가 내가 테스트 한 가장 빠른 이유는 묻지 마십시오). 10.000 크기의 배열을 만들고 성공적인 레코드를 삽입합니다. 오류가 발생하면 롤백을 수행하고, 트랜잭션을 시작하고, 배열에서 레코드를 삽입하고, 커밋 한 다음 깨진 레코드 후에 새 트랜잭션을 시작합니다.</target>
        </trans-unit>
        <trans-unit id="6b739c10e74293364ba0d24439f65294b7e5a99a" translate="yes" xml:space="preserve">
          <source>My test machine is a 3.60 GHz P4 running Windows XP.</source>
          <target state="translated">내 테스트 컴퓨터는 Windows XP를 실행하는 3.60GHz P4입니다.</target>
        </trans-unit>
        <trans-unit id="725b0e5796b8baedf9846345cfd466c118fc41d9" translate="yes" xml:space="preserve">
          <source>Nice! There's a little bit more code (don't forget to call &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; and &lt;code&gt;sqlite3_reset&lt;/code&gt;), but we've more than doubled our performance to &lt;strong&gt;53,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">좋은! 약간 더 많은 코드가 있지만 ( &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; 및 &lt;code&gt;sqlite3_reset&lt;/code&gt; 을 호출하는 것을 잊지 마십시오), 우리는 &lt;strong&gt;초당 53,000 개의 삽입으로&lt;/strong&gt; 성능을 두 배 이상 향상 시켰습니다 &lt;strong&gt;.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="71cb481da4769935c7cb6729efb5b6f47e162d66" translate="yes" xml:space="preserve">
          <source>On bulk inserts</source>
          <target state="translated">벌크 인서트</target>
        </trans-unit>
        <trans-unit id="23976e24ccb5c88d260af95f9f2b0d95e8f2c905" translate="yes" xml:space="preserve">
          <source>Optimizing SQLite is tricky. Bulk-insert performance of a C application can vary from 85 inserts per second to over 96,000 inserts per second!</source>
          <target state="translated">SQLite를 최적화하는 것은 까다 롭습니다. C 어플리케이션의 대량 삽입 성능은 초당 85 개의 삽입에서 초당 96,000 이상의 삽입까지 다양합니다!</target>
        </trans-unit>
        <trans-unit id="b15b2b66aeaf59f9d4af467b7dce9e1e809af568" translate="yes" xml:space="preserve">
          <source>PRAGMA journal_mode = MEMORY</source>
          <target state="translated">PRAGMA journal_mode = 메모리</target>
        </trans-unit>
        <trans-unit id="03a9d7f69c55c2b9bb13076c851bb0c196528d38" translate="yes" xml:space="preserve">
          <source>PRAGMA synchronous = OFF</source>
          <target state="translated">PRAGMA 동기식 = OFF</target>
        </trans-unit>
        <trans-unit id="e1c75641cd03f3af313aee27467012f92b04b104" translate="yes" xml:space="preserve">
          <source>PRAGMA synchronous = OFF &lt;em&gt;and&lt;/em&gt; PRAGMA journal_mode = MEMORY</source>
          <target state="translated">PRAGMA 동기 = OFF &lt;em&gt;및&lt;/em&gt; PRAGMA journal_mode = MEMORY</target>
        </trans-unit>
        <trans-unit id="847bfcdea40fa982b77f7b8713d9d1c6b544bfb7" translate="yes" xml:space="preserve">
          <source>Playing with page sizes makes a difference as well (&lt;code&gt;PRAGMA page_size&lt;/code&gt;). Having larger page sizes can make reads and writes go a bit faster as larger pages are held in memory. Note that more memory will be used for your database.</source>
          <target state="translated">페이지 크기로 재생하면 차이가 있습니다 ( &lt;code&gt;PRAGMA page_size&lt;/code&gt; ). 더 큰 페이지 크기를 가지면 더 큰 페이지가 메모리에 유지되므로 읽기 및 쓰기 속도가 약간 빨라집니다. 데이터베이스에 더 많은 메모리가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e22067ebafc73b20c18e9861a705da211f5109b2" translate="yes" xml:space="preserve">
          <source>Prior to calling &lt;a href=&quot;https://www.sqlite.org/c3ref/step.html&quot;&gt;sqlite3_step()&lt;/a&gt; for the first time or immediately
  after &lt;a href=&quot;https://www.sqlite.org/c3ref/reset.html&quot;&gt;sqlite3_reset()&lt;/a&gt;, the application can invoke the
  &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind()&lt;/a&gt; interfaces to attach values to the parameters. Each
  call to &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind()&lt;/a&gt; overrides prior bindings on the same parameter</source>
          <target state="translated">&lt;a href=&quot;https://www.sqlite.org/c3ref/step.html&quot;&gt;sqlite3_step ()&lt;/a&gt; 을 처음으로 호출하기 전에 또는 &lt;a href=&quot;https://www.sqlite.org/c3ref/reset.html&quot;&gt;sqlite3_reset ()&lt;/a&gt; 직후에 응용 프로그램은 &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind ()&lt;/a&gt; 인터페이스를 호출하여 값을 매개 변수에 첨부 할 수 있습니다. &lt;a href=&quot;https://www.sqlite.org/c3ref/bind_blob.html&quot;&gt;sqlite3_bind ()&lt;/a&gt; 에 대한 각 호출은 동일한 매개 변수의 이전 바인딩을 대체합니다.</target>
        </trans-unit>
        <trans-unit id="d1dc6289bf46af7ecb10109083938ec233b12f44" translate="yes" xml:space="preserve">
          <source>Put inserts/updates in a transaction.</source>
          <target state="translated">트랜잭션에 삽입 / 업데이트를 넣습니다.</target>
        </trans-unit>
        <trans-unit id="9d00bcd205db77802eec1f76d0bfc2a4e82e6fe2" translate="yes" xml:space="preserve">
          <source>Refactoring C Code</source>
          <target state="translated">C 코드 리팩토링</target>
        </trans-unit>
        <trans-unit id="b25e791003c46490e0166b007c32a101c17271c5" translate="yes" xml:space="preserve">
          <source>Running the code as-is doesn't actually perform any database operations, but it will give us an idea of how fast the raw C file I/O and string processing operations are.</source>
          <target state="translated">코드를있는 그대로 실행하면 실제로 데이터베이스 작업이 수행되지 않지만 원시 C 파일 I / O 및 문자열 처리 작업이 얼마나 빠른지 알 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7801bb5ecd32d8d6426f3434d9102bfe5f65316d" translate="yes" xml:space="preserve">
          <source>Several tips:</source>
          <target state="translated">몇 가지 팁 :</target>
        </trans-unit>
        <trans-unit id="bf198eba07fea151a8fb44062f5cf968092033e2" translate="yes" xml:space="preserve">
          <source>So here is where the rollback comes. The only issue with the rollback is that you lose all your inserts and start from the top. How can you solve this?</source>
          <target state="translated">롤백이 오는 곳입니다. 롤백의 유일한 문제는 모든 인서트를 잃어 버리고 맨 위에서 시작한다는 것입니다. 어떻게 해결할 수 있습니까?</target>
        </trans-unit>
        <trans-unit id="db1afd310be73362aa7fb7a0a2c83f7cc9be9db1" translate="yes" xml:space="preserve">
          <source>Summary (so far)</source>
          <target state="translated">요약 (지금까지)</target>
        </trans-unit>
        <trans-unit id="fda992cd350165c2f1d88bde9d7d98e92fe66347" translate="yes" xml:space="preserve">
          <source>Take advantage of saving space...smaller databases go faster. For instance, if you have key value pairs, try making the key an &lt;code&gt;INTEGER PRIMARY KEY&lt;/code&gt; if possible, which will replace the implied unique row number column in the table.</source>
          <target state="translated">공간 절약의 이점을 누리십시오. 작은 데이터베이스가 더 빠릅니다. 예를 들어 키 값 쌍이있는 경우 가능하면 키를 &lt;code&gt;INTEGER PRIMARY KEY&lt;/code&gt; 로 설정 하면 테이블의 내재 된 고유 행 번호 열이 대체됩니다.</target>
        </trans-unit>
        <trans-unit id="c6c60bb2b9aa2a9dcf08905210c5336ed8ba1be0" translate="yes" xml:space="preserve">
          <source>That's better. Simply wrapping all of our inserts in a single transaction improved our performance to &lt;strong&gt;23,000 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">그게 낫다. 모든 인서트를 단일 트랜잭션으로 간단히 포장하면 &lt;strong&gt;초당 23,000 개의 인서트로&lt;/strong&gt; 성능이 향상되었습니다 &lt;strong&gt;.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="017b6041e5e97ed016693e8cbc3c4c24484ab010" translate="yes" xml:space="preserve">
          <source>The &quot;Control&quot;</source>
          <target state="translated">제어&quot;</target>
        </trans-unit>
        <trans-unit id="88cbff81bd98a7e52e52c7d398a52f2faba9c9c8" translate="yes" xml:space="preserve">
          <source>The &quot;Worst-Case-Scenario&quot;</source>
          <target state="translated">&quot;가장 최악의 시나리오&quot;</target>
        </trans-unit>
        <trans-unit id="508178fc7a6c1685a9ce3f25f29c50b86c817345" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://www.sqlite.org/cintro.html&quot;&gt;C API intro&lt;/a&gt; from the SQLite docs says:</source>
          <target state="translated">SQLite 문서의 &lt;a href=&quot;https://www.sqlite.org/cintro.html&quot;&gt;C API 소개&lt;/a&gt; 는 다음과 같이 말합니다.</target>
        </trans-unit>
        <trans-unit id="38372a1525b1bf61a2f5f0cc1ddbbf17915e0784" translate="yes" xml:space="preserve">
          <source>The ON CONFLICT command does not apply, cause if you have 10 elements in a record and you need each element inserted to a different table, if element 5 gets a CONSTRAINT error, then all previous 4 inserts need to go too.</source>
          <target state="translated">ON CONFLICT 명령이 적용되지 않습니다. 레코드에 10 개의 요소가 있고 각 요소를 다른 테이블에 삽입해야하는 경우 요소 5에 CONSTRAINT 오류가 발생하면 이전 4 개의 모든 삽입도 이동해야합니다.</target>
        </trans-unit>
        <trans-unit id="8ea1fabbe4633c8d4db54d4c842da90c9441b97d" translate="yes" xml:space="preserve">
          <source>The algorithm I created helped me reduce my process by 2 hours. Final loading process of file 1hr 30m which is still slow but not compared to the 4hrs that it initially took. I managed to speed the inserts from 10.000/s to ~14.000/s</source>
          <target state="translated">내가 만든 알고리즘은 프로세스를 2 시간 단축시키는 데 도움이되었습니다. 파일 1 시간 30 분의 최종 로딩 프로세스는 여전히 느리지 만 처음에 걸린 4 시간과 비교되지는 않습니다. 인서트 속도를 10.000 / s에서 ~ 14.000 / s로</target>
        </trans-unit>
        <trans-unit id="9f26c58828cd1c833c02f45b4f92100c4d5ab702" translate="yes" xml:space="preserve">
          <source>The answer to your question is that the newer SQLite&amp;nbsp;3 has improved performance, use that.</source>
          <target state="translated">귀하의 질문에 대한 답변은 최신 SQLite 3의 성능이 향상되었다는 것입니다.</target>
        </trans-unit>
        <trans-unit id="3987d3dbe6e66d288d9494f0c4a889acd57d2876" translate="yes" xml:space="preserve">
          <source>The code in the test sets the bindings every time through which should be enough.</source>
          <target state="translated">테스트의 코드는 바인딩이 충분할 때마다 바인딩을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="03189b3c8c0eb7bf3b9cf95a8e187e585d96d60f" translate="yes" xml:space="preserve">
          <source>The code is compiled with &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_C%2B%2B#32-bit_versions&quot;&gt;Visual C++&lt;/a&gt; 2005 as &quot;Release&quot; with &quot;Full Optimization&quot; (/Ox) and Favor Fast Code (/Ot).</source>
          <target state="translated">이 코드는 &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_C%2B%2B#32-bit_versions&quot;&gt;Visual C ++&lt;/a&gt; 2005에서 &quot;완전 최적화&quot;(/ Ox) 및 Favor Fast Code (/ Ot)를 사용하여 &quot;릴리스&quot;로 컴파일됩니다.</target>
        </trans-unit>
        <trans-unit id="0ea5d284cecee101861f152c707c71f8fd74f317" translate="yes" xml:space="preserve">
          <source>The improvements are now smaller, but we're up to &lt;strong&gt;69,600 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">향상된 기능은 이제 더 작지만 &lt;strong&gt;초당&lt;/strong&gt; 최대 &lt;strong&gt;69,600 개의 삽입물이 있습니다.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="be2689c857db56817bdb470b056a287c52a2e0c0" translate="yes" xml:space="preserve">
          <source>There is nothing in the docs for &lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt;&lt;code&gt;sqlite3_clear_bindings&lt;/code&gt;&lt;/a&gt; saying you must call it in addition to simply setting the bindings.</source>
          <target state="translated">&lt;a href=&quot;https://www.sqlite.org/c3ref/clear_bindings.html&quot;&gt; &lt;code&gt;sqlite3_clear_bindings&lt;/code&gt; &lt;/a&gt; 에 대한 문서에는 바인딩을 설정하는 것 외에도 호출해야한다고 말하는 것은 없습니다.</target>
        </trans-unit>
        <trans-unit id="bf20f7e886b3170f117100780131fac01a688cee" translate="yes" xml:space="preserve">
          <source>This answer &lt;em&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly/11769768#11769768&quot;&gt;Why is SQLAlchemy insert with sqlite 25 times slower than using sqlite3 directly?&lt;/a&gt;&lt;/em&gt; by SqlAlchemy Orm Author has 100k inserts in 0.5 sec, and I have seen similar results with python-sqlite and SqlAlchemy. Which leads me to believe that performance has improved with SQLite&amp;nbsp;3.</source>
          <target state="translated">이 답변 &lt;em&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly/11769768#11769768&quot;&gt;sqlite3을 직접 사용하는 것보다 sqlite를 사용하는 SQLAlchemy insert가 25 배 느린 이유는 무엇입니까?&lt;/a&gt;&lt;/em&gt; SqlAlchemy에 의해 Orm Author는 0.5 초 만에 100k 개의 삽입을 가지고 있으며 python-sqlite 및 SqlAlchemy와 비슷한 결과를 보았습니다. SQLite 3에서 성능이 향상되었다고 생각합니다.</target>
        </trans-unit>
        <trans-unit id="c6adca7440b2ae1858c40b313a78614c3cd32177" translate="yes" xml:space="preserve">
          <source>This is going to be slow because the SQL will be compiled into VDBE code for every insert and every insert will happen in its own transaction. &lt;em&gt;How slow?&lt;/em&gt;</source>
          <target state="translated">SQL이 모든 삽입에 대해 VDBE 코드로 컴파일되고 모든 삽입이 자체 트랜잭션에서 발생하기 때문에 속도가 느려집니다. &lt;em&gt;얼마나 느려?&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="db63715f64683425fd01f5904246eab4178b65d8" translate="yes" xml:space="preserve">
          <source>This solution helped me bypass the issues I have when dealing with files containing bad/duplicate records (I had almost 4% bad records).</source>
          <target state="translated">이 솔루션을 사용하면 불량 / 중복 레코드가 포함 된 파일을 처리 할 때 발생하는 문제를 피할 수있었습니다 (거의 4 %의 불량 레코드가 있음).</target>
        </trans-unit>
        <trans-unit id="ed7f88668556c34e922129040d0b4cb1fff93abd" translate="yes" xml:space="preserve">
          <source>Too many or too little threads won't do it, you need to benchmark and profile yourself.</source>
          <target state="translated">스레드가 너무 많거나 너무 적 으면 벤치마킹하고 프로필을 작성해야합니다.</target>
        </trans-unit>
        <trans-unit id="5e1b2a6b6d80f8d0e183b885c337e18d7f131c6e" translate="yes" xml:space="preserve">
          <source>Try using &lt;code&gt;SQLITE_STATIC&lt;/code&gt; instead of &lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; for those inserts.</source>
          <target state="translated">해당 삽입에 대해 &lt;code&gt;SQLITE_TRANSIENT&lt;/code&gt; 대신 SQLITE_STATIC 을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="054498b4ab93a63c9779fb5e4449fc342376cebb" translate="yes" xml:space="preserve">
          <source>Use ContentProvider for inserting the bulk data in db.
The below method used for inserting bulk data in to database. This should Improve INSERT-per-second performance of SQLite.</source>
          <target state="translated">db에 벌크 데이터를 삽입하려면 ContentProvider를 사용하십시오. 아래 방법은 데이터베이스에 대량 데이터를 삽입하는 데 사용됩니다. 이는 SQLite의 초당 INSERT 성능을 향상시켜야합니다.</target>
        </trans-unit>
        <trans-unit id="86258bb2c189f1c4b45a4e393182d5e6be34a275" translate="yes" xml:space="preserve">
          <source>Using a Prepared Statement</source>
          <target state="translated">준비된 진술 사용</target>
        </trans-unit>
        <trans-unit id="27bfc98a791c846a44ceefffbe8088440beb0489" translate="yes" xml:space="preserve">
          <source>Using a Transaction</source>
          <target state="translated">거래 사용</target>
        </trans-unit>
        <trans-unit id="efa798e2337da1f597bb94d66f1cd12d1cc78d2f" translate="yes" xml:space="preserve">
          <source>Using a transaction was a huge improvement, but recompiling the SQL statement for every insert doesn't make sense if we using the same SQL over-and-over. Let's use &lt;code&gt;sqlite3_prepare_v2&lt;/code&gt; to compile our SQL statement once and then bind our parameters to that statement using &lt;code&gt;sqlite3_bind_text&lt;/code&gt;:</source>
          <target state="translated">트랜잭션 사용은 크게 개선되었지만 동일한 SQL을 반복해서 사용하는 경우 모든 삽입에 대해 SQL 문을 다시 컴파일하는 것은 의미가 없습니다. &lt;code&gt;sqlite3_prepare_v2&lt;/code&gt; 를 사용하여 SQL 문을 한 번 컴파일 한 다음 &lt;code&gt;sqlite3_bind_text&lt;/code&gt; 를 사용하여 해당 명령문에 매개 변수를 바인드하십시오.</target>
        </trans-unit>
        <trans-unit id="674be12a68db41f5e65e8f6f5288f5307643a49c" translate="yes" xml:space="preserve">
          <source>Using an In-Memory Database</source>
          <target state="translated">인 메모리 데이터베이스 사용</target>
        </trans-unit>
        <trans-unit id="a989490dc1086fbe60acc040f2077ee40bc910a4" translate="yes" xml:space="preserve">
          <source>We're going to generate the SQL string using the values read from the file and invoke that SQL operation using sqlite3_exec:</source>
          <target state="translated">파일에서 읽은 값을 사용하여 SQL 문자열을 생성하고 sqlite3_exec를 사용하여 해당 SQL 작업을 호출합니다.</target>
        </trans-unit>
        <trans-unit id="51a38e71a882481707d999fc28f7f0fcdeaf78ba" translate="yes" xml:space="preserve">
          <source>Yikes! 2 hours and 45 minutes! That's only &lt;strong&gt;85 inserts per second.&lt;/strong&gt;</source>
          <target state="translated">이케 스! 2 시간 45 분! &lt;strong&gt;초당 85 개의 삽입물입니다.&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="cc4e57454f2e22aeb719d5949b1a38ae2ba3ce02" translate="yes" xml:space="preserve">
          <source>You have to be quite careful if you have concurrent access to SQLite, as the whole database is locked when writes are done, and although multiple readers are possible, writes will be locked out. This has been improved somewhat with the addition of a WAL in newer SQLite versions.</source>
          <target state="translated">쓰기가 완료 될 때 전체 데이터베이스가 잠기고 여러 판독기가 가능하더라도 쓰기가 잠기므로 SQLite에 동시에 액세스 할 수있는 경우 매우주의해야합니다. 최신 SQLite 버전에 WAL이 추가되어 다소 개선되었습니다.</target>
        </trans-unit>
        <trans-unit id="f84952b103a6b1fa35391ad802ceb45691b6a3c4" translate="yes" xml:space="preserve">
          <source>for each thread:</source>
          <target state="translated">각 스레드마다 :</target>
        </trans-unit>
        <trans-unit id="718651ac1e4d28eed11decc1cc7b263cdac1558f" translate="yes" xml:space="preserve">
          <source>then read in pages (LIMIT/OFFSET):</source>
          <target state="translated">그런 다음 페이지를 읽습니다 (LIMIT / OFFSET).</target>
        </trans-unit>
        <trans-unit id="779e8933edaa2a8b59f69f6c48510a0f1a6cf67a" translate="yes" xml:space="preserve">
          <source>where  and  are calculated per-thread, like this:</source>
          <target state="translated">다음과 같이 스레드 당 계산되는 위치는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="f4c7bc63d48e550900e1d3bed8080e1b721d1e85" translate="yes" xml:space="preserve">
          <source>which bulk loads an array of ActiveRecords into &lt;a href=&quot;http://en.wikipedia.org/wiki/MySQL&quot;&gt;MySQL&lt;/a&gt;, SQLite or &lt;a href=&quot;http://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; databases. It includes an option to ignore existing records, overwrite them or raise an error. My rudimentary benchmarks show a 10x speed improvement compared to sequential writes -- YMMV.</source>
          <target state="translated">ActiveRecord 배열을 &lt;a href=&quot;http://en.wikipedia.org/wiki/MySQL&quot;&gt;MySQL&lt;/a&gt; , SQLite 또는 &lt;a href=&quot;http://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; 데이터베이스에 대량로드합니다. 기존 레코드를 무시하거나 덮어 쓰거나 오류를 발생시키는 옵션이 포함되어 있습니다. 필자의 기초 벤치 마크는 순차적 쓰기 (YMMV)에 비해 속도가 10 배 향상되었습니다.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
